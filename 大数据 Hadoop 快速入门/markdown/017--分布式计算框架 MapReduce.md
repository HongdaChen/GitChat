### 什么是 MapReduce？

MapReduce 起源是 2004 年 10 月 Google 发表了 MapReduce 论文，之后由 Mike Cafarella 在
Nutch（爬虫项目）中实现了 MapReduce 的功能。它的设计初衷是解决搜索引擎中大规模网页数据的并行处理问题，之后成为 Apache Hadoop
的核心子项目。

它是一个面向批处理的分布式计算框架；在分布式环境中，MapReduce 程序被分为 Map（映射）阶段和 Reduce（化简）阶段。

它的第一个核心思想，移动计算而非移动数据。在分布式环境中，数据是被拆分，然后存储到不同的节点，海量数据的情况下，这些数据的移动会造成非常大的开销，于是
MapReduce 将任务分发到数据所在的节点进行运算，这个阶段称为
Map。各个节点的计算任务，因为使用的是部分数据，所以计算得到的结果，一定是部分结果；那就需要对这些部分结果进行汇总，这个汇总阶段称为 Reduce。

![](https://gitee.com/QiaoLuManMan/ImageUpload/raw/master/img/20201018061254.png)

整个的运算流程，是拆分到不同节点进行的，所以这也是它第二个核心思想的体现：分而治之，并行计算。

### 基本特点

首先作为分布式的计算框架，和其它大数据组件一样，拥有良好的扩展性和高容错的特性。其次，计算跟着数据走，这是大数据计算引擎常见的设计方式，海量数据的规模下，这种方式是一种妥协，也是一种新的思路。

而且正因为这种计算随着数据走的形式，所以它适合海量数据的离线批处理，为什么？因为离线处理方式，正是将数据存储起来之后，再对数据进行处理，而对离线数据的处理方式，使用批处理是最为合适的；且
MapReduce 出现时间较早，限于硬件成本，它更多使用了与磁盘交互的方式以节约内存，所以它也不能像 Spark
一样，将流处理任务转换成微批处理模式。离线批处理，是现阶段它唯一的使用场景。

作为一个通用的分布式计算框架，它降低了分布式编程的门槛，提供了分布式计算的能力；但相对于之后出现的
Spark，它更多的还需要去考虑数据的拆分、聚合的设计逻辑，易用性略微不足。

### 适用场景

MapReduce 的典型应用场景是离线批处理，所以数据统计，如：网站的 PV 和 UV
统计、搜索引擎构建索引、海量数据查询、复杂数据分析算法实现，都可以使用 MapReduce 来实现。

但有一些场景不太适用。如 OLAP，这种要求实时返回结果或者延迟较低的场景，MapReduce
因为过多的依赖了磁盘交互，所以无法完成计算结果的实时返回；流计算，因为需要数据集的实时输入，而 MapReduce 只能接收离线的数据集；还有 DAG
计算，多个作业存在依赖关系，后一个的输入是前一个的输出，构成有向无环图 DAG，MapReduce 也不太适合，单个 MapReduce 作业只能完成一次
Map 和一次 Reduce 聚合，如果需要只能通过多个 MapReduce 任务来进行，但因为每个 MapReduce
作业的输出结果都会落盘，造成大量磁盘 IO，导致性能非常低下。

