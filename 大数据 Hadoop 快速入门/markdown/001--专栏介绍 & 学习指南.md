### 写在前面的话

你好，我是李鹏程，高级数据工程师、大数据讲师。这次给大家带来的是《大数据 Hadoop 快速入门》专栏。

2013
年被称为大数据元年，随着互联网的快速发展和信息爆炸式增长，带来了数据存储、运算方式的革命。一种全新的，完全依附于分布式架构的技术解决方案，被称为大数据。

虽然在分布式架构下，数据存储的延迟会较高，数据处理时的调度耗时也较大；但它也带来了极强的扩展性，而且在海量数据规模下吞吐量极大，处理速度非常快（海量数据规模下，调度时间远远小于处理时间），解决了大数据规模下的存储、处理的痛点。

在大数据技术提供了分布式存储、分布式通用计算的基础上，针对不同场景（如数据仓库、实时流处理、图计算、分布式机器学习、搜索与检索），有丰富的大数据产品可供选择，致力解决易用性问题。

将来 5G
时代的来临，企业的数据量会更加庞大，那么传统数据处理架构便要逐步更换为大数据架构。大数据的人才也会非常紧缺。而且正因为大数据的兴起，所以人工智能也换发了第二春，大数据与人工智能是相辅相成的两个方向。

但一般而言，大数据的入门会有一定的门槛；首先是因为环境搭建比较麻烦，很容易劝退；其次框架众多，需要花费一定的学习时间。专栏内容会尽量帮大家降低入门的门槛，提供环境一键搭建脚本，快速完成大数据环境搭建，直接便可以上手并见到效果。在内容上，主要讲解
Hadoop 框架，包含 HDFS、Yarn、MapReduce，以入门为主，语言精练，逐步为大家构建大数据技术的印象，扎实基础。

那到底什么是大数据？什么是 Hadoop？它是如何发展来的？它的架构、原理是怎样的？如何使用？在这个专栏中，都会为大家讲解到。

### 专栏内容

专栏内容一共分为 4 部分，大数据简介、HDFS、Yarn、MapReduce。

在简介部分，主要介绍大数据的诞生背景、基本概述、应用场景、编年史，并讲解大数据的生态架构、技术体系。在这部分全面了解、掌握大数据的前世今生，构建对大数据技术的整体印象。

HDFS 部分，首先介绍 HDFS 基本情况，然后分别讲解 HDFS 的系统架构、存储模式、读写操作、安全模式、高可用等原理内容。HDFS
的使用上，主要讲解环境搭建与配置、HDFS 服务命令、Shell 命令、Java API。最后运维部分，讲解 HDFS 运维命令、系统监控的内容。

Yarn 部分，从简介、原理、资源调度策略、运维与监控 4 部分着手，分别讲解 Yarn
的诞生目标、设计目标、系统架构、高可用、资源调度策略，运维这里，会涉及到 Yarn 的基本命令、配置文件、可视化监控。

MapReduce 部分，从简介、原理、作业管理、使用案例展开，讲解 MapReduce
基本概念、适用场景，并分析其基本架构、执行过程、运行模式。在代码实战，会介绍作业的提交与管理、监控与诊断，并附上 4 个基础案例进行讲解和练习。

### 学习指南

在整体专栏学习的时候，先不要陷入细节中，可以快速浏览下专栏内容，在整体上有个大概的把握，然后再阅读每一部分内容。否则，不见全貌，而陷入对细节的纠结中，会对之后的学习产生不利的影响。而且专栏内容一定是要看好几遍的，第一遍只是帮助你搭建一个知识框架，之后的每一遍阅读都会使你对知识的理解更为深入；由浅入深，这才是知识的学习步骤。

而且在技术学习中，尤其在线上专栏中，大部分学员会在环境搭建这里花费很长时间，然后学习热情被消耗殆尽，专栏也就仅仅完成了从入门到放弃的劝退功能。所以环境的开箱即用是最重要的，尽量在环境上少花费时间，因为在企业开发中，环境都是现成的；如果真的需要亲自去完成环境搭建，也不需要记住每一步过程，留个文档，甚至写个脚本复用就好。

所以在专栏中，会提供一键安装脚本，帮助在集群中快速建立大数据集群环境。只需要大家在 Virtual Box 上准备 3 台 CentOS 7.2
的虚拟机环境即可，当然虚拟机镜像也会提供。环境的快速搭建，帮助大数据开发的学员迅速进入实际操作环节，而且对运维的学员也是一种福利。

好，整体交代清楚后，来一起进行正式大数据 Hadoop 基础入门的学习吧。

