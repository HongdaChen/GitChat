### HDFS 简介

#### **什么是 HDFS？**

HDFS 全称 Hadoop Distributed File System，Hadoop 分布式文件系统。它是 2003 年 10 月 Google
发表的 GFS（Google File System）论文的开源实现，之后成为 Apache Hadoop
的核心子项目，用于解决海量数据存储问题。它在开源大数据技术体系中，地位无可替代，到现在为止，依然是主流的大数据存储选型。

![](https://gitee.com/QiaoLuManMan/ImageUpload/raw/master/img/20201010053825.png)

#### **设计目标**

HDFS 的设计目标有：

  * 可以运行在大量廉价商用机器上；因此硬件错误是常态，所以 HDFS 提供容错机制，来保证集群的安全性与数据的可靠性。
  * 简单一致性模型：一次写入多次读取，支持追加，不允许修改，保证数据一致性。因为 HDFS 在数据存储时，会使用多副本机制保证数据的安全性；如果开放修改功能，首先会导致随机修改的出现，这在海量数据的分布式场景下无异是灾难，其次因为多副本的原因，数据修改后，其它副本的数据也一定要进行修改，从而保证数据一致性，这更加重了集群的负担。
  * 流式数据访问：批量读而非随机读，关注吞吐量而非时间；HDFS 在设计时就是为了海量数据的存储而生，并且用于支持海量数据的离线批处理，而在离线批处理场景中，数据都是全部被读取后，进行批量处理，所以 HDFS 在设计上更注重数据的批量读而非随机读，保证数据处理时的吞吐效率。
  * 存储大规模数据集：典型文件大小 GB~TB，关注横向线性扩展；这是 HDFS 设计的初衷，保证海量数据的存储。

### HDFS 的优缺点

#### **优点**

HDFS 最大的优点在于它支持 **海量数据存储** （典型文件大小 GB~TB，百万以上文件数量，PB 以上数据规模），是大数据存储的经典选型。

其次，它有 **高容错** （多副本策略）、 **高可用** （HA，安全模式）、 **高扩展** （10K
节点规模）的特性，作为大数据存储解决方案已经非常成熟。

它 **构建成本低、安全可靠** （构建在廉价商用机器上，提供容错机制）， **适合大规模离线批处理**
（流式数据访问，数据位置暴露给计算框架），为大数据计算提供了支持。

#### **缺点**

HDFS 的缺点也很明显，首先它 **不适合低延迟数据访问** ，因为数据存储到 HDFS
上时，首先要切分成固定大小的块，然后每块数据进行存储时还要进行多副本的备份，所以数据读取时，先要从各个节点将每块数据读取出来，然后再合并成原文件返回，所以访问文件时延迟会比较大；但在数据处理时，其实数据时不需要移动的，计算任务会直接分发到数据节点，这才是
HDFS 的适用场景。

HDFS **不适合大量小文件存储** ，因为 HDFS
设计时是主从架构，从节点是数据节点，负责存储数据，而主节点保存元数据（记录数据被存储到那个从节点中），所以小文件越多，主节点保存的元数据也就越多，而元数据大小是固定的，所以会占用
NameNode
大量空间。再一个，在进行计算处理时，一个数据文件上会启动一个计算任务，小文件数量越多，那生成的任务数量也就越多；但单个任务在处理时因为数据量小，运算速度很快，大量的时间被消耗在任务的生成、分发、调度中，造成计算时间大幅度增加。

HDFS **不支持并发写入** ，因为在分布式集群中要保证数据的一致性，而并发写入有可能会造成数据不一致的风险。且 **不支持文件随机修改**
（仅支持追加写入），其实之前已经讲过，在集群中进行文件的随机修改，而且是多副本情况下，会造成很大的负载。

对于 HDFS 这些不适用场景，一定要留意。每个产品设计出来，便会有它的适用场景，在它的适用场景中才会发挥它最大的威力，如果错误适用它，会造成很大的浪费。

### 小结

这一篇主要介绍了 HDFS 的基本情况，下一篇会解读 HDFS 的架构、原理，一起来看吧。

