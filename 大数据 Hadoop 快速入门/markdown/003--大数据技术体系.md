这一篇，来认识下大数据的技术框架有哪些，它们分别用于解决哪些问题？它们的内在逻辑和适用场景有哪些？OK，一起去探索下。

### 生态架构

![](https://gitee.com/QiaoLuManMan/ImageUpload/raw/master/img/20201008072612.png)

首先，看一下大数据技术体系的整体架构图。根据数据流转的方向，从下而上进行介绍。

在前面，我们了解到，大数据的数据存储是分布式的，而且能够接受任务调度，与传统的数据存储存在差异。所以离线方式处理的数据，需要通过 **ETL**
模块，导入到大数据的 **数据存储系统** 进行存储；其中 Sqoop 是常见的抽取结构化数据工具；而 Flume 和 Logstach
是用于抽取非结构化、半结构化数据工具。

大数据的 **数据存储系统** ，最常见的就是分布式文件系统 HDFS；如果需要使用 NoSQL 数据库功能，HBase 是基于 HDFS 实现的一个分布式
NoSQL 数据库。

存储起来的数据，使用大数据的 **通用计算引擎** MapReduce 或 Spark 进行计算，这些计算任务会由 **资源管理框架** ——Yarn
进行调度。将任务分发到数据的存储位置——HDFS 中。

但使用通用计算引擎 MapReduce 或 Spark
编写处理任务，需要使用特定的语法；这样一来，原有的特定领域的传统业务，进行迁移时就会带来很多问题。比如原有的数据仓库，使用 SQL
进行数据处理任务，但迁移到大数据平台之后，原来的 SQL 业务需要全部转换为 MapReduce、Spark
语法，迁移成本太大。其次，图计算、机器学习等其他领域，在 MapReduce、Spark 语法基础上，实现起来非常困难，且易用性很差。

于是在通用计算引擎之上，针对不同的领域，诞生了很多提升易用性的产品；以使得对存储在大数据平台上的数据进行 **数据分析** ，变得更加容易。

比如在 Hadoop 生态圈的 Hive，它的作用就是将 SQL 转化成 MapReduce 任务，减少了数据仓库迁移成本，虽然它的 SQL 支持率只有
60% 左右，而且有特定的语法 HQL（Hive SQL），但已经极大的简化了结构化数据的处理过程。当然它现在也支持底层计算引擎转换为
Spark，以便提升处理性能。

Hadoop 生态圈的 Pig 的功能和 Hive 类似，但它是将 MapReduce 封装为自己的 API，使用起来比原生的 MapReduce
更易用一些；在早期，使用的公司较多，现在基本已很少被使用。

Hadoop 生态圈的 Malhot 是机器学习的一个框架，可以完成机器学习的任务，底层将任务转换为 MapReduce，从而实现分布式运算。

除了 Hadoop 生态圈，Spark 引擎也有自己的生态圈，其中 Spark SQL 和 Hive 功能类似，将 SQL 转换为 Spark
任务，提升结构化数据处理的易用性。MLlib 提供机器学习的功能，GraphX 完成图计算功能，Spark Streaming 完成流计算任务。

在架构图中的 **数据分析层**
中，有一个产品比较特殊——Elasticsearch，它是用于大数据下的搜索与检索场景的产品。但它是独立运行的，将数据存储于本地磁盘，不依赖于
HDFS；有自己的计算引擎，不依赖于 MapReduce、Spark。所以，除了在大数据领域，其它很多场景中也能见到它的身影。

### 大数据实时流处理

在大数据实时运算这里，半结构化、非结构化数据先通过实时 ETL 工具，如 Flume、Logstash
进行数据的实时采集；结构化数据，一般会采用监控数据库预写日志的方式，通过 CDC 或者 OGG 等工具进行实时抽取。

实时抽取的数据，首先会进入到消息队列中，完成削弱峰值和解耦合的功能，之后便交于流处理引擎进行处理。常见的流处理引擎有 Spark
Streaming、Flink。

其中 Spark Streaming 是将实时处理任务转换为 Spark
这种离线批处理任务进行处理，它的原理就是将一定时间间隔内的数据，转换为离线批处理任务，只要时间间隔足够短，它就可以近似于实时处理。所以 Spark
Streaming 的处理方式也被称为微批处理模式。

而 Flink，它有自己的运算引擎，所以是真正意义上的实时计算，而不需要转换为批处理任务。

数据经过处理之后，最终的结果会被存储到数据库集群中，企业常用的选型是
HBase，因为它有一个较好的特性：高并发读，可以满足前端系统结果的实时查询。当然，Druid、Clickhouse 也是常用的选型产品。

### 分布式协调服务

大数据的产品，都是分布式架构，以集群的形式部署和运算。于是，分布式集群的管理便成了一个问题，比如节点间的发现、主从的切换等。而
ZooKeeper，就是为了解决这些问题而存在的，它提供分布式协调服务。

ZooKeeper 本质上是一个特殊的文件系统，加上消息通知机制，来完成分布式协调。比如节点间的发现，当某个集群在第一次启动时，假设为 Kafka，它会在
ZooKeeper 上的文件系统中创建自己的目录——Kafka；其中 Kafka 每个节点启动成功后，假设为 Node01，会在 ZooKeeper 上的
Kafka 目录中注册，即创建自己的节点文件——Node01，ZooKeeper 检测到 Kafka 目录创建了 Node01，便会通知 Kafka
中的所有节点，Node01 加入到集群中了；而 Node01 超过一定时间没有向 ZooKeeper 进行通信，Kafka 目录下的 Node01
文件便会被删除，于是 ZooKeeper 便又会通知所有 Kafka 节点，Node01 节点被移除了。

在很多大数据产品中，都会依赖 ZooKeeper 集群，用于实现分布式协调服务。

### 分布式任务调度

大数据分析任务，一般都会有多个产品协同完成，并且存在严格的先后顺序。比如，要完成对当天数据的处理，首先需要通过 ETL 组件，将数据抽取到 HDFS
中进行存储，之后再由 Hive 或 Spark SQL 将数据接入进行处理，处理完成之后，为了保证前端的查询效率，可能再通过 ETL
组件将结果表存储到其它数据库中。

其次，大数据任务的执行，如离线数据仓库，一般会选择定时执行；如凌晨零点，对昨天的数据统一进行抽取，并处理计算。

大数据的分布式任务调度组件 Azkaban、Oozie 就是来完成这些任务的，它们可以完成控制任务的执行顺序、定时执行等功能。

而 Azkaban 相对 Oozie 来说，它的功能相对丰富，Web 界面也较为美观，在企业选型中比较常见。

### 分享交流

我们为本专栏付费读者创建了微信交流群，以方便更有针对性地讨论专栏相关的问题。入群方式请添加 GitChat 小助手 Task
的微信号：Linmicc（或扫描以下二维码），然后给小助手发「7237」消息，即可拉你进群～

![avatar](https://images.gitbook.cn/FrOaV_n_HIjq3OjwyqAYRX_TBOUx)

