### 数组指针 vs 指针数组

    
    
    func main() {
        var a [3]int
        var b [3]*int
        var p *[3]int = &a
        p[0] = 10
        var p1 *int = &a[2]
        *p1 = 30
        fmt.Println(a, b)
    }
    

  * 数组指针引用整个目标数组。
  * 数组指针元素类型为指针。
  * 可使用数组指针访问和赋值元素，可直接获取元素地址。

数组指针指的是数组的起始位置，用一个变量保存这个地址，这个变量叫做数组指针。变量要分配内存，这个变量里面存了某一个地址，而地址只是抽象的序号，所以指针和地址并不是一回事。数组指针是一个变量保存了数组的起始位置，指针数组是数组里面保存的是指针，就是说一个数组的元素类型是指针的情况下叫指针数组，等于整数数组整数换成指针而已。

上面例子中 a 和 b 都是普通的数组，a 存的是整数，b 存的是指针。p
是数组的指针，数组本质上是一个单一对象，对它取指针操作，虽然指针指向数组起始地址，实际上包括完整的内存访问空间，我们称为数组的指针。数组的指针和数组本身操作没什么区别，支持语法糖访问。p1
取的是某个元素的指针，不能用下标的方式退化为普通的指针操作。

    
    
    func main() {
        var x [100]int
        p := &x
        p[1] = 100 //语法糖(*p)[1]
        println(p[1])
    
        p2 := &p
        println((*p2)[1])
    
        p3 := &x[30]
        *p3 = 99
        println(x[30])
    }
    

上面例子数组 x，p 取它的地址返回它的指针，p 的类型是 `*[100]int`。数组的指针指的是把这个数组当成单一对象来对待，可以通过类型的指针进行赋值
`p[1] = 100`，这是一种语法糖，相当于自动转换为 `(*p)[1]`。p2 是二级指针，取指针 p 的指针，语法糖仅支持一级指针，不支持
p2[1] 写法，需要指定 `(*p2)[1]`。

数组支持直接取元素的地址。比如 `p3 := &x[30]`，p3 不能通过下标赋值，下标只是数组的方式。p3
是单个元素的地址，是把一个块当成整数处理。这两种指针类型是不一样的，数组的指针是完整的，可以用语法糖下标的方式，如果取的是其中元素从数组演化成单一对象，只能针对元素操作，不是操作整个数组而是操作其中一个元素
`*p3 = 99`。所以要分清楚数组的指针、元素的指针。

指针数组 `var x [100]*int`
是一个普通的数组。区别就是，每个元素是一个指针，指向某个对象。所以数组的指针和指针数组不一样的，数组的指针是内存块而言，指针数组和整数数组字符串数组没什么区别。

    
    
    func main() {
        var x [100]unsafe.Pointer //任意类型的指针
    
        a := 1
        x[0] = unsafe.Pointer(&a) //整数的指针
    
        s := "abc"
        x[1] = unsafe.Pointer(&s) //字符串的指针
    }
    

### 是不是数组就一定能分配在栈上？

很多时候我们用数组优化会非常好，但是数组未必分配到栈上，下面的例子声明一个数组，并把它的地址打印出来。

    
    
    func escape() {
        var d [10]int
        fmt.Println(&d)
    }
    
    
    
    $ go run -gcflags "-m" main.go
    # command-line-arguments
    &d escapes to heap
    &d escapes to heap
    moved to heap: d
    escape ... argument does not escape
    &[0 0 0 0 0 0 0 0 0 0]
    

我们发觉 `&d` 逃逸到堆上了，因为 fmt.Println
接收参数的是接口对象，接口对象必须复制原始对象内部需要储存相应的信息，原始数据必须保证生命周期必须要放到堆上面。

### False Sharing的问题

cache miss 就是 cache 没有命中，在数组操作时候可能会写一些性能有问题的代码。

CPU 的结构是多核，核内部每个都有 L1、L2 缓存，L3 是共享的，L1 分成指令缓存和数据缓存。

当我们获取数据的时候首先在缓存中查，查不到到主存中查，查到存到缓存中，问题是数据不是完全按对象缓存，因为缓存时候 CPU
根本不知道对象结构是什么样的，所有的内存都是字节，它把空间分成多个等长的块，每个块称之为 cache line，每次缓存是固定大小的块，这个块可能是 64
字节。

假如一个数组，一个块缓存可能是多个元素，假设 cpu0 访问 index=0 数据，cpu1 访问 index=1 数据，这样 cpu0 和 cpu1
除了自己操作的数据以外还缓存了别人的数据。假如 cpu0 和 cpu1 并发执行两个任务，cpu0 的 index=0 做加法的时候整个 cache
line 发生变化了，因为 CPU 内部 cache line 是一整块，所以两个 cache line 同时被两个 CPU
缓存，一旦修改里面的状态就会导致其他核同样的缓存块失效，cpu0 上状态改变了，cpu1 必须同步。同样地，cpu1 修改数据 cpu0 必须同步，cpu0
和 cpu1 频繁进行缓存同步，会造成缓存效应非常的差。我们管这种现象叫做 False Sharing，这种缓存是有问题的。

这是因为 CPU 不清楚内部什么数据结构，它是按照 64 字节来缓存一个块，如果 cpu0 和 cpu1 都持有这 64
字节，任何字节发生改变都需要同步到其他 CPU 核。

    
    
    func falseSharing() {
        var wg sync.WaitGroup
    
        // 有 4 个计数器，有 4 个并发任务，每个任务拿其中一个来作为计数器使用
        var counter [4]int
    
        for i := 0; i < len(counter); i++ {
            wg.Add(1)
    
            go func(idx int) {
                defer wg.Done()
    
                for n := 0; n < 1000000; n++ {
                    counter[idx]++
                }
            }(i)
        }
        wg.Wait()
    }
    

上面的这段代码，有 False Sharing 问题，我们修改一下：

    
    
    func falseSharing() {
        var wg sync.WaitGroup
    
        var counter [4]struct {
            data int
            _    [64 - 8]byte
        }
    
        for i := 0; i < len(counter); i++ {
            wg.Add(1)
    
            go func(idx int) {
                defer wg.Done()
    
                for n := 0; n < 1000000; n++ {
                    counter[idx].data++
                }
            }(i)
        }
        wg.Wait()
    }
    

每个计数器一条 cache line，修改计数器只是修改 0 号位，相互之间没有重叠的地方，这样就不会导致缓存失效问题。怎么样保证每个计数器调用单独的
cache line，简单做法就是用来补位，需要补位字段，提高性能。

    
    
    func test() {
        var counter [8]struct {
            x int
            // _ [64 - 8]byte
        }
        var wg sync.WaitGroup
        wg.Add(len(counter))
        for i := 0; i < len(counter); i++ {
            go func(id int) {
                for n := 0; n < 100000; n++ {
                    counter[id].x++
                }
                wg.Done()
            }(i)
        }
        wg.Wait()
    }
    
    func BenchmarkTest(b *testing.B) {
        b.Run("nopad", func(b *testing.B) {
            for i := 0; i < b.N; i++ {
                test1()
            }
        })
        b.Run("pad", func(b *testing.B) {
            for i := 0; i < b.N; i++ {
                test2()
            }
        })
    }
    
    
    
    false sharing; cache line; MESI, RFO
    

下面命令查看系统 cache line 大小：

    
    
    $ cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
    $ cat /proc/cpuinfo | grep cache_alignment
    

mheap.go 文件：

测试样本有八个计数器，每个计数器是个结构体，根据索引访问每个是独立的计数器，没有数据竞争，因为不会访问相邻的内存。区别在于有一行用来补位，结果带来这么大的性能差别，这就是所谓的缓存共会不会失效的问题。

CPU 有一套自己缓存体系，CPU 没有办法直接访问内存，现代 CPU 所有的数据都是从它的缓存获取的。L1 缓存分为指令和数据，CPU 有自己独立的 L1
缓存、L2 缓存，所有 CPU 共享 L3 级缓存，实际上是这样架构。当访问数据的时候，它会优先一级一级缓存去找，找不到才会到主存里找。缓存器负责从主存和
L3、L2、L1 取数据，写数据反过来一个方向。

一份数据可能同时被两个 CPU 缓存，读没有问题。假设 CPU1 修改数据，它会向地址总线发出一个请求对修改数据要求独占，这条指令在地址总线被其他 CPU
监听，会立即把自己缓存里相同的数据缓存失效，导致相同的数据在其他的 CPU 核立即失效，从共享变成独占直到修改成功下次访问重新刷新缓存。

CPU 实际上不理解数据结构，它的缓存器存的是一块缓存，缓存分成一块一块的，每块称之为行，每行称之为 cahce line
缓存行。所谓的独占、修改、共享是以缓存行为单位的。缓存行通常情况下 64 字节。当缓存数据的时候，它会以某个对象起始的连续的 64
个字节内存一次性缓存一行，这就是所谓的缓存空间局部性原则，接下来很大概率读取相邻的内存，也就意味着修改同样是缓存行，拿到这一行的独占权。会导致其他 CPU
相同的这一行数据失效，修改成功要重新刷新缓存，这就是所谓的缓存行的概念。

每个计数器是 8 字节，一共是 8 个 64 字节正好一缓存行，意味着数据正好会被刷到 CPU1 的一行里，CPU2、CPU3、CPU4
都有同样的数组，这样同一个数组会被所有 CPU 内核缓存起来。如果不了解这个背景知识，我们认为 CPU1 只修改一小块，CPU2
修改一小块，从代码上看它修改内存不相等。但是对 cpu 来说它按照一整行 64 字节来锁定的，它不关心在 64 字节里访问哪一块，64 字节是一个整体。当
CPU1 修改数据的时候要独占 64 字节会导致 CPU2 整个缓存行全部失效。CPU2 要修改也要把缓存重新刷回来。任何一方修改计数器都会导致其他 cpu
里缓存行全部失效。

怎么解决呢？用补位的方式占 64 字节。这样 CPU1 刷到是 64 字节，CPU1 和 CPU2 刷的数据是不一样的，数据不相交。CPU2
缓存数据不会出现在 CPU1 里。用补位把原来挤在一块凑成一个 cache line。通过补位的方式每一个元素占 64 字节不被所有 CPU 共享，每个
CPU 都持有一条独立的行，这样缓存就能正常工作。尤其是在服务器编程核数量越多的情况下，影响会越来越严重。

对于伪共享背后有一整套的理论，以后写相关并发的时候要考虑到，伪共享可能会造成一些性能损失。它跟语言无关，使用任何的语言最终都跟 CPU
打交道，都可能会面临这样的一些问题。

