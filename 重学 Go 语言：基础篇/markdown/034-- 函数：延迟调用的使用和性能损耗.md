### 延迟调用（defer）执行机制和时机

还有一点是所谓延迟调用的问题。我们知道返回一个匿名函数只是返回一个包装，但是并没有调用这个函数，这就存在延迟调用问题。

    
    
    func closure() []func() {
        //动态切片当做数组
        var fs []func()
    
        for i := 0; i < 10; i++ {
            //添加10个匿名函数
            fs = append(fs, func() {
                fmt.Printf("%p: %v\n", &i, i)
            })
        }
        return fs
    }
    
    func closureFix() []func() {
        var fs []func()
    
        for i := 0; i < 10; i++ {
            x := i
            fs = append(fs, func() {
                fmt.Printf("%p: %v\n", &x, x)
            })
        }
        return fs
    }
    
    func testClosure() {
        for _, f := range closure() {
            f()
        }
    }
    

执行的时候和我们想象的不太一样，10 个函数都引用同一个变量而且变量都是 10。需要搞清楚的是，往 fs 里面加的实际上是匿名函数的指针和 i 的指针。10
个匿名函数引用的是同一个i变量，只不过 i 被逃逸到堆上了，但是变量是同一个。接下来执行的时候当然是同一个地址。闭包复制的是变量的指针，没有复制它的值。

### 如何在调用堆栈的任意环节终止执行

    
    
    func main() {
        func() {
            println("1")
    
            func() {
                println("1.1")
    
                runtime.Goexit()
    
                func() {
                    println("1.1.1")
                }()
            }()
        }()
        println("end")
    }
    

嵌套多层调用，这是一个完整的调用堆栈，因为某种原因想终止调用堆栈流程。return
只是保证当前堆栈帧结束。很多语言都有类似这样的功能，就是把当前的线程或者并发单元终止。

### 不能确保延迟调用一定被执行

    
    
    func main() {
        defer println("exit")
        //os.Exit(0)
        panic("abc")
    }
    

  * 引发 panic，延迟函数也会被执行。
  * 用 runtime.Goexit 终止当前 goroutine，延迟函数会被执行。
  * 但 os.Exit 会立即终止进程，不执行任何延迟函数。

defer 语句确保可以被执行，其实这句话有错误。defer 语句能执行的前提是，不能调用一些很特殊的进程终止方法。

### 延迟调用性能损耗

    
    
    var m sync.Mutex
    
    func call() {
        m.Lock()
        // logic
        m.Unlock() //call
    }
    func deferCall() {
        m.Lock()
        defer m.Unlock() // deferproc+deferreturn
        // logic
    }
    
    func BenchmarkTest(b *testing.B) {
        b.Run("call", func(b *testing.B) {
            for i := 0; i < b.N; i++ {
                call()
            }
        })
        b.Run("defer", func(b *testing.B) {
            for i := 0; i < b.N; i++ {
                deferCall()
            }
        })
    }
    

比如最常见的枷锁操作两种写法，第一种直接 Lock() 执行逻辑，然后 Unlock()。第二种写法使用
defer，这两种写法实际上到底有多大性能差别。我们大概对比有三倍的性能差异。

很多语言都有类似的语法糖，语法糖会让代码变得更简单，但是多数情况下语法糖都是性能杀手，就像 defer 语句在源码上看上去很简单，使用 defer
关键字就能确保语句一定会被执行，不管出错不出错；但是汇编时这条语句会编译成很多次函数调用，而且很复杂。很显然，从指令级别变成函数调用，这里面性能差异就是数量级的。

我们做个简单的演示：

    
    
    var m sync.Mutex
    
    func call() {
        m.Lock()
        m.Unlock()
    }
    
    func deferCall() {
        m.Lock()
        defer m.Unlock()
    }
    
    func BenchmarkCall(b *testing.B) {
        for i := 0; i < b.N; i++ {
            call()
        }
    }
    
    func BenchmarkDefer(b *testing.B) {
        for i := 0; i < b.N; i++ {
            deferCall()
        }
    }
    
    
    
    $ go test -v -bench . -benchmem
    
    
    
    BenchmarkCall      100000000           16.4 ns/op         0 B/op          0 allocs/op
    BenchmarkDefer     20000000            55.5 ns/op         0 B/op          0 allocs/op
    

注意到 defer 调用会比普通调用高出 4 倍，这就是它的性能差异，多了 60ns。60ns 执行多少条汇编指令，对于 CPU来说已经很长了，OPS
压力非常大，尤其对于锁竞争非常激烈的情况下。比如说有 1000 个并发线程，它们竞争同一个锁，那么理论上这 1000
个线程在锁的控制下实际从并行变成串行了。那么这个锁的时间就变得非常关键，每次锁都需要耗时
60ns，压力大的时候这个数量变得非常可怕。考虑并发压力情况下总体会被放大到多大规模。

所以说学习一门语言的时候，语言提供很好看上去很酷的功能，需要搞清楚是用什么代价换来的，这个功能如果花费了这么高的代价，需要考虑假如没有多大并发压力，浪费点性能让代码变得很简单，就会优先使用这个语法糖；但是如果压力非常大，在高并发的情况下，那可能就不会使用，因为这个功能在高并发情况下会被无限放大，放大了之后就会成为性能瓶颈。现在的语言都会很喜欢提供各种各样的语法糖，需要知道这些语法糖是用什么换来的，什么时候该用，什么时候不该用，选择的前提是，搞懂这些是怎么实现的。

