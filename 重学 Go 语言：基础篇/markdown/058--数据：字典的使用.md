### 字典的数据竞争问题

很多人会问，数据结构是不是线程安全的？大部分语言都是非线程安全的，为什么不直接做成线程安全？

因为线程安全需要加锁。

如果字典线程安全，比如遍历处理，是不是每次访问都要进行锁的处理？我们可能希望在遍历之前加锁，遍历完成之后解锁，这时候锁的粒度是由调用方控制的，因为只有我们才知道锁的粒度多大才合理。字典只是逻辑处理的代码块，逻辑可能有多个代码块组成的，那么可以对几个代码块区域加锁，在内部再实现第二把锁没有必要。

一个数据结构是不是线程安全，前提你得知道，你的算法在数据安全范围到底有多大，而什么时候开始加锁、什么时候开始解锁只有算法知道，数据结构不知道，它没有办法控制这些东西。之所以想要数据安全，是因为想把它从数据算法里分离出去，作为独立的存储结构。

如果你的逻辑结构用异步的方式把数据存储到存储结构里面，数据提交完了并不负责存储这块，那么存储结构的锁就变成独立的了，因为这两个东西并不属于一个执行序上面的。这时候锁是分离的，选择线程安全的数据容器就很正常。我们把一个东西异步提交，最终由哪个线程执行是不确定的，它已经从当前线程脱离出去了。当前线程的锁并不会影响另外一个线程，另外一个线程有自己的锁，这时候选择数据用线程安全的容器就变成合理的了。什么时候选择什么样的线程容器，这个容器是否线程安全和算法有关系，不能莫名奇妙地就去选择一种线程安全的容器。

Go 语言的特点是所有东西都是并发的，从程序一启动都是并发的，字典是很容易造成并发冲突的，所以 Go
编译器把它当作特等公民对待，只要发现有并发冲突就立马对它进行中断。

    
    
    func main() {
        m := make(map[string]int)
    
        w := func() {
            for {
                m["a"]++
            }
        }
    
        r := func() {
            for {
                _ = m["b"]
            }
        }
    
        _, _ = r, w
    
        go w()
        go w()
    
        time.Sleep(time.Second * 2)
    }
    

启动 2 个线程进行读写操作，写和读是不能并存的，因为都会带来数据竞争。

如果有个数组，线程 1 只访问 index0，线程 2 只访问 index2，那么线程 1 和线程 2
有并发冲突么？如果有这个冲突，意味着你访问任何内存都有冲突，整个地址空间其实就是个大数组。其实在数组这块，你访问的数据不属于同一个区域，哪怕它们隶属于同一个对象也不存在冲突。

字典有非安全问题，比如线程 1 去写数据可能会引发扩容操作，那么这时候另外线程正在遍历，指针发生变化了处理不了了。

### defaultdict 如何实现，是否要在 map 中创建 entry？

字典有 setdefault 方法，就是从字典里面读 key，如果存在直接返回 value，如果不存在先把 key 设为 100，然后返回
100。这种设计非常常见。

    
    
    func main() {
        m := make(map[string]int)
        v, ok := m["a"]
        if !ok {
            m["a"] = 0
        }
    }
    

如果返回时候没有找到 a，就在里面创建 a，虽然它的值是默认值。不创建的话 for 循环永远不会有 a 出现，但是创建了 a 会出现。

访问的数据虽然现在没有值，但是基于很典型的乐观缓存，接下来可能会被设置。就像 CPU
一样，当访问一个页，接下来最有可能连续访问后面一页，会提前缓存起来。当我们访问数据的时候很可能继续写，写进去接下来检查的时候，我们会知道接下来操作什么东西。这是两种不同的设计理念。

很多时候访问数据是加锁，处理数据解锁，持有锁的期间把数据加进去，和以后再去拿锁往里加不是一个概念了。任何时候并发编程涉及到锁时候都得小心。

### 字典无序遍历设计

对于字典来说比较诡异的东西，字典每次输出的顺序不一样。我们不能依赖于遍历字典 key 的顺序，同样的遍历进行增加和删除都会有问题。

迭代字典的顺序不属于语言规范，不能保证使用相同的迭代顺序。另外在迭代期间进行删除或者增加操作，不能保证会删除或者增加被合法读到。这其实和 hash
结构设计有关，其实是有意设计乱序的，早期还是有些规律的，每 8 个 keyvalue 形成一个桶，这 8 个原来能保证是一致的，后来有意变成乱序了。

其实归根结底通过这种方式解决几个问题，警告不要依赖顺序，这和哈希表设计数据结构实现原理有关系。不管是开放地址法还是链表法，并不能保证新增数据的位置，这跟他的具体
hash 算法有关系，对于 Go
来说，这种哈希算法是隐藏的并没有对外公开，不需要知道这些，因为如果依赖于内部实现，任何人都不希望你依赖对方内部实现。这样可以用来数据洗牌
shuffle，打乱它的次序。

    
    
    func main() {
        m := make(map[int]int)
    
        for i := 0; i < 10; i++ {
            m[i] = i
        }
        for k := range m {
            println(k)
        }
        for k := range m {
            println(k)
        }
    }
    

### 如何实现 orderdict？添加顺序，键值排序，如何删除？

添加顺序：有些时候希望添加和遍历保持顺序这样的需求。

字典说白了就是一个定位器，字典没有顺序的，就另外用一个有顺序的数据结构来保存。用数组保存 value，用字典保存 key
和数组的索引。添加从数组尾部添加返回索引号，把 key 和索引号保存到字典中。如果顺序遍历，数组可以存 key 和 value。删除把数组数据变成 0。

用数组实现顺序化存储，用字典实现定位器，字典从数据容器转变成定位器。

键值排序可能使用大小堆来实现，heap 就是大小堆，比较操作的时候是大于还是小于。也可以用切片实现排序，sort 库有现成的函数。

### 用 map 实现 cache 容器是否合理？LFU、LRU、TTL

我们实现缓存容器时候，字典不太够用，因为缓存有很多相关数据，例如 TTL 有生存周期 30s，LFU、LRU 最后保存 100M
空间，超出的话就会放弃其中的一部分。缓存是可丢失的，用 map 未必合理。Go 类似的库挺多的。

> <https://github.com/allegro/bigcache>

是用 map 实现的，是保证紧凑性比较好的缓存容器，有分片、最大尺寸等配置。hash 的 FNV 算法的好处是针对短字符串性能比较好。

> <https://github.com/golang/groupcache>

著名项目，作者最早实现很专业的 Memcache，后来开发 groupcache 用来替代 Memcache。自从 Redis 出来之后 Memcache
用的比较少，Memcache 和 Redis 不是一回事，Memcache 缓存的是 key-value 数据，Redis 大多数当 DB
用。设计真正意义上的缓存不是像 Redis
设计复杂的数据结构，而是快速检索、高效存储、持久化类似这样的东西。设计缓存需要考虑的是性能、内存使用率要非常合理、什么策略抛弃旧数据、数据是否压缩存储、是否持久化，避免
MongoDB 内存问题。

> <https://github.com/alecthomas/mph>

MPH 算是很有名的 hash 算法，它利用 MPH 实现只读的快速检索哈希表，对于海量数据像 300K 键、2GB
的数据进行快速检索。很多时候很多数据需要检索，比如 IP 数据库、敏感词过滤库。而且可以保存文件下次读出来。它对于只读的海量数据处理效率会很高。

### 设计相关数据结构 SET

有种数据结构叫集合，Go 里面没有。最简单的做法使用字典，只有key，value 是空结构体 `set :=
make(map[string]struct{})`。

### 使用 Bloom Filters 代替 map

很多时候用字典当作集合使用，字典做去重效率不是特别好。推荐做法用布隆过滤器。布隆过滤器创建足够大的位图，位图就是个字节数组，每个字节 8
个标记位，每个索引对应 1 个二进制标记位，如果判断某个 url 是否已经写过，用 3 种哈希算法，每种哈希算法都可以得到一个值，比如 1、7、9，把
1、7、9 标记为 1。

换句话说，下次判断这个 url 是否存在，要判断 3 个索引位上面数字全部标记为 1，只要 1 个不对肯定不存在。除非另外一个 url 和当前 url 的
3 种哈希得出来一模一样才会出现碰撞。

布隆过滤器存储效率非常高，1 个字节 8
个标记位，能处理很大数据量。运算效率非常高，二进制运算非常快。哈希算法可以选择多种，越多碰撞几率越小。这样比直接用字典处理效率高很多。它的缺陷有碰撞误操作。但是可以这样避免，用一个布隆过滤器预处理，如果能得到准确结果立即返回，不能的话后面可能向后端发起查询，这样布隆过滤器可以拦截
99% 的去重，它的效率非常的高。

有些时候使用一些手段实现预处理。这种预处理使用合适的数据结构，比如使用 Bloom Filters 代替 map。因为字典的存储效率很低的，比如创建 100
个空间只能存储 60
个，这是哈希表的数据结构决定的。第二，没法在二进制位上做标记。第三，布隆过滤器访问效率非常高。对于不同的应用选择不同的做法，我们会组合不同的数据结构。

### sync.Map

同步版本，并非取代 map+mutex/rwmuex：

  * 一次写，多次读；
  * 不同并发单元（goroutine）读取不相交键值项。

sync.Map 不是用来替代 map 加锁。sync.Map
的问题是，存储的键值对用接口实现，接口需要额外的开销，对垃圾回收压力很大，本身的内存模型效率不高，因为没有泛型用接口实现。

正常情况下，我们使用 map 加锁方式。它解决两种需求，在一次写多次读和不同并发单元操作的键值对不一样。

