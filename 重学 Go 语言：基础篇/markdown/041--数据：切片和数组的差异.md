
    //go:noinline
    //go:nosplit
    func test(x []int) {
        fmt.Println(x)
    }
    func main() {
        var a [3]int
        b := a[:]
        c := []int{1, 2, 3}
        d := make([]int, 0, 100)
        test(b)
    }
    

  * 切片可动态指定长度，预分配内存。
  * 传递时仅复制切片自身结构。

切片和数组对比，第一，复制的内容不一样，切片复制的是三个字段；第二，切片的语法相对来说比较灵活，例如可以指定预分配长度，可以用变量来表达。所以我们用切片是实现类似动态数组的功能，但是切片本身和动态数组没什么关系。

### 切片和数组的性能差异

切片和数组从语法访问上有些类似，实际上切片是间接的访问底层数组，所以它们之间存在一定的性能差异，这个性能差异不会很大。

    
    
    func array() [1024]int {
        var x [1024]int
    
        for i := 0; i < len(x); i++ {
            x[i] = i
        }
    
        return x
    }
    
    func slice() []int {
        x := make([]int, 0, 1024)
    
        for i := 0; i < cap(x); i++ {
            x = append(x, i)
        }
    
        return x
    }
    
    func slice2() []int {
        var x []int
        for i := 0; i < 1024; i++ {
            x = append(x, i)
        }
    
        return x
    }
    
    func BenchmarkArray(b *testing.B) {
        for i := 0; i < b.N; i++ {
            array()
        }
    }
    
    func BenchmarkSlice(b *testing.B) {
        for i := 0; i < b.N; i++ {
            slice()
        }
    }
    
    func BenchmarkSlice2(b *testing.B) {
        for i := 0; i < b.N; i++ {
            slice2()
        }
    }
    

性能差异：

    
    
    $ go test -v -bench . -benchmem slice_test.go
    
    
    
    BenchmarkArray       2000000           917 ns/op           0 B/op          0 allocs/op
    BenchmarkSlice       1000000          1182 ns/op        8192 B/op          1 allocs/op
    BenchmarkSlice2       500000          2335 ns/op       16376 B/op         11 allocs/op
    

数组就是分配一块内存，没有任何管理机制；切片就是两块内存，第一个是切片本身，第二个是切片管理的底层数组。返回切片的时候实际上是返回切片本身的内存，要么是切片本身内存的指针，要么是切片本身内存的复制块，底层数组的内存没法返回，必须从栈上逃逸到堆上，因为只返回切片本身，然后栈上栈帧要失效，切片本身可以拷贝到调用栈帧，底层数组必须从栈上分配到堆上。

所以切片另外很大的问题就是，每次至少操作一次底层数组堆内存分配，也有可能两次，把切片本身和底层数组都分配到堆上去，如果切片本身作为复制品返回，就保存在栈上。我们知道，堆上分配内存除了本身执行开销以外，还需要加上分配内存的开销垃圾回收的开销，这就是潜在的性能差异。

虽然我们代码看上去除了创建语句不一样以外，其他的操作看上去一模一样，但是这两者是存在性能差异的，除了分配内存垃圾回收开销之外，每次访问需要先读出指针，用指针找到底层数组，然后对底层数组进行读写，起码多了一次寻址过程。而我们对于数组的访问，直接是数组的指针加上偏移量就可以操作，没有二次寻址。不要小看寻址差异，如果数据被缓存到
L1-L3 cache 中还好点，如果没有缓存，我们必须从主存上去读取，要知道 CPU 从主存上读数据不是很快。

性能差异很大的原因是长度非常大，如果长度改小点，切片就会被编译器优化，对于小切片，一个方法操作并没有超过整个栈帧，那么编译器会尝试把它从切片退化成数组，这样的话属于一种编译器的优化策略。

    
    
    func testArray() {
        var data [10]byte
    
        for i := 0; i < len(data); i++ {
            data[i] = 100
        }
    }
    
    func testSlice() {
        data := make([]byte, 10)
    
        for i := 0; i < len(data); i++ {
            data[i] = 100
        }
    }
    
    func main() {
        testArray()
        testSlice()
    }
    

对比反汇编

    
    
    $ go build -gcflags "-l" -o test test2.go
    
    
    
    $ go tool objdump -s "main\.testArray" test
    
    
    
    TEXT main.testArray(SB)
      test2.go:3        0x4509b0        4883ec18        SUBQ $0x18, SP
      test2.go:3        0x4509b4        48896c2410      MOVQ BP, 0x10(SP)
      test2.go:3        0x4509b9        488d6c2410      LEAQ 0x10(SP), BP
      test2.go:4        0x4509be        48c744240600000000  MOVQ $0x0, 0x6(SP)
      test2.go:4        0x4509c7        48c744240800000000  MOVQ $0x0, 0x8(SP)
      test2.go:4        0x4509d0        31c0            XORL AX, AX
      test2.go:6        0x4509d2        eb08            JMP 0x4509dc
      test2.go:7        0x4509d4        c644040664      MOVB $0x64, 0x6(SP)(AX*1)
      test2.go:6        0x4509d9        48ffc0          INCQ AX
      test2.go:6        0x4509dc        4883f80a        CMPQ $0xa, AX
      test2.go:6        0x4509e0        7cf2            JL 0x4509d4
      test2.go:9        0x4509e2        488b6c2410      MOVQ 0x10(SP), BP
      test2.go:9        0x4509e7        4883c418        ADDQ $0x18, SP
      test2.go:9        0x4509eb        c3          RET
    
    
    
    $ go tool objdump -s "main\.testSlice" test
    
    
    
    TEXT main.testSlice(SB)
      test2.go:11        0x4509f0        4883ec18        SUBQ $0x18, SP
      test2.go:11        0x4509f4        48896c2410      MOVQ BP, 0x10(SP)
      test2.go:11        0x4509f9        488d6c2410      LEAQ 0x10(SP), BP
      test2.go:12        0x4509fe        48c744240600000000  MOVQ $0x0, 0x6(SP)
      test2.go:12        0x450a07        48c744240800000000  MOVQ $0x0, 0x8(SP)
      test2.go:12        0x450a10        31c0            XORL AX, AX
      test2.go:14        0x450a12        eb08            JMP 0x450a1c
      test2.go:15        0x450a14        c644040664      MOVB $0x64, 0x6(SP)(AX*1)
      test2.go:14        0x450a19        48ffc0          INCQ AX
      test2.go:14        0x450a1c        4883f80a        CMPQ $0xa, AX
      test2.go:14        0x450a20        7cf2            JL 0x450a14
      test2.go:17        0x450a22        488b6c2410      MOVQ 0x10(SP), BP
      test2.go:17        0x450a27        4883c418        ADDQ $0x18, SP
      test2.go:17        0x450a2b        c3          RET
    

小切片没有任何 make 的操作，所有的操作完全是在栈上进行的。大切片看到调用 make 函数语法糖被翻译成具体的函数
runtime.makeslice()
调用，来完成多次的内存调用和初始化操作。很显然容量比较大的时候，编译器并没有对它进行优化，而是按照标准的在堆上分配内存的操作；但是如果是非常小的切片，它实际上会退化成在栈上操作。退化成栈上操作并不是意味着完全退化成数组了，因为它依然会保留像长度、容量，只不过不在堆上分配，完全演变成在栈上数据操作，看上去和数组没有什么区别。

所以当我们对比两个数据结构的时候，对比方式采样方式需要搞清楚为什么上面有很大的性能差异，而下面的性能差异几乎没有，也没有任何堆分配。这时候需要知道编译器在当中承担什么角色，编译器是否把切片操作优化成普通数组操作。如果优化过后以后那么对于小切片的测试就变得没有意义了，也就是说对于小切片的测试用例来说没有任何意义，因为我们测试的并不是切片，切片并没有体现出切片本身的功能。

所以我们学习一个新的语言的时候，学习数据结构的时候，测试性能的时候最好的方式是逐级增加测试容量。比如以切片为例，我们测试范围
10、1000、100000、1000000，测试不同的级别然后看看它们的性能差异有多大；同时要跟踪编译器怎么处理，编译器是否在不同的级别对它不同的优化，它优化的阈值门槛到底有多大，这些关乎到你学习一门语言对数据结构理解多少，因为这些并不能说看
makeslice 源码所知道的。看源码的时候只是标准操作，显然编译器优化时根本没有调用 makeslice
操作，这样除了看源码以外，还得尝试看编译器是否调用哪些源码。

大部分语言内置类型，比如由编译器或者运行时支持的内置类型，它都会尝试性能优化操作，因为内置类型对性能要求往往比较苛刻，使用频率非常高。那么对性能要求苛刻情况下可以做两件事情，第一，尽可能地在栈上操作，第二，尽可能使用寄存器。而我们普通有库的方式提供函数的时候是享受不到这些便利，可能享受只是简单的函数内联，很难去做到像内置类型级别的优化，大部分语言的内置类型可以享受这样一种待遇。

以后学习新语言的时候，你测试一种数据结构性能时，一定要知道采样多大是合适的，测试多大的范围，编译器在其中是否充当误导我们的作用。不能用简单的小切片和数组对比就说它们的性能差不多，很显然小切片测试没有任何含义，因为根本没有按照标准切片方式来操作。

我们现在知道切片和数组的差异，而且也知道切片和数组访问时候一些性能差异，其中最可怕的在于堆上的内存分配。因为在堆上分配内存的时候就需要垃圾回收进行干预，当我们访问压力比较大的时候，因为使用了切片而没有使用数组，每秒钟可能在堆上产生成千上万个需要回收的对象，这就是很大的负担。

