### 字符串内部实现

看 runtime 源码找字符串的定义：

    
    
    grep -n "type string" *
    
    
    
    type stringStruct struct {
        str unsafe.Pointer
        len int
    }
    

uintptr 与 unsafe.Pointer 区别是，uintptr 保存的是整数，并不能保证目标不会被垃圾回收，不能保证它持有对象的引用。

uint 与 int 区别，跟汇编指令优化有关系，int
类型是汇编处理默认类型，汇编对于数字是有类型的，在内核层面以性能为优先，并不在乎业务实现。暴露给用户的是公开接口，内部性能优先。不同类型 CPU
架构处理方式不一样，所以会选择默认类型。

### Go 字符串和 C char* 的差异

C 语言中 *char 代表字符串，一个字节数组加个一个结束符。Go
语言字符串底层是字节数组，字节数组保存数据但没有结束信息。它单独会构建一个头信息，头信息开始位置是个指针，指向字节数组起始位置，后面用一个长度表达有多长。所以说存在很大的差别：C
语言字符串是连续的内存块。Go
语言里字符串很显然是个复合结构，由两块内存组成的：一个是字符串头信息，一个是数据体。那么当我们复制字符串的时候，我们到底复制的是哪部分？

![enter image description
here](https://images.gitbook.cn/b4c41380-1f38-11ea-b66b-1b78f0422b99)

Go 语言判断字符串的长度，sizeof
处理的是返回类型的长度，类型长度都是固定的，大多时候这种复合结构返回类型长度只有头信息。这里需要注意，返回实例长度和返回类型的长度不是一回事。

类型长度和实例长度例子：

    
    
    func main() {
        s := "abcdefg"
        println(unsafe.Sizeof(s), len(s)) //16 7
    }
    

unsafe.Sizeof(s) 返回的是字符串类型的长度，len(s) 返回的是实例的长度。

所以 Go 语言中字符串是指针和长度两个字段构成，长度是 16 字节。至于指针指向什么地方，是实例的属性和类型无关，类型里面只看到一个指针。

查看内部结构：

    
    
    $ go build -o test -gcflags "-N -l" test.go
    $ gdb test
    $ l
    $ b 9
    $ r
    $ ptype s #输出字符串类型信息，看到字符串标准类型是由一个指针加上一个整数组成的。至于指针指向什么地方是实例的内容。
    $ x/2xg &s #查看 s 的实例信息，第一块是指针，第二块是长度，字符串地址是在栈上面
    $ x/s 0x0000000000472288 #这个是底层字节数组
    $ info files #对比地址指向 rodata 里，字面量 abcdefg 保存在rodata里。
    $ p/x $rsp
    $ p/x &s #字符串地址是在栈上面
    

字符串标准结构是指针和长度，指针指向字节数组，字节数组在 .rodata 段里。那么我们动态构建一个字符串信息，字节数组会不会在 .rodata 段里？

    
    
    func main() {
        s := strings.Repeat("a", 3)
        println(unsafe.Sizeof(s), len(s))
    }
    
    
    
    $ go build -o test -gcflags "-N -l" test.go
    $ gdb test
    $ l
    $ b 10
    $ r
    $ p/x &s #字符串对象是在堆上
    $ p/x $rsp #用 rsp 对比
    $ x/2xg &s #查看字符串内容，第一块是地址不属于 rodata，是堆的地址，第二块是长度。
    

需要注意的是，预编译的地址基本上都是短地址。

我们这时观察到，动态构建的字符串是分配在堆上的，为什么分配在堆上而不分配在栈上？这个字符串是由 strings.Repeat
函数生成的，函数返回局部变量的时候有两种可能：第一种原因是，这个函数被内联了直接在当前栈桢分配，如果不能内联返回一个失效栈桢里面的数据是不安全的，只能把这个数据扔到堆上；第二种原因是，很多语言对于字符串特殊处理，在大部分语言字符串都是一种很特殊的数据类型。

视频演示：

[![asciicast](https://asciinema.org/a/j9DUgxtWf2HAcNJvCX8ApzrfU.png)](https://asciinema.org/a/j9DUgxtWf2HAcNJvCX8ApzrfU)

### 不可变类型

早期比如像 C 语言中没有像字符串这种东西，实际上把它就当作一个字节数组，只不过字符串比较特殊的地方在于这里面的字符都可以打印的。因为我们知道 ASCII
字符其实可以分为控制符、可以被打印机打印出来的还有一些不可以打印的。我们通常情况下字符串处理的时候这里面存的都是可打印字符，人类可以阅读的。实际上在早期没有专门字符串这种东西。

我们使用字符串量比较大，频繁复制可能导致性能问题和安全问题。

在很多语言里，字符串都有几个特征，其中一个重要特征是，字符串都是不可变类型。即一旦生成了字符串以后，就不能对这个字符串进行修改，修改的前提是，需要将其转换或者重新拼一个新的字符串出来。很多语言都有这样的限制，为什么要把字符串实现成不可变类型，我们知道像
Python、Go、Java、C# 字符串是不可变的。下面来看看字符串实现成不可变类型的原因。

#### 池化共享

任何语言里面的优化基本原则，都是基于一定统计的基础。

字符串类型是我们日常工作当中使用频率非常高的数据类型，这种类型的特点是不定长的，对于字符串处理往往非常复杂。如果由你来设计这种数据结构如何实现呢？

核心问题是需要提高它的处理效率，我们会尽可能地把它缓存起来。比如说多个人使用同一个字符串的时候，或者字符串在不同函数中传递的时候，希望要么复制、要么不可变。字符串被大量引用的情况下最好的方式是它是数据安全的、不可变的。这样的好处是，不管引用多少次，我只需要保留一份副本，当对其进行修改的时候，就创建一个新的。

所以我们可以把它进行池化操作，尤其像动态语言 Python
中所有的名字空间里面都是用字符串来实现的。这些字符串会被大量的使用，如果每次都创建新的对象，那内存管理就什么都不用干了，全变成零零碎碎的了。所以对字符串做池化处理，来减少相同字符串在内存当中的副本数量。

#### map[hashcode]

假如我们自己写个算法，比较两个字符串是否相等，什么方式最快？最简单的做法直接比较
hashcode，当我们每个字符串生成了以后，这个字符串如果是不可变的情况下，生成完了之后立即计算它的 hashcode，把 hashcode
作为这个字符串对象的一部分。

那么接下来只要判断 hashcode 是否相同，如果相同也有可能不一样因为有哈希碰撞问题。所以在很多语言里，每个字符串都会生成后立即把 hashcode
计算出来，因为这两个 hashcode 不同的话这两个字符串肯定不一样，如果 hashcode
相同，再去比较它们字符这样来避免哈希碰撞问题。前三个条件可以减少我们低效率操作。这也是让字符串变成不可变类型的原因。

#### 安全性

有些 DSL 语言考虑安全性因素，而绝大部分编程语言都没有这样考虑。比如我们调用 SQL 操作，当我们把 select
语句扔进去的时候，如果这个字符串类型是只读的，可以避免这个字符串对象被修改，因为一旦字符串被修改了以后，它和原来的字符串就不属于同一块，那么可以验证字符串，在中途是否变更过来避免一些非安全的注入。

有些像 SQL 引擎它会做这样的操作，它会验证 SQL
语句是否被修改过，最好的办法是这个字符串对象是只读的。因为这块内存在只读的情况下，这块内存访问会触发一些安全机制不可写，肯定是没有办法修改，也没有办法注入非安全的东西，因为很多时候它是支持插件机制的。但这种东西比较少见，只是在一些引擎或者
DSL 里面见过。

### 不可以取元素地址

我们可以通过索引号去读没有问题，任何时候取地址意味着可以修改，字符串放到 rodata 取地址以后根本没有办法修改。读和写在编译器层面是两回事。

在内部用黑盒方式来实现功能，这些功能按照需求分为几块。我们知道任何代码都可以分为 IO 密集型和 CPU 密集型，第一块是 IO 类型的，第二块 CPU
类型的，最好在写程序时候把这两样东西分开，因为 CPU 密集型代码的写法和 IO 密集型的写法是不一样的：IO 密集型对于性能要求优化放松一点，因为优化再好
IO 跟不上没用。

而 CPU 密集型要求比较高，我们举个简单例子，比如要写个 HTML 编码解密操作，在内存中对数据块处理就属于 CPU
密集型，所以这一块它的权重是性能优先；而 IO 块可以体现接口，对外公开阅读性做得更好一点。

IO 块可能用 Python 来写，因为基于维护的角度，它的 IO 等待时间超出虚拟机执行的时间。但是 CPU 密集型性能要求很高，Python
跟不上。我们可以用 C 和 Go 来写 Python 扩展，因为这种语言不是虚拟机这种，对内存分配效率比较高。

这给我们的启示是，平时写程序包括重构时，你得区分出来哪些是 IO 密集型，哪些是 CPU 密集型，你把 CPU 密集型代码单独摘出来打包到函数内部或者是一个
model 内部，这段代码最好做出类似的黑匣子，把它修改权限控制在极少数手中，目的是为了提高性能。CPU
密集型代码一定要控制它的量，因为这东西一旦扩散到整个项目里去，到最后很容易失控。

所以我们很多时候把 CPU 密集型代码从标准包里拿出来，作为第三方扩展包放进来。我们实现两个版本，因为时间原因第一个版本用 Python
写，写好可以立马工作，有时间用 Go 或者 C 重构另外一个版本，写好以后替换掉。

用第三方扩展包的好处是从主项目中剥离出去成为一个黑匣子，这样对于代码来说，到一定程度它冻结的时间和时机好控制。对于大多数程序来说，CPU
密集型的代码往往一旦写好之后，很长时间不会再动它，对于很多逻辑有关的代码冻结很难，会随着业务修改而修改。

所以这就会造成一些问题，如果 CPU 密集型的代码分散到业务逻辑内部，那么一来，对业务逻辑的阅读维护造成麻烦，CPU
密集型的代码优化时策略没法统一，需要搞清楚 CPU 密集型和 IO 密集型是有区别的。最终最好的方式是独立成第三方包，让专门的人处理。

这也是很常见的重构技巧，有一些维度，这里是 CPU 和 IO 维度，还有复杂度比较高的，比如说加密函数对复杂度要求比较高，可以先完成 DES 加密，因为交换
key 时候安全性比较差；然后再基于 RSA+3DES 加上 key 管理，实现一个复杂版本把安全性提高。对于项目来说算法是不能暴露出去的。

