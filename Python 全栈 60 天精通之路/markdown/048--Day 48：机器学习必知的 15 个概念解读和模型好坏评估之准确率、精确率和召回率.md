要想精确地入门机器学习，有一些概念是我们要准确掌握的，这通常是第一步，走好这一步能为未来构建机器学习大厦打下坚实的基础，同时对理解基于这些概念的理论和算法提供必不可少的帮助。

今天这节课我们结合实例，快速理解机器学习中最主要的一些概念。

### 数据集（data set）

记录的集合，假如我们用 3 个特征，分别为性别、头衔、有无同行人来预测泰坦尼克号上船员的生死，并且拥有基于这 3 个特征的 892
条记录，其中一条记录的取值为：

    
    
    性别=female，头衔=Mrs，有无同行人=True
    

如果记录到 .csv 文件中，这个文件的结构可以记为 `train[892][3]`，这样一个二维数组，行数为 892，列数为 3。

### 示例（instance）

每条记录是关于一个事件或对象的描述，也称为样本，比如以上其中一条记录：

    
    
    性别=female，头衔=Mrs，有无同行人=True
    

可看做是一个实例。

### 属性（attribute）

反映事件或对象在某方面的表现或性质的事项，例如色泽、根蒂、响声等，又称为特征 feature。如下红框标出的便是 3 个特征：

![](https://images.gitbook.cn/db9b2130-db8d-11ea-9d4f-fd9909d9aad4)

属性上的取值如下红框所示，称为特征的取值。

![](https://images.gitbook.cn/ed080960-db8d-11ea-98dc-69751c28f996)

### 样本空间（sample space）

样本空间又称为属性空间，attribute space，或输入空间。

它可以理解为训练数据中实际出现的所有属性值构成的集合空间，如果仅考察数据集中的 Genre 列，Genre 列的样本空间为 27，因为 Genre 列一共有
27 种不同取值。

![](https://images.gitbook.cn/fd8a1c60-db8d-11ea-856c-1b0ca96fbf95)

和它有相似的一个概念叫做假设空间（hypothetical space），它是理论上的所有可能属性值构成的集合空间。

如果我们在购买某个股票时假定只考虑两个主要特征：股票经纪公司等级和股票最近 3 个月的涨幅情况，进而判断是否购买某只股票。

假定股票经纪公司等级取值为 4 种：A 等、B 等、C 等，还要考虑到一种特殊取值 `*`，这个特征对于是否买这只股票是无关紧要的。

股票最近 3 个月的涨幅情况取值为 3 种：涨、降、`*`（同上面解释）。

那么根据这 2 个特征和特征取值，并且股票的标签 y 取值为买或不买，因此理论上可以得到一个由 12 种不同取值组成的假设空间：$4 \times 3 =
12 $。

### 特征向量（feature vector）

假如将以下 11 个属性（注意：Survived 列为标签列，不算在内）作为 11 个坐标维度，其值就是一个坐标向量，被称为一个特征向量，记为 $(x_1,
x_2, ..., x\\_11)$。

![](https://images.gitbook.cn/10e8c270-db8e-11ea-8b08-a305d0150119)

### 标记（label）

关于样本的标签信息，比如判断船员是否能被获救，那么这位船员便会拥有标记示例，一般用 $(X_i , y_i) $ 表示第 $i$ 个样例，其中 $y_i$
是样本 $X_i$ 的标记。如下红框对应列就是样本的标记 $y_i$。

![](https://images.gitbook.cn/286ad370-db8e-11ea-9f8d-6db671417c55)

### 维数（dimensionality）

每个样本包含的属性个数，泰坦尼克号源数据集共有 11 个特征如上图所示，那么它的维数便是
11，这是机器学习中需要理解的重要概念，同时要注意和线代中维数概念加以区分。

如下影评数据集的维数为 12：

![](https://images.gitbook.cn/39c8ee90-db8e-11ea-8d16-77936a705f77)

### 学习（learning）

从数据中学得模型的过程，又称为训练（training）。正如上文所示，892 条船员数据集，根据它的 11
个特征和每条特征对应的标记，经过计算最后得到了一个 $f$，通过这个 $f$ 我们能预测第 893 位船员是否获救，这个过程被称为学习。

### 训练数据 （training data）

训练过程中使用的数据，其中每个样本称为一个训练样本（training sample），训练样本组成的集合称为训练集（training
set）。如下泰坦尼克号训练数据集的文件名称：

![](https://images.gitbook.cn/4ac90b30-db8e-11ea-bd41-fdeec52ccca1)

共有 892 行，除去表头共有 891 个样本组成的训练数据，Survived 列为标签。

![](https://images.gitbook.cn/5b79a840-db8e-11ea-856c-1b0ca96fbf95)

通过这些训练数据学习，最终得出一个 $f$，也就是我们学到的模型。与之相对应的是测试数据，测试数据中缺少标签列。例如，泰坦尼克号测试数据集中没有
Survived 列，是一个 418 行 11 列的数据集。

训练数据主要用于训练模型，训练后得到的模型对训练数据是可见的，那么再基于训练数据评估模型的好坏就完全失去意义，因此我们需要找到一些模型未知的新数据，以此来评估模型才具有价值，我们称这部分数据为测试数据。

通常训练数据占到整个数据集的 80%，测试数据占 20%，如下所示：

![](https://images.gitbook.cn/71808af0-db8e-11ea-9f8d-6db671417c55)

基于训练数据和测试数据模式的机器学习流程，主要就是先在训练数据集上得到一个模型，然后再在测试数据集上评估模型，根据在测试数据集上获得的效果调整模型，然后再训练，重复迭代。从中选出在测试数据集上表现最好的模型。

![](https://images.gitbook.cn/847a0690-db8e-11ea-9369-b5210af59199)

还有一种更加优秀的训练模式，就是在训练数据集上再拿出一部分数据作为验证集，这种模式就更加避免了模型对测试数据集地可见性，所以能更好的评估我们得到的模型。

### 回归（regression）

如果预测的可能取值不是有限个，例如预测商品在未来 14 天的销量，理论上销量可取值为不小于 0 的任意整数值，如下表格是要预测第一列商品在未来 14
天销量的，默认都为 0，所以需要根据在训练集上得到模型预测这些商品的销量。

![](https://images.gitbook.cn/956d03d0-db8e-11ea-9f8d-6db671417c55)

或者是预测今年某地大樱桃的甜度，连续的任意多种可能值，根据今年的雨水量、光照情况等，这种预测称为回归。

回归任务通过学习带标签的数据，得到 $f$。在预测时输入 $X_m$，带入到 $f$ 中，得到 $y_m$。

### 分类（classification）

如果要预测的是取值有限的离散值，信用交易是否存在欺诈，邮件是否为垃圾邮件，船员是否能获救等等，这些类学习任务被称为分类。

如果分类的结果为两类，又称此分类为二分类，通常称其中一个为正类（positive class），另一个为反类（negative class）。

### 聚类（clustering）

整个数据集都不带标签，但是数据集本身的分布具有一定规律。根据某些特征和聚类算法，可以将训练中的数据分成若干组，自动形成几簇，这些簇可能对应一些潜在的概念。

比如 A 簇中的用户群体都喜欢喜剧电影，或者都信仰某种文化等等这些概念都是我们事先不知道的。

### 有监督学习（supervised learning）

如果数据集是带标签的数据，则成为有监督学习，比如泰坦尼克号训练数据集学习任务便是有监督学习。

### 无监督学习（unsupervised learning)

无监督学习是指在无标签数据上的学习过程，常见的聚类任务便是无监督学习，使用聚类算法或神经网络模型最终输出一些潜在的概念。

当然世上很少是非红即白的事，有时给定的数据集中有的含有 $y$，有的缺失 $y$，基于此类数据集的学习问题被称为半监督学习任务。

### 泛化能力

泛化能力（generalization）是指学到的模型适用于新样本的能力，关乎最后的预测精度。

举个例子来说明什么是泛化能力。

>
> 上学那回小明爱动脑筋，老师讲的题目不光会做，还能举一反三；小红学习很努力，上课认真听讲，老师布置的作业完成的非常好，但是这仅限于老师讲过的知识范畴内，小红不怎么喜欢思考，主要是填鸭式地学习知识，老师讲什么她就学什么，并且对老师教授的知识总会一遍又一遍的反复温习。
>
> 不过一次数学竞赛，考的题目基本不是以前老师上课讲过的，考试的结果，小明 90，小红 50。
>
> 小明的变通能力更强，能根据老师所讲的东西变通解题。但是，小红这方面能力很弱，虽然对老师讲过的知识掌握得很好，但是当题目样式新颖后，她就会答错很多题。

引起泛化能力不足的一个重要原因是过拟合，过拟合导致在测试集上变现非常好，但是在新来的数据集上表现非常差。在以后的学习过程中 **过拟合**
将会是一个老生常谈的问题。

### 模型好快评价方法

以上就是一些机器学习的基本概念，下面介绍评价机器学习模型好坏的重要方法。判断一个分类模块好坏的标准至关重要，问题是采用何种判断方法。

#### **准确率**

表面上看这是一个简单的问题，如果分类的 **准确率** 越高，就断言分类模型越好。

据此评价方法，对于二分类问题，评价分类算法准确率的计算公式为：

$$Accuracy = \frac {TP + TN} {TP + TN + FP + FN}$$

其中，P 全称 Positive，N 全称 Negative，T 全称 True，表示预测正确；F 全称 False，表示预测错误。

如果正负样本个数较为均衡，使用以上评价公式是没有问题的。

实际中，我们要分类的问题大都满足正负样本个数均衡吗？

如果一下能举出很多反例，大概率就可以说正负样本不均衡的情况还是很多。银行卡信贷欺诈判断、交通违规判断、考试作弊判断、垃圾邮件检测、涉黄电影判断、恶性肿瘤检测……

并且下意识告诉我们，这些分类任务的数据集中正负样本个数往往是不均衡的，欺诈的交易总归占据少数，交通违规、考试作弊大概率也如此。

如果正负样本个数比例真是这样不均衡，使用以上公式评价问题就出现了。比如 100 个肿瘤检测报告中，只有 1
个是正类别（确定为肿瘤），对于这类数据集，我们只要写一行代码，预测所有都为负类别（即确定不是肿瘤），则：

$$Accuracy = \frac {0 + 99} {0 + 99 + 0 + 1} = 99\%$$

你看，我们什么都没做，仅靠投机取巧，模型预测的准确率就达到 99%，这太匪夷所思！

#### **精确率 + 召回率**

显然，仅仅使用准确率评价模型好坏，失败了。原因在于正负样本个数的不均衡，导致评价出现问题。

所以，需要设计出更加科学健全的评价指标。于是就有了 **精确率 + 召回率** 的评价体系。

其中， **精确率** 的计算公式为：

$$ Precision = \frac{TP}{TP + FP} $$

公式意义：被预测为正类别的样本中，确实为正类别的比率。

召回率的计算公式为：

$$ Recall = \frac{TP}{TP + FN} $$

公式意义：在所有正类别样本中，能够正确的识别为正类别的比率。

按照此评价体系，如果还是纯碎靠猜测，即预测 100 个肿瘤全为负类别，则：

$$ Precision = \frac{0}{0 + 0} $$

这种极端情况，我们没有预测出正样本，所以精确率公式失去意义。下面考察召回率：

$$ Recall = \frac{0}{0 + 1} = 0 $$

等于 0，所以判定纯碎靠猜是不可取的，所以 **精确率 + 召回率** 的评价体系更优于仅凭准确率的方法。

### 小结

今天一起学习机器学习相关的基本概念，包括：数据集、样本、属性、样本空间、特征向量、标记、维数、训练数据、回归、分类、聚类、有监督学习、无监督学习、泛化能力。

最后介绍重要的模型评估方法，精确率 + 召回率更加常用。

希望大家能理解这些基本概念，为接下来的机器学习之路打下坚实基础。

