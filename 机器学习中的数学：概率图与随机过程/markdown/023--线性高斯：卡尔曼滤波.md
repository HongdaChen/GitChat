### 卡尔曼滤波中的线性与高斯

这一讲我们来介绍卡尔曼滤波器，首先还是开局一张图，重温一下卡尔曼滤波器的结构：

![图1 卡尔曼滤波器结构](https://images.gitbook.cn/ac7f9c90-8e9f-11ea-ac32-8b276c4e4423)

在前面我们介绍过，除了拥有齐次马尔科夫假设和观测独立性假设两个特性之外，卡尔曼滤波器还满足 $Z_t$ 和 $Z_{t-1}$ 之间以及 $X_t$ 和
$Z_t$ 之间的两组线性关系：

$$z_t=Az_{t-1}+B+\epsilon$$

$$x_t=Cz_t+D+\delta$$

这里 $A$、$B$、$C$、$D$ 是线性系数，而 $\epsilon$ 和 $\delta$ 则是两个满足均值为 0 的高斯分布的随机变量，我们记作：

$$\epsilon\sim N(0,Q), \delta\sim N(0,R)$$

而我们在前面还介绍过，卡尔曼滤波器中，无论是隐含变量 $Z$ 还是观测变量
$X$，都是服从高斯分布的，具体的分布形式，其实我们从上面的一组线性关系表达式中通过变化，找出这个规律：

$$p(z_{t}|z_{t-1})=N(Az_{t-1}+B,Q)$$

$$p(x_{t}|z_{t})=N(Cz_{t}+D,R)$$

对于模型的第一个变量，也就是隐变量 $z_1$，我们直接令它服从一个高斯分布：

$$p(z_1)=N(\mu_1,\Sigma_1)$$

这时候，整个卡尔曼滤波器的模型我们就描述清楚了，它的参数为：

$$\theta=(A,B,C,D,Q,R,\mu_1,\Sigma_1)$$

在模型描述清楚后，我们重点关注的是卡尔曼滤波器中的滤波问题，也就是求取概率 $p(z_t|x_1,x_2,x_3,...,x_t)$ 的核心思路。

### 滤波问题的解决思路

我们需要清楚一点的是，卡尔曼滤波器是动态图模型，模型中蕴含着一条时间主轴，按照时间的推演顺序，我们是依次顺序的观察到观测变量
$x_1,x_2,x_3,...,x_T$，换句话说，在观察到 $x_t$ 之前，我们将先观察到 $x_{t-1}$，那么思路就来了，我们不妨去建立
$p(z_t|x_1,x_2,x_3,...,x_t)$ 和 $p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})$
这前后相邻两个时间节点的滤波表达式之间的递推关系，关系建立了之后，我们就能从 $p(z_1|x_1)$ 一路平推到
$p(z_t|x_1,x_2,x_3,...,x_t)$。

下面我们开始。

首先按照贝叶斯公式来一道转换：

$$p(z_t|x_1,x_2,x_3,...,x_t)=\frac{p(x_1,x_2,x_3,...,x_t,z_t)}{p(x_1,x_2,x_3,...,x_t)}$$

因为 $p(x_1,x_2,x_3,...,x_t)$ 描述的是这一组观测变量的概率，因此是一个常数，所以就转换为如下的正比关系：

$$p(z_t|x_1,x_2,x_3,...,x_t)\propto p(x_1,x_2,x_3,...,x_t,z_t)$$

再来一次贝叶斯定理展开：

$p(x_1,x_2,x_3,...,x_t,z_t)$

$=p(x_t|x_1,x_2,x_3,...,x_{t-1},z_t)p(x_1,x_2,x_3,...,x_{t-1},z_t)$

$=p(x_t|z_t)p(x_1,x_2,x_3,...,x_{t-1},z_t)$

最后一步化简很简单，就是依据模型的观测独立性假设，$x_t$ 的取值只与 $z_t$ 有关。

紧接着继续按贝叶斯公式展开：

$p(x_1,x_2,x_3,...,x_t,z_t)$

$=p(x_t|z_t)p(x_1,x_2,x_3,...,x_{t-1},z_t)$

$=p(x_t|z_t)p(z_t|x_1,x_2,x_3,...,x_{t-1})p(x_1,x_2,x_3,...,x_{t-1})$

这最后一步公式中，其实蕴含了两个要点：

  * 第一，$p(z_t|x_1,x_2,x_3,...,x_{t-1})$ 是一个预测问题；
  * 第二，$p(x_1,x_2,x_3,...,x_{t-1})$ 又是一个关于观测变量的概率，它是一个常数，可以用正比于的关系替代掉。

因此就有了：

$$p(x_1,x_2,x_3,...,x_t,z_t)\propto p(x_t|z_t)p(z_t|x_1,x_2,x_3,...,x_{t-1})$$

那么这最终一路下来就有：

$$p(z_t|x_1,x_2,x_3,...,x_t)\propto p(x_1,x_2,x_3,...,x_t,z_t)$$

$$ \propto p(x_t|z_t)p(z_t|x_1,x_2,x_3,...,x_{t-1})$$

下来我们看一下这个预测的概率如何进一步化简：

$p(z_t|x_1,x_2,x_3,...,x_{t-1})$

$=\int_{z_{t-1}}p(z_t,z_{t-1}|x_1,x_2,x_3,...,x_{t-1})dz_{t-1}$

$=\int_{z_{t-1}}p(z_t|z_{t-1},x_1,x_2,x_3,...,x_{t-1})p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})dz_{t-1}$

$=\int_{z_{t-1}}p(z_t|z_{t-1})p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})dz_{t-1}$

现在是不是突然有了豁然开朗的感觉，这个式子中也包含了两个含义明显的式子：

  * 一个是通过齐次马尔科夫假设化简而得来的概率 $p(z_t|z_{t-1})$
  * 另一个是 $t-1$ 时刻的滤波表达式：$p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})$

这两个等式，在递推的大背景下都是已知的。

好了，到目前为止其实整个递推的过程我们就全都理出来了，这里结合下面两个式子来，我们来汇总一下全过程。

### 滤波过程中的 predict 和 update 步

在递推的过程中，在 $t-1$ 时刻，我们总是先利用 $t-1$ 时刻的滤波结果，在 $t-1$ 时刻的观测序列
$x_1,x_2,x_3,...,x_{t-1}$ 的基础上，去预测下一时刻 $t$ 的状态 $z_t$ 的概率，这一步，我们称之为 **predict
步** 过程：

$p(z_t|x_1,x_2,x_3,...,x_{t-1})$

$=\int_{z_{t-1}}p(z_t|z_{t-1})p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})dz_{t-1}$

拿到了 $t-1$ 时刻对 $t$ 时刻状态的预测之后，我们进入$t$时刻，此时，我们新增了 $t$ 时刻的观测值 $x_t$，我们通过它来对 $t-1$
时刻的预测进行修正，也就是去修正隐变量 $z_t$ 概率，因此这一步也叫作 **update 步** 过程：

$$p(z_t|x_1,x_2,x_3,...,x_t)\propto p(x_t|z_t)p(z_t|x_1,x_2,x_3,...,x_{t-1})$$

那么再直白一点，我们从 $t=1$ 这一步来演示这个过程：

$t=1$ 时刻：

  * **update** 步：求 $p(z_1|x_1)$
  * **predict** 步：求 $p(z_2|x_1)$

$t=2$ 时刻：

  * **update** 步：求 $p(z_2|x_2)$
  * **predict** 步：求 $p(z_3|x_2)$

然后不断地 $t=3,t=4,...,t=n-1,t=n$ 进行迭代。

$t=1$ 的启动 **update** 步，$p(z_1|x_1)\propto p(x_1|z_1)p(z_1)$，其中隐状态 $z_1$
会是一个提前给定的正态分布。

### 利用正态分布特性得到解析结果

最后一个问题来了， **predict** 和 **update**
的两步骤中都是这么复杂的运算形式，我们这一步一步地该如何求解呢？不用害怕，这里就要用到正态分布的有关性质了。

因为卡尔曼滤波中有个重要的假设，那就是我们前面讲的三个高斯分布特性：

$$p(z_{t}|z_{t-1})=N(Az_{t-1}+B,Q)$$

$$p(x_{t}|z_{t})=N(Cz_{t}+D,R)$$

$$p(z_1)=N(\mu_1,\Sigma_1)$$

而我们知道，高斯分布有一个非常好的性质，那就是高斯分布的联合概率、边缘概率和条件概率的结果仍然是高斯分布。

从 $t=1$ 时刻开始我们看看。

**update 步骤：**

$$p(z_1|x_1)\propto p(x_1|z_1)p(z_1)$$ 这里面，$p(x_1|z_1)$ 和 $p(z_1)$
都服从正态分布，它们联合后的乘积 $p(z_1|x_1)$ 也服从正态分布。

**predict 步骤：**

$$p(z_2|x_1)=\int_{z_{1}}p(z_2|z_{1})p(z_{1}|x_1)dz_{1}$$

这里 $p(z_1|x_1)$ 和 $p(z_2|z_1)$ 都服从正态分布，因此联合概率 $p(z_2|z_{1})p(z_{1}|x_1)$
也是高斯分布，它的边缘概率 $p(z_2|x_1)=\int_{z_{1}}p(z_2|z_{1})p(z_{1}|x_1)dz_{1}$ 也服从高斯分布。

由此一般化，在推导的过程中，$t-1$ 时刻的 **predict** 步：

$p(z_t|x_1,x_2,x_3,...,x_{t-1})$

$=\int_{z_{t-1}}p(z_t|z_{t-1})p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})dz_{t-1}$

$p(z_t|z_{t-1})$ 和 $p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})$
都服从高斯分布，二者先联合后求边缘概率后得到的概率结果 $p(z_t|x_1,x_2,x_3,...,x_{t-1})$ 同样也服从高斯分布。

那么，紧接着进入到下一时刻 $t$ 的 **update** 步：

$$p(z_t|x_1,x_2,x_3,...,x_t)\propto p(x_t|z_t)p(z_t|x_1,x_2,x_3,...,x_{t-1})$$

$p(z_t|x_1,x_2,x_3,...,x_t)$ 和 $p(x_t|z_t)p(z_t|x_1,x_2,x_3,...,x_{t-1})$
都是服从高斯分布的，二者的联合概率归一化之后，即概率 $p(z_t|x_1,x_2,x_3,...,x_t)$ 同样也是服从高斯分布。

因此卡尔曼滤波每一轮的 **predict** 步和 **update** 步都可以得到解析解，而且都是服从高斯分布的。

那么，具体结果是多少，我们可以看下面一组高斯分布性质的公式。

假定 $p(x)$ 和 $p(y|x)$ 都服从高斯分布，且随机变量 $y$ 和 $x$ 满足带噪声的线性关系，它们服从的正态分布记作：

$$p(x)=N(X|\mu,\Lambda^{-1})$$

$$p(y|x)=N(y|Ax+b,L^{-1})$$

高斯的性质定理中直接给出了 $p(y)$ 和 $y(x|y)$ 两个概率的表达式，看上去确实有点复杂：

$$p(y)=\int_x p(x)p(y|x)dx\Rightarrow p(y)=N(y|A\mu+b,
L^{-1}+A\Lambda^{-1}A^T)$$

这个公式描述的场景显然是和 **predict** 过程是对应的：

$p(z_t|x_1,x_2,x_3,...,x_{t-1})$

$=\int_{z_{t-1}}p(z_t|z_{t-1})p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1})dz_{t-1}$

很显然，我们可以一个萝卜一个坑地找到对一个关系：

$$p(x)\Rightarrow p(z_{t-1}|x_1,x_2,x_3,...,x_{t-1}) =
N(\mu_{t-1},\Sigma_{t-1})$$

$$p(y|x)\Rightarrow p(z_t|z_{t-1})=N(Az_{t-1}+B,Q)$$

$$p(y) \Rightarrow
p(z_t|x_1,x_2,x_3,...,x_{t-1})=N(\mu_t^{*},\Sigma_{t}^{*})$$

类比把上面的参数分别带入到 $p(y)=N(y|A\mu+b, L^{-1}+A\Lambda^{-1}A^T)$ 公式中，就能够对应的直接求出
$\mu_t^{*},\Sigma_{t}^{*}$ 的值：

$$\mu_t^{*}=A\mu_{t-1}+B$$

$$\Sigma_{t}^{*}=Q+A\Sigma_{t-1}A^T$$

这样 **predict** ，也就是预测的结果就求出来了，而且由于结果是高斯分布，得到了参数，就相当于求出了概率分布，得到了解析解。

那么另一个 $p(x|y)$ 的分布解析解如下：

$$p(x|y)=N(x|\Sigma\\{A^TL(y-b)+\Lambda\mu\\},\Sigma)$$

$$\Sigma=(\Lambda+A^TLA)^{-1}$$

看得出来，$p(x|y)\propto p(x)p(y|x)$ 显然可以和 **update** 步骤中的
$p(z_t|x_1,x_2,x_3,...,x_t)\propto p(x_t|z_t)p(z_t|x_1,x_2,x_3,...,x_{t-1})$
进行一一类比：

$$p(x)\Rightarrow p(z_t|x_1,x_2,x_3,...,x_{t-1})=N(\mu_t^{*},\Sigma_{t}^{*})$$

$$p(y|x)\Rightarrow p(x_t|z_t)=N(Cz_t+D,R)$$

$$p(x|y)\Rightarrow p(z_t|x_1,x_2,x_3,...,x_t)=N(\mu_t,\Sigma_t)$$

同样可以对着前面的高斯性质公式一个一个位置地填坑，把参数 $\mu_t$和$\Sigma_t$
给填出来，这俩参数拿到手了，$p(z_t|x_1,x_2,x_3,...,x_t)$ 的概率就得到解析解了，$t$ 时刻的滤波过程也就结束了。

这里，我们稍加带入就得到了：

$$\mu=\Sigma\\{C^{T}R^{-1}(z_t-D)+(\Sigma_t^{*})^{-1}\mu_t^{*}\\}$$

$$\Sigma=((\Sigma_t^{*})^{-1}+C^TR^{-1}C)^{-1}$$

其中，$\Sigma_t^{*}$和$\mu_t^{*}$ 是上面我们刚刚求得的 $t-1$ 时刻预测概率（高斯分布）
$p(z_t|x_1,x_2,x_3,...,x_{t-1})=N(\mu_t^{*},\Sigma_{t}^{*})$ 的参数。

这样，我们每一轮的 **predict** 和 **update** 过程都可以通过上面求出的 $\Sigma_t^{*}$和$\mu_t^{*}$ 以及
$\Sigma_t$ 和 $\mu_t$ 公式来求得高斯分布参数的值，从而不断地得到 **predict** 和 **update**
过程的概率分布解析解。

一轮一轮地，我们就不断地随着时间，观测到新的观测变量$x_t$，而不断地进行着滤波的过程。

