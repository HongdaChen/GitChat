## 什么是分桶？

和分区一样，分桶也是一种通过改变表的存储模式，从而完成对表优化的一种调优方式。

但和分区不同的是，分区是将表拆分到不同的子目录中进行存储，而分桶是将表拆分到不同文件中进行存储。

那什么是分桶呢？它按分桶键哈希取模的方式，将表中数据随机、均匀地分发到若干桶文件中。

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/a64c5300da394532959f5ec73cd96ca4.png#pic_center)

比如，对表的ID字段进行分桶，那ID字段被称为分桶键。ID字段存储的数据假设是1-10，执行分桶操作时，需要确定要分几个桶，这里定为3个；那么便会对分桶键中的值，按照桶的数量进行哈希取模，这里即对桶数3进行取余。那么，ID为3、6、9的数据会存放到第一个桶中，ID为1、4、7、10的会存放到第二个桶中，ID为2、5、8的则存放到第三个桶中。而每个桶在进行存储的时候，会存储为一个桶文件。

那分桶操作的目的是什么呢？它通过改变数据的存储分布，提升查询、取样、Join等特定任务的执行效率。

因为分桶之后，在数据查询中，根据分桶键的过滤条件，就可以直接通过哈希取模来确定数据存放的桶文件，从而减少需要处理的数据量；在海量数据场景中，能极大提升数据处理效率。而在数据取样过程中，可以直接对某几个桶文件进行取样，缩短取样时间。

其次，如果在Hive中，两张表需要进行join操作，转换为MapReduce或Spark作业之后，必定要经过Shuffle，而Shuffle过程会耗费大量时间，从而拉低了处理效率。但两张表，假设使用ID进行Join，而且都使用ID作为分桶键进行了分桶操作，分桶数也相同，均为3；那么便可以直接对两张表的对应桶文件直接进行join处理，提升处理效率。因为ID相同的数据，按照相同的方式进行哈希取模，必定会存放到相同的桶文件中。

所以当两张表的桶数相同或成倍数时，会带来join效率的提升。

分区和分桶是两种不同的优化手段，当然也可以同时进行，即先分区后分桶；最终的存储效果便是在子目录下的数据，被存储为多个桶文件。

## 分桶表的操作

### 分桶表的创建

    
    
    CREATE [EXTERNAL] TABLE <table_name>
    (<col_name> <data_type> [, <col_name> <data_type> ...])]
    [PARTITIONED BY ...]
    CLUSTERED BY (<col_name>)
    [SORTED BY (<col_name> [ASC|DESC] [, <col_name> [ASC|DESC]...])]
    INTO <num_buckets> BUCKETS
    [ROW FORMAT <row_format>]
    [LOCATION '<file_path>']
    [TBLPROPERTIES ('<property_name>'='<property_value>', ...)];
    

例如，现创建一张分桶表tb_buckets，包含字段id、name、age，将id作为分桶键，分桶数为3：

    
    
    create table tb_buckets(
    id int,
    name string,
    age int
    )
    clustered by (id) into 3 buckets
    stored as textfile;
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/27b61d31f378d5f747b39295f35378ca.png#pic_center)

分桶后，数据存放时默认按分桶键升序。如果需要为桶文件进行自定义排序，则可以使用SORTED BY进行设定。

例如，创建分桶表tb _buckets_ desc，包含字段id、name、age，将id作为分桶键，分桶数为3，在桶中按ID降序排列：

    
    
    create table tb_buckets_desc(
    id int,
    name string,
    age int
    )
    clustered by (id)
    sorted by (id desc)
    into 3 buckets
    stored as textfile;
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/609bbe8d9adf0c97dae9b950f5dafb47.png#pic_center)

### 分桶表数据插入

分桶表创建完成后，可以插入数据：

    
    
    --再次强调，Hive不建议单条插入，会生成小文件，这里只是方便演示
    insert into table tb_buckets values(1, 'zs', 18);
    insert into table tb_buckets values(2, 'ls', 18);
    insert into table tb_buckets values(3, 'ls', 18);
    insert into table tb_buckets values(4, 'ls', 18);
    

但是，在数据插入之后，在HDFS中查看数据文件，却发现是4个文件，而且没有桶文件的区分（在2.x的Hive版本中，已经自动开启分桶，而且脚本安装的Hive也配置了自动分桶，所以无法得到下面的结果）：

    
    
    hadoop fs -ls /user/hive/warehouse/tb_buckets
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/f7794fd3166c18133f04e3af876e7454.png#pic_center)

那么说明，在数据插入时，不会自动分桶。而必须要开启配置：

    
    
    set hive.enforce.bucketing=true;
    

参数默认值为false；设置为true之后，mr运行时会根据bucket桶的个数自动分配reduce
task个数。一次作业产生的桶（文件数量）和reduce task个数 一致。这个参数在2.x版本之前，不需要进行设置。

当然用户也可以通过mapred.reduce.tasks自己设置reduce任务个数，但分桶时不推荐使用。

为了对比，设置分桶的配置参数后，向tb _buckets_ desc表插入相同的数据：

    
    
    --开启配置
    set hive.enforce.bucketing=true;
    --插入数据
    insert into table tb_buckets_desc values(1, 'zs', 18);
    insert into table tb_buckets_desc values(2, 'ls', 18);
    insert into table tb_buckets_desc values(3, 'ls', 18);
    insert into table tb_buckets_desc values(4, 'ls', 18);
    

数据插入后，再进入到HDFS中进行查看，可以看到虽然文件数较多，因为TextFile仅支持追加，每插入一次数据便会生成一个文件，但桶已经可以区分出来了。

    
    
    hadoop fs -ls /user/hive/warehouse/tb_buckets_desc
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/47a6b593795f0e542bf5c65f9577cb44.png#pic_center)

当然，如果不开启自动分桶配置的话，可以手动指定mapred.reduce.tasks，并在数据插入时，在SQL中使用DISTRIBUTE
BY或CLUSTER BY语句来指定分桶键；这种方法也可以完成分桶数据的写入。

但值得注意的是DISTRIBUTE BY语句执行后，数据在桶中是乱序存放的，可以使用SORT BY语句来自定义排序；而CLUSTER
BY语句执行后，数据在桶中是按照分桶键升序排列的，不可以自定义排序。

    
    
    --设置reduce个数为分桶数
    set mapred.reduce.tasks=3;
    --插入数据时，指定分桶键
    INSERT (OVERWRITE | INTO) TABLE <table_name>
    SELECT <select_expression>, <select_expression>, ...  FROM <table_name>
    DISTRIBUTE BY <col_name> SORT BY <col_name> [ASC|DESC] [, col_name [ASC|DESC], ...]
    [CLUSTER BY <col_list> ]
    

例如，将tb _buckets表数据插入到分桶表tb_ buckets_desc中，并且要求在桶文件中，数据按照ID降序排列。

    
    
    --设置reduce个数为分桶数
    set mapred.reduce.tasks=3;
    --插入数据时，使用DISTRIBUTE BY .. SORT BY指定分桶键和排序
    INSERT INTO TABLE tb_buckets_desc
    SELECT * FROM tb_buckets
    DISTRIBUTE BY id SORT BY id desc;
    

接下来，依然要求将tb _buckets表数据插入到分桶表tb_ buckets_desc中，但数据在桶文件中按照ID升序排列。

    
    
    --设置reduce个数为分桶数
    set mapred.reduce.tasks=3;
    --方法一：插入数据时，使用DISTRIBUTE BY .. SORT BY指定分桶键和排序
    INSERT INTO TABLE tb_buckets_desc
    SELECT * FROM tb_buckets
    DISTRIBUTE BY id SORT BY id asc;
    --方法二：插入数据时，使用CLUSTER BY，默认按照分桶键升序排列
    INSERT INTO TABLE tb_buckets_desc
    SELECT * FROM tb_buckets
    CLUSTER BY id;
    

最后，还是要求将tb _buckets表数据插入到分桶表tb_ buckets_desc中，但数据在桶文件中存放时不要求排序。

    
    
    --设置reduce个数为分桶数
    set mapred.reduce.tasks=3;
    --方法一：插入数据时，使用DISTRIBUTE BY指定分桶键，默认不会进行排序
    INSERT INTO TABLE tb_buckets_desc
    SELECT * FROM tb_buckets
    DISTRIBUTE BY id;
    

但一般在使用分桶表时，开启自动分桶参数，然后正常写入数据即可，不会使用手动分桶的方法。

### 分桶表注意事项

分桶表在使用时，通常使用insert..select进行数据导入，在开启自动分桶的情况下，也可以支持单条数据插入（insert..values）。

在3.x版本之前，不支持load方式导入，但在3.x版本之后，会转换为insert..select方式导入数据。所以为了规范起见，建议使用insert..select方式，而单条数据插入会造成小文件生成，在生产环境中不推荐使用。

而且要注意的是，在写入分桶文件时，如果定义了数据排序，不管使用哪种方式，只能保证在写入到当前桶文件时的数据顺序。而非全局排序。

比如，先向表添加了数据1,4,7，默认降序，则数据写入到一个桶文件中，会存放为7,4,1。但再次追加数据10,13,16，数据又会进入到一个新的桶文件中，按照排序规则，存储为16,13,10。而Hive在读取表数据时，是按照文件顺序读取的，所以读取出的数据顺序为7,4,1,10,13,16。这个细节一定要注意。

如果需要拿到排序的数据，只需要在SQL中添加排序语句Order By即可，但会增加额外的处理。

分桶数的规划，需要根据表的数据规模来进行，每个桶文件的数据不要过大，大概100-200M（仅为建议值，根据生产环境自行测试调整），以保证处理性能。

而之前的tb_buckets因为没有设置自动分桶，就插入了数据，这会产生什么影响？

于是，在开启分桶的配置参数后，再向tb_buckets进行数据插入：

    
    
    --开启配置
    set hive.enforce.bucketing=true;
    --插入数据
    insert into table tb_buckets values(5, 'zs', 18);
    insert into table tb_buckets values(6, 'zs', 18);
    

在到HDFS中进行查看：

    
    
    hadoop fs -ls /user/hive/warehouse/tb_buckets
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/0a2ad4a4d1e8b8d0071df72861006a2a.png#pic_center)

此时可以看到，桶已经分开了，而且查询一下全量数据，也没有出现丢失：

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/c93cf8820064346e6fd3630ec57838f7.png#pic_center)

全表数据扫描肯定没有问题，那单独进行查询呢？因为按照正常的逻辑，前4条数据都在桶1中。但真正应该在桶1的数据是ID为1和4的数据，其余的2、3这两条数据，单独进行查询时，应该就搜索不到了。

    
    
    select * from tb_buckets where id=1;
    select * from tb_buckets where id=2;
    select * from tb_buckets where id=3;
    select * from tb_buckets where id=4;
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/17bac67db9a260cbe44df7572dda4023.png#pic_center)

但实际上是可以查询到的，而且再对两张分桶表进行join操作：

    
    
    select a.id,a.name,b.age from tb_buckets a inner join tb_buckets_desc b on a.id=b.id;
    select a.id,a.name,b.age from tb_buckets_desc a inner join tb_buckets b on a.id=b.id;
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/574c07c7ffcfb5e92c3e42e8c20b3c3f.png#pic_center)

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/1ba33c220c6d7e6b67d1e3645cf9033e.png#pic_center)

产生3个map，且没有reduce，说明没有影响。为了再次印证，使用桶抽样，抽取单个桶文件中的数据，也可以得到正确数据。

    
    
    select * from tb_buckets table TABLESAMPLE(bucket 1 out of 3 on id);
    

所以Hive会在分桶时，自动对之前历史的数据进行调整，然后逻辑划分桶文件（之前历史数据所在的桶文件，不会发生变化）。

可以得到最终的结论就是：分桶机制一部分依赖于存储在HDFS上的桶文件，但并不是完全依赖，也会有其它机制去保证分桶的正确运行。

