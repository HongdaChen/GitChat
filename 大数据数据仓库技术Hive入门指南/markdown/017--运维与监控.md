## Hive配置

### 配置方式

Hive可以通过三种方式进行参数配置，但它们的作用范围不同。

  1. set命令配置方式，可以在CLI或beeline客户端中直接使用set命令进行配置，仅在当前Session有效。

    
    
    --配置Hive临时缓存目录
    set hive.exec.scratchdir=/tmp/mydir;
    --查看某个配置项
    set hive.exec.scratchdir;
    --查看所有配置项
    set;
    

  1. hiveconf配置方式，在CLI或hiveserver2启动时使用--hiveconf指定配置项，在整个服务运行周期中有效。

    
    
    hive --hiveconf hive.exec.scratchdir=/tmp/mydir
    hive --service hiveserver2 --hiveconf hive.exec.scratchdir=/tmp/mydir &
    

  1. 更改配置文件方式，在Hive服务启动前进入$HIVE_HOME/conf/中对特定的配置文件进行配置，全局有效。

    
    
    <property>
    <name>hive.exec.scratchdir</name>
    <value>/tmp/mydir</value>
    <description>Scratch space for Hive jobs</description>
    </property>
    

配置文件包含hive配置文件hive-site.xml和其它服务配置，其中Metastore配置文件为hivemetastore-
site.xml，HiveServer2服务配置文件为hiveserver2-site.xml。

### 配置参数一览

Hive的配置分为对Hive集群的配置、MetaStore配置、Hadoop交互配置、运行时信息传递配置。以下是官网提供的最新配置参数。已全部亲自翻译。

#### Hive集群的配置

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/1794aa7cfe3cd6adfcc75de6fc0bb75e.png#pic_center)

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/6f7448467f8ba6c9095d42c5fad83e1c.png#pic_center)

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/6e615e2822f84f0a94aa8058953ac916.png#pic_center)

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/8e00a35c0aae9e60f47ba0c9f8189a83.png#pic_center)

可以按照需要，对集群进行相应的配置和优化。

#### MetaStore配置

对于MetaStore，又分为基础配置和额外配置。

基础配置主要是用于MetaStore的正常启动，额外配置用于调优。

**基础配置参数** 有：

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/5e79191d81d9b57f424599bf9f2a7fd6.png#pic_center)

**额外配置参数** 有：

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/d719f11cb1bf4374fda277bf44ca535a.png#pic_center)

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/9e8772df89b0544265be62bc7f13f450.png#pic_center)

#### Hadoop的交互配置

Hive需要依赖Hadoop，所以需要进行与Hadoop相关的配置。

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/b9307735f9801faa0b9fd80d584d76a1.png#pic_center)

#### 运行时信息传递配置

运行时信息传递配置，主要用于自定义设置与Hive交互时的一些数据信息，一般很少手动配置。

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/798a51678721993fdb719c0eb0b95880.png#pic_center)

## MetaStore

在Hive中，对于MetaStore的配置和运维是很重要的一环。接下来对MetaStore进行专门的讲解。

### MetaStore数据库配置

对于MetaStore，可以设置在本地内置的Derby数据库中，也可以使用第三方远程数据库。

但本地内置的Derby数据库，只允许单用户连接，配置参数较为简单：

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/a1aafa6fa5593c739696231ed71c2989.png#pic_center)

一般在生产集群中，需要配置远程第三方数据库，支持多用户连接：

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/09b7595fbcbf754bae906ef796add407.png#pic_center)

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/c203f3fa4b43d2e8e2b2c64dbc30b3fe.png#pic_center)

MetaStore支持的第三方数据库有：

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/99d662fdbe45af25bc2090c746391c12.png#pic_center)

### MetaStore动态发现

在Hive 4.0 版本之前，可以使用Zookeeper实现MetaStore动态服务发现。配置参数如下：

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/7b964785b6400a73475c93ba4b8423af.png#pic_center)

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/c12a8abfb85f76cb53d09d5188a29690.png#pic_center)

### MetaStore基本运维

#### 启动端口更改

MetaStore配置成功之后，需要启动MetaStore服务，在此时可以更改MetaStore的启动端口。

    
    
    hive --service metastore -p <port_num>
    

#### 秘钥连接

MetaStore启动之后，会使用配置文件中的用户名、密码去连接对应的数据库。但此时，密码是明文方式，容易造成一定的风险。所以在生产中，可以配置秘钥连接，从而避免将MetaStore密码明文配置到site.xml中。

首先，使用命令生成秘钥：

    
    
    --生成秘钥
    hadoop credential create javax.jdo.option.ConnectionPassword -provider jceks://file/usr/lib/hive/conf/hive.jceks
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/d26a41d519ae14dd7e5eccffaeb59bd8.png#pic_center)

然后在配置文件hive-site.xml或hivemetastore-site.xml中配置秘钥位置：

    
    
    --配置秘钥存放位置
    <!-- Configure credential store for passwords-->
    <property>
    <name>hadoop.security.credential.provider.path</name>
    <value>jceks://file/usr/lib/hive/conf/hive.jceks</value>
    </property>
    

#### Hive Schema Tool

Hive提供Hive Schema Tool用于MetaSore的运维修复、升级。

    
    
    schematool -help
    

首先，可以使用Hive Schema Tool进行元数据的初始化工作，下面的命令会在数据库mysql中生成Shema数据。当然支持更改数据库类型，Hive
Schema Tool支持derby|mysql|postgres|oracle|mssql这几种dbtype类型。

    
    
    schematool -dbType mysql -initSchema
    

一般元数据初始化工作在Hive安装时进行，会在DB中创建hive数据库，并生成必要的元数据表。

可以使用命令获取当前的MetaStore信息：

    
    
    schematool -dbType mysql -info
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/c7c724546ab96f9e293bc63fa5c2fc42.png#pic_center)

在Hive升级后，需要将MetaStore进行升级，因为之前老版本的Hive MetaStore中不会记录版本号，导致与新版本不兼容的情况。

使用Hive Schema Tool可以方便的进行升级操作：

    
    
    --upgradeSchemaFrom参数指定当前hive版本
    schematool -dbType mysql -upgradeSchemaFrom 0.10.0
    

除了升级，也可以添加参数-dryRun，查看升级过程中使用的脚本信息：

    
    
    schematool -dbType mysql -upgradeSchemaFrom 0.7.0 -dryRun
    

Hive Schema Tool强大的是，支持将hive元数据信息迁移到spark目录中，但这个功能需要高版本的Hive才支持。

    
    
    schematool -moveDatabase db1 -fromCatalog hive -toCatalog spark
    

于是，可以使用以下命令，将Hive元数据和表文件全部迁移到Spark中。

    
    
    # 在spark中创建对应数据库newdb，用于接收hive迁移来的数据库
    beeline ... -e "create database if not exists newdb";
    #进行数据库迁移
    schematool -moveDatabase newdb -fromCatalog hive -toCatalog spark
    # 进行表数据迁移
    schematool -moveTable table1 -fromCatalog hive -toCatalog spark  -fromDatabase db1 -toDatabase newdb
    

## Web监控

在Hive中可以使用WEB UI进行作业监控和集群监控。

### 作业监控

Hive支持的，可用于作业监控的WEB UI有：

  1. Yarn WebUI、Spark WebUI
  2. HiveServer2 WebUI
  3. HWI（Hive Web Interface）
  4. WebHCat

#### Yarn WebUI & Spark WebUI

其中Yarn WebUI、Spark WebUI是底层分布式计算引擎自带的作业监控页面。Hive默认会将作业提交到Yarn中运行，可以通过Yarn
WebUI进行作业查看。如果使用Spark作为计算引擎，即Hive On Spark，则可以使用Spark WEB UI查看作业详情。

Yarn Web UI默认端口为8088。

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/5fbb0acd46e10c4b62eddd94e88bec1c.png#pic_center)

而Spark WEB UI默认端口为8080。

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/61c8c5a0758825b0b9618095904ab493.png#pic_center)

#### HiveServer2 WebUI

在2.0.0版本后，提供HiveServer2 WebUI用于日志查看、配置管理、集群指标导出功能。默认访问端口为10002。

需要在hive-site.xml中可以进行配置修改，以开启HiveServer2 WebUI。

    
    
    <property>
    <name>hive.server2.webui.host</name>
    <value>0.0.0.0</value>
    </property>
    <property>
    <name>hive.server2.webui.port</name>
    <value>10002</value>
    </property>
    <property>
    <name>hive.server2.webui.max.threads</name>
    <value>3</value>
    </property>
    

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/a2ad4fa0c2219753ed8099a32d2af909.png#pic_center)

#### HWI（Hive Web Interface）

HWI提供在Web界面中使用Hive命令的功能，之前一直内置在Hive中，但在2.2.0版本后，不再进行维护，从Hive中被移除。

而HWI也不建议在生产中使用HWI，因为它在安全性方面存在一些问题。

如果需要使用Web界面对Hive进行操作，则可以使用Apache Hue来完成。

#### WebHCat

WebHCat用于为HCatLog提供HTTP Rest API功能，它并不提供直接的WEB界面。

HCatLog是一个公共的表存储层，可以提供Hadoop组件间的表数据共享。

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/2f3c9310b5b6cd76d3fcfcf9525e1df4.png#pic_center)

在HCatLog基础上使用WebHCat可以让开发人员通过HTTP进行数据访问、作业管理与提交。

### 集群监控

大数据集群监控，常用的组件有Zabbix、OpenFalcon、Prometheus。

其中Zabbix是基于Web界面提供分布式系统监控及网络监视功能的企业级开源解决方案，OpenFalcon则是小米开源的面向互联网企业的监控产品，Prometheus是开源的监控&报警&时间序列数据库的组合。

![在这里插入图片描述](https://img-
blog.csdnimg.cn/img_convert/8e71a1e75f8c15e773fcc6ef4d059182.png#pic_center)

它们都是通用的集群监控组件，可以对不同的大数据组件进行自定义监控和告警功能。

