经过介绍安全方面的项目技术，我们已经充分理解运维 Kubernetes 系统的问题和方案。本篇内容就是从案例角度来带领大家循序渐进的利用现有的
Kubernetes 社区提供的安全技术做练习，加深对此类技术的掌握。

### Kubernetes 生产级安全技术应用步骤回顾

当我们决定投入应用到 Kubernetes
生产环境中的时候，不仅仅需要考虑应用架构的高可用，我们还要从安全架构的角度考虑去验证我们的安全配置是否可靠。在这个应用安全技术的过程中，我们可以类比筛选大米的过程来理解。这个过程有四个步骤。

#### **舂**

这个阶段是应用 Kubernetes 安全措施的概念阶段，可能用户自己也不清楚当前的状态是否安全。所以这个阶段需要大量使用当前 Kubernetes
社区中流行的安全技术来使用，抽取相应的结果数据集合做好类比分析。把重复无效的数据内容去除，把有用的信息排列出来，通过排列组合形成一套安全指标清单。

在之前的文章中我们介绍过 K8S 基准安全扫描工具——kube-bench，就是针对主机层面快速扫描出当前 Kubernetes
的安全概况。有了这个抓手工具，我们可以清楚例如用户权限有没有问题，API Server 的端口暴露是否合理等常见问题，服务 CA
证书有没有配置等等。从应用层来讲，我们的安全是依赖服务端口的通讯协议和端口加固 TLS 等，这个方面服务网格技术 Istio 是可以起到安全管控流量的作用。

从运维的角度来讲，我们还可以利用混沌技术来保障系统稳定性的工作，这方面前面介绍过 Litmus 框架，
它集成了很多混沌技术社区共享的稳定性演练的脚本，利用云原生分布式系统的特性把脚本部署到 Kubernetes
环境中做一些自动化破坏性操作，看看应用系统的鲁棒性。这些锤炼工具都是可以让你的应用系统更安全可靠。

#### **簸**

簸的阶段是用来筛检安全指标中哪些糟粕的信息的过程。很多时候我们用上社区流行的安全扫描工具，能扫描出一大堆重复的不痛不痒的警告指标，真正能起到防护作用的并不多。这个时候需要详细列出来指标的参数和意义，充分理解每个指标的真正含义和作用。

一般这个时候我们是需要真实演练一下安全工具的扫描步骤的，让用户有场景带入感，只有把真实有效的安全基准给定义出来，才能真正去做好 Kubernetes
安全配置。

#### **筛**

筛的过程是一个汇聚所有安全指标，并且根据业务场景归类的过程。没有数据就没有安全防控，通过场景合理有效的经过一遍评审之后，一定会沉淀下来运营应用的标准安全指标模板。

#### **拣**

拣的过程就是要在安全指标的监控大板中优化安全指标的优先级。把最关键的三个指标放在最显眼的地方。通过真实的生产环境中历练使用，让用户能指出自己关心的安全指标，根据用户反馈把安全指标调整到满意的集合位置，就可以实现良性的安全生产运营迭代。

### 保护集群安全

从主机入手，做好 Kubernetes 集群系统各个组件的安全防护。下面我们开始做一次测验历程。

#### **控制对 Kubernetes API 的访问**

默认 API Server 是暴露 8080 端口，直接可以在本地访问的。需要通过安全配置加载 TLS
证书加固端口才能保证集群的安全。请注意，集群组件的安装方法是否可能使用 HTTP 来访问本地端口，
管理员应该熟悉每个组件的设置，以识别潜在的不安全的流量。在有了安全端口 6443 开放后，对于认证，我们也可以选择采用 TLS
证书认证的方式来授权服务的访问。所有 API 客户端都必须经过身份验证，即使它是基础设施的一部分，比如节点、代理、调度程序和卷插件。
这些客户端通常使用服务帐户或 X509 客户端证书，并在集群启动时自动创建或是作为集群安装的一部分进行设置。

#### **控制运行时负载或用户的能力**

ResourceQuota，资源配额是基于 Namespace 的资源隔离对象,
对每个命名空间的资源消耗总量提供限制。一般企业应用中很少关注这块的配置，毕竟资源还是很充足的。从安全的角度来看，定额定量的分配使用资源才能为后面安全运营提供有效的数据指标。开头万事难，所以推荐还是默认加上资源配额。

#### **控制容器运行的特权**

securityContext，是为 Pod 或容器配置安全性上下文。在去 Docker 化的过程中，Kubernetes
极大的加强了对容器沙箱的环境控制。你可以完全不用考虑 Docker 容器的安全选项，直接使用 Kubernetes
配置的安全上下文来控制应用安全。范例如下：

    
    
    apiVersion: v1
    kind: Pod
    metadata:
      name: security-context-demo
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 2000
      volumes:
      - name: sec-ctx-vol
        emptyDir: {}
      containers:
      - name: sec-ctx-demo
        image: busybox
        command: [ "sh", "-c", "sleep 1h" ]
        volumeMounts:
        - name: sec-ctx-vol
          mountPath: /data/demo
        securityContext:
          allowPrivilegeEscalation: false
    

#### **限制网络访问**

NetworkPolicy，网络安全策略依赖第三方网络插件的能力，比如常见的 Calico
就提供的此能力。一般我们很容易忽略这方面的应用。其实这里的安全能力是很重要的安全配置措施。在此提醒大家，一定要熟练掌握策略配置方法，并能灵活应用。并且在下一次的
Kubernetes 环境中第一时间就应用此技术。配置范例如下：

    
    
    ### 限制 nginx 服务的访问
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: access-nginx
    spec:
      podSelector:
        matchLabels:
          app: nginx
      ingress:
      - from:
        - podSelector:
            matchLabels:
              access: "true"
    

#### **控制 Pod 可以访问哪些节点**

Taint（污点）使节点能够排斥一类特定的 Pod，容忍度（Toleration）是应用于 Pod 上的，允许（但并不要求）Pod
调度到带有与之匹配的污点的节点上。污点和容忍度（Toleration）相互配合，可以用来避免 Pod 被分配到不合适的节点上。 比如我们给 master
节点配置一个策略，不让普通的 Pod 在上面跑：

    
    
    kubectl taint nodes node1 key1=value1:NoSchedule
    

给节点 node1 增加一个污点，它的键名是 key1，键值是 value1，效果是 NoSchedule。 这表示只有拥有和这个污点相匹配的容忍度的
Pod 才能够被分配到 node1 这个节点。

若要移除上述命令所添加的污点，你可以执行：

    
    
    kubectl taint nodes node1 key:NoSchedule-
    

一个 Pod 拥有其中的任何一个容忍度都能够被分配到 node1 ,有两种表达方式：

    
    
    tolerations:
    - key: "key1"
      operator: "Equal"
      value: "value1"
      effect: "NoSchedule"
    

或者：

    
    
    tolerations:
    - key: "key1"
      operator: "Exists"
      effect: "NoSchedule"
    

#### **限制访问 etcd**

对于私有部署，大量的集群安装模式是把 etcd 集群和 Kubernetes
控制面放在一起。所以在这样的情况下，我们不得不对整个集群的控制面做好防护，放在防火墙的后面最好。不要在调度 Pod
到控制节点上运营。对于很多小集群来说，它的架构方式是业务节点和计算节点放在一起的，这样的结构就只能对主机端口做好安全过滤，不要让 Kubernetes
组件调用外部访问。

在最新的发行版本 v1.20 中提供了日志审计能力，负责记录 API 操作以便在发生破坏时进行事后分析。 可以关注对 etcd 组件的审计配置。

### 总结

从 Kubernetes 云原生的安全架构来讲，业界已经提供了基准测试工具链，可以为我们提供丰富的安全基准指标。在这个前提下，Kubernetes
集群层面的安全措施也是武装到了牙齿，当然前提是你需要时刻保持集群版本的更新。很多企业的基础环境一般都是 3~5
年的生命周期保持不变，并不像互联网公司一样，环境可以时刻有机会更新到最新的版本。所以当你为企业选择一份发行版本的时候，还请选择当下最新的版本，并且能在多方面纬度考量安全措施的实施难度。在这些工作做全的情况之下，就可以持续地维护这个实施版本即可。

### 参考资料

  * <https://kubernetes.io/zh/docs/tasks/administer-cluster/securing-a-cluster/>
  * <https://kubernetes.io/zh/docs/concepts/scheduling-eviction/taint-and-toleration/>

