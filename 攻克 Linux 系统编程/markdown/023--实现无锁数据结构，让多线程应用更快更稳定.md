在本节中，我们要讨论的是无锁编程。我们会通过对基本无锁数据结构设计思路的介绍，来帮助读者入门无锁编程，主要包括以下几部分内容：

  * 无锁编程概述
  * 简单一对一无锁队列
  * 关于指令顺序

### 1 无锁编程概述

免费的午餐早已经结束，多线程编程已经成为当代系统开发者的一项基本技能。在《第12课：掌握线程同步，让复杂工作流协调有序》中，我们介绍了很多种线程间同步的锁方法，它们能很好地解决多个并行线程间协调与同步的问题，保证多线程程序执行结果的正确性。

但是， **锁方法也有一些它自己的缺点**
，比如，当发生锁争用的时候，会有线程被投入到挂起状态，而再次被唤醒的时机，就取决于操作系统的调度算法了。这不能满足一些对实时性有特殊要求的服务，而且，这也会减慢服务的响应速度。

另外， **使用锁方法还会发生所谓的优先级倒置的问题**
，比如，当一个低优先级的线程获得了某个互斥锁，正在临界区内执行的时候，被更高优先级的线程抢占，而当该高优先级线程也试图获取这个互斥锁的时候，就会失败，也就是说，它可能会导致低优先级的线程阻碍高优先级线程的执行。

所以，一直以来，全世界的开发者都在试图寻找比锁方法更安全、更高效的线程间同步方法， **无锁编程就是其中的成果之一** 。

无锁编程，表面意思是不使用锁技术而实现的多个线程访问共享数据的技术。更学术一点的定义则是，无锁编程是非阻塞同步技术中的一种，它能保证在任意时刻，至少有一个线程能够继续执行，而且，在任意位置停止一个线程，都不会影响其他线程的执行。

可以发现，在学术上，更加关注的是无锁技术的安全性，也就是它在防止死锁、优先级倒置等问题上的改进。而在实际开发过程中，
**开发人员引入无锁技术的出发点，更多的往往是性能上的考虑。**

在本节课中，我们关注的主要是后者，我们会从最简单的无锁队列入手，介绍不使用锁，如何实现对共享数据区的同步访问，以及在实现过程中需要考虑的种种技术细节。

### 2 简单一对一无锁队列

**无锁编程是一项极具挑战性的技术** 。但是如果把情况限定在只有一个生产者和一个消费者的条件下，情况就可以简单许多。

比如，生产者与消费者之间可以使用一个单向递增的消息队列进行消息的传递。生产者向消息队列中追加消息的时候，先把消息体复制到队列内，再更新队尾指针；类似的，消费者也是先取出消息内容，再更新队首指针。对于队首和队尾指针来说，因为生产者和消费者各自只更新其中一个，所以永远不会发生冲突；而对于两者共享的消息数据来说，生产者只在队尾之后追加，消费者只会从队首取，只要协调好队首和队尾标记的更新顺序，也永远不会发生冲突。由此，就可以实现一个最简单形式的无锁队列。

以这样的思路实现的无锁队列的示例代码如下所示：

    
    
    char queue_buffer[QUEUE_LEN];
    int head = 0, tail = 0;
    int lockless_enqueue(const char * msg, int len)
    {
        int ml = min(QUEUE_LEN - tail, len);
        memcpy(queue_buffer + tail, msg, ml);
        tail += ml;
        return ml;
    }
    
    int lockless_dequeue(char * buffer, int len)
    {
        if(head == tail) return 0;  //空队列
        int ml = min(len, head - tail);
        memcpy(buffer, queue_buffer + head, ml);
        head += ml;
        return ml;
    }
    

在这段代码中，因为出队函数是通过 head 和 tail
的位置关系来判断有没有新的消息内容的，而入队函数只有在把消息内容成功放入队列缓冲区之后，才会去更新队尾指针，所以，可以保证出队函数发现有新数据的时候，消息数据一定是准备好的。

在更新上面的队首和队尾指针的时候，当它们超过缓冲区大小时就重新回绕。当拷贝数据时，如果发现有回绕，则对回绕的两段数据分别执行 memcpy
操作，就可以实现一个无锁的环形消息队列。

**这种无锁消息队列还可以扩展到进程之间的通信** ，只要把队首和队尾指针，以及消息缓冲区，都放到共享内存里面就行了。工作示意图如下所示：

![无锁队列](https://images.gitbook.cn/44987d60-44e3-11e9-9f55-0f5c72c4faf3)

### 3 关于指令顺序

看上去好像没有问题，在测试程序上，也能够正常地工作。但是，如果把这段代码放到生产环境下，它可能会时不时地给你带来一点麻烦。这段程序会间歇性地发生奇怪的错误，很难重现，很难追踪，而且发生得没有规律，可能几天，也可能几个月才能遇到一次。

原因何在呢？上面的想法，在逻辑上没有任何问题，但是，它忽略了一点，就是现代 CPU 上指令的乱序执行。

现代的 CPU
中，采用了很多的手段来提高机器指令的执行速度，比如指令乱序执行、多级缓存技术等，而这些都有可能会导致某些指令执行或完成的顺序与开发者预期的顺序有轻微的差异。
**总体上，造成这种差异的来源可以分为两类：静态的和动态的** 。

#### 3.1 静态乱序

静态的差异是由编译器带来的，为了优化程序的执行效率，编译器会在它认为不影响最终执行结果的条件下，适当调整生成的指令的执行序列，以实现尽可能高的并行化水平，提高生成的程序的执行效率。

但是，在一些需要使用严格的指令序列的场合，我们并不希望编译器帮助我们重排指令。因为编译器在执行优化的时候，并不能很好地预测多个线程或进程间相互配合的情况，乱序之后的指令序列通常并不是我们想要的。

解决静态乱序的方法，大多数开发者应该都比较熟悉， **就是使用 volatile 关键字，修饰顺序更新的每个变量**
。这个关键字会告诉编译器，这几个变量的内容是易变的，请不要把使用它们的指令的执行顺序打乱。

或者使用如下定义的屏障指令，它能保证该屏障之前的指令，不会被编译器重排到该屏障之后。

    
    
    #define barrier()    __asm__ __volatile__("": : :"memory")
    

#### 3.2 动态乱序

经过以上处理之后的指令，它们的执行顺序就会完全按照预期的顺序依次执行了。但是，仍然不能保证它们完成的顺序是预期的。
**计算机的多层缓存机制，就是造成这种运行时乱序的原因之一。**

在现代的计算机中，存储系统是分层的，从靠近 CPU 的方向算起，有寄存器、一级缓存、二级缓存，有的还有三级缓存，然后才到主存，越靠近 CPU
的存储层，其执行速度越快。

计算机在执行指令或读写数据的时候，会一次从主存中载入一个缓存线大小的内存数据，根据数据访问的局部性原理，下次访问附近的数据的时候，就有可能直接在 CPU
的缓存中命中，从而有利于程序执行速度的提升。

**这种缓存结构造成的一个后果就是，内存访问指令执行完成的顺序，并不一定与指令开始执行的顺序完全一致**
。在上面的无锁队列中，消息入队时，虽然逻辑上是先把数据放入消息缓冲区，然后才去更新队尾指针，但是如果某个时刻，在把消息体放入消息缓冲区的时候，目标消息缓冲区的内存还没有加载进高速缓存，而队尾指针已经在高速缓存中了，就可能产生队尾指针的更新在消息体复制操作之前先完成的情况。如果出队函数也恰好在这个时间点执行，读到的消息体就可能不是最新的内容。

**要解决这个问题，需要一种机制来保证指令的完成顺序** ，在 x86 CPU 上，有三条内存屏障指令可以完成这个任务： **lfence、sfence 和
mfence** ，它们表示的意义如下所示。

  * lfence：读内存屏障，作用是保证该指令之后的读内存操作，一定会在它之前的读内存操作完成之后才去执行。
  * sfence：写内存屏障，保证该指令之后的写内存操作，一定会在它之前的内存写操作完成之后才去执行。
  * mfence：读写内存屏障，保证该指令之后的读或写内存操作，一定会在它之前的读或写内存操作完成之后才会去执行。

例如，在上面的无锁消息队列中，在 memcpy
函数与对头尾指针的更新操作之间，插入写内存屏障指令，就可以保证消息体的入队与队首队尾指针更新操作的严格顺序。方便起见，可以定义如下的屏障函数来使用：

    
    
    #define read_barrier()    __asm__ __volatile__("lfence": : :"memory")
    #define write_barrier()    __asm__ __volatile__("sfence": : :"memory")
    #define memory_barrier()    __asm__ __volatile__("mfence": : :"memory")
    

### 4 总结

在本节课中，我们通过对最简单形式的一对一无锁队列实现思路的讨论， **介绍了无锁编程的基本思想** ，并
**讨论了这个逻辑上无错的程序在实现上需要额外考虑的两个影响因素和解决方案** 。

然而，无锁编程的内容远不止本节课介绍的这么一点点，更复杂的无锁算法，可以实现多个生产者和消费者间无锁地访问共享资源，它们的核心思想是原子化的
CAS（Compare And Swap）操作，需要硬件指令级的原子指令支持。在 x86 CPU 上，这个指令是
CMPXCHG。感兴趣的读者可以自行搜索相关的内容。

