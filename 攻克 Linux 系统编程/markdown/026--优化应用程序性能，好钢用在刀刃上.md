现在我们来 **讨论一下影响应用程序性能的不同方面，并针对性地提出优化应用程序性能的常用手段** 。

我们将从以下几个方面分别进行讨论：

  * 优化网络性能
  * 优化文件访问性能
  * 优化内存使用性能
  * 优化 CPU 使用性能

### 1 概述

性能优化是大多数软件产品都会经历的一个非常重要的阶段。随着硬件计算能力的提升，以及越来越注重产品迭代速度的今天，性能优化经常会被安排在项目的后期，作为产品正式上线之前的一项重要任务。

而对一些立项之初就非常注重运行性能的服务器产品，虽然会在架构设计时就把性能问题作为重要的设计目标，并且在产品的整个开发周期中，都把性能作为重要的测试和把控参数，但是在产品正式上线推出之前，对系统进行整体的性能测试和调优，仍然是一项不可或缺的重点任务。

性能优化不是一项简单的任务，相对于业务逻辑的开发，它需要开发者以更加接近机器实际运作的思考方式，更快、更准确地定位到问题所在，并提出优化方案。

### 2 网络性能优化

大多数应用程序在网络性能方面的需求，通常可以归结为两个方面：

  * 尽量低的网络延迟
  * 尽量高的吞吐量

下面我们从软件设计的层面，分别讨论可用的优化方法。

#### 2.1 优化网络延迟

**网络延迟的来源有很多，最常见的是连接延迟、首字节延迟和数据往返延迟** 。

连接延迟来源于数据传输之前建立网络连接需要的时间。通常来说，TCP 的连接延迟要大于 UDP，因为 TCP
建立连接时要经过三次握手的过程，而且，在服务器负载特别高的情况下，如果服务器上的接收队列已满，那么三次握手的 SYN
包是可能被服务器丢弃的，这时就会引起客户端检测到超时之后重传 SYN
包，从而造成连接延迟的延长。因此，尽量提高服务器的消息处理能力，能减少极端情况下的连接延迟。

首字节延迟指的是，从连接建立到服务器接收并开始处理第一个字节的数据需要的时间。这个时间与服务器的处理能力，采用的复用模型，以及对接收到的处理任务的分发算法等都有关系。

数据往返延迟，指的是网络数据包在两个端点之间往返所需要的时间。这个延迟主要取决于选定的网络路由和当前的网络状况。降低该项延迟的常用方法是在路径中部署高质量的转发节点，比如很多的网游加速器，就是网游厂商在骨干网上专门搭建或租用了高带宽的双线机房，并识别游戏数据包，使他们根据用户的网络线路类型，自动选择速度最快的节点服务器执行数据转发。

另外，TCP 的可靠传输，依赖于其丢包检测算法，当发现丢包时自动重传某个数据包。不同的丢包检测算法发现丢包的反应时间是不同的，如果服务不能忍受 TCP
的丢包重传引起的延迟时间抖动，可以考虑使用 UDP 来代替 TCP，并在应用层设计自己的丢包、乱序等检查和纠正逻辑的方式，实现优化平均传输延迟的效果。

例如，我曾参与研发的一款实时对战手游产品的帧同步服务器，就是用 UDP
协议实现数据转发。帧同步的游戏数据，需要严格按照每帧的顺序，可靠地传输给参与对战的每个客户端。为了在不可靠的 UDP
上实现可靠的数据传输，这个服务器在一帧中给每个客户端发送临近的五帧游戏数据，也就是用五倍的冗余数据换来尽量少的丢包重传造成的延迟。如果某帧的数据发生了丢失，客户端还有很大的概率从接下来的另外四帧内获取到丢失的数据，只有在连续五帧数据都丢失的情况下，客户端才会要求服务器重发某个特定帧的数据。但是这种极端情况只有在网络条件特别差的情况下才会出现。

#### 2.2 优化数据吞吐量

**优化网络数据吞吐量的主要方式是使用缓冲** 。比如，在具有数据可靠性保证的 TCP
传输协议中，使用可变的发送窗口，一次性地发送多个数据包给对端，而不是等收到上一个数据包的确认之后再发送下一个，以此来提高整体的数据吞吐量。

另外，在套接字上也有相应的缓冲区，让发送和接收的数据都可以在某个位置先聚集。有时候，需要根据网络程序的数据处理能力，和线路的最大传输速度，来计算并调整需要的缓冲区大小，来保证能够达到需要的数据吞吐量。

### 3 文件访问性能优化

应用程序的文件访问性能主要受两个方面的影响：

  * 一个是硬件的读写性能；
  * 另一个是采用的文件系统的工作性能。

#### 3.1 硬件性能优化

**在硬件的读取性能优化方面，最直接的方法当然是更换性能更好的硬件** ，比如，换用转速更快、缓存更大的机械硬盘，或者升级成固态硬盘，或者闪存盘。

而 **在软件设计层面，尽量保持磁盘数据访问的连续性，避免过多的随机位置 I/O，能显著地提高文件的读取性能**
。这是因为，对于有旋转部件的机械硬盘来说，在随机位置的 I/O
会引入更多的磁头寻道和移动时间，因而性能更差；而对于固态或闪存盘来说，其内部的地址查找缓存，可以对连续地址的 I/O 访问性能有些帮助，而对随机地址 I/O
就无能为力了，虽然它的影响幅度会比机械硬盘小得多。

对写入性能来说，设置合适的内存缓冲区，合并多个连续的 I/O 写操作，能显著提高文件的写入性能。

#### 3.2 文件系统性能优化

除了底层硬件之外，采用的文件系统也会对应用程序的文件读写性能产生很大的影响， **常用的优化手段包括：尽量保持连续的 I/O
地址访问、文件内容预取、避免文件读写的等待时间、使用内存映射文件、避免不必要的元数据更新** ，等等。

保持连续的 I/O
地址访问，不只影响底层硬件的读写性能，同时对软件层面的文件系统的工作性能也有显著的影响。这是因为，当执行文件读写操作时，在内核中也会有相应的数据缓冲区，来加速后续对附近地址的读写操作。

文件内容预取技术，对于有明确访问模式的文件的读取性能有非常显著的提高。比如，当只使用文件系统的默认缓存时，每当发现要读取的文件内容不在内存缓冲区时，就会把附近的一小部分数据一起加载进内存，但是在依次使用后续文件数据时，如果文件体积比较大，就会触发多次缓存不命中，从而引起性能问题。在这种情况下，显式地告诉文件系统一次性预加载哪部分文件内容，可以显著地提高整体的性能表现。

Linux 提供的完成这个功能的系统调用是 readahead，其函数原型定义为：

    
    
    ssize_t readahead(int fd, off64_t offset, size_t count);
    

减少文件读写的等待时间，有两个思路，一个是把阻塞的文件读写任务分配给单独的工作线程，避免主线程在文件操作时白白浪费 CPU
的等待时间；另外一个更加常用的方法是使用非阻塞的 I/O。

内存映射文件，是用系统调用 mmap() 创建的，这个系统调用会把文件内容映射到内存中，从而可以直接使用内存地址访问来操作文件内容，避免使用 read()
和 write()
所产生的系统调用和上下文切换开销。但是，在使用内存映射文件的时候，一定要先确认系统性能瓶颈的准确位置，如果性能瓶颈并不在文件系统的内容访问上，那么这个方法并不能带来明显的性能提升。

**文件系统的元数据更新，也会带来显著的性能开销，对于机械硬盘的影响尤其显著**
。因为文件的元数据通常会保存在不同于文件内容数据的磁盘块上，对元数据的更新会引起磁头寻址的操作。所以，应该根据应用的具体需求，尽量减少对元数据的更新。相关内容在《第
02 课：精细控制文件 I/O，编写更稳健的应用》中也有讨论。

### 4 内存使用性能优化

在内存使用方面， **比较有效的性能优化手段包括：保持内存访问的局部性、使用对象池、避免内存页被换出等** 。

#### 4.1 充分利用局部性原理

保持内存访问局部性的优势在于，能够充分利用 CPU
中的各级高速缓存。实际上，现代计算机中的各种缓存技术，能够生效的基础就是计算机程序数据访问的局部性原理。在《深入理解计算机系统》（英文版：）一书中，就用了大量的篇幅介绍计算机中多种层次上的缓存，并用一个实际的示例程序，演示了不同的内存访问方式产生的巨大的性能差异。

#### 4.2 使用对象池

对象池是另外一个非常有效的提高内存使用性能的优化手段。它的核心思想是，把某几类经常使用的对象放在应用层的某块缓存中，当某类对象使用完成之后，不把它占用的内存释放掉，而仅仅是放回到应用层维护的某个空闲对象列表中；当后续有对该对象的使用需求时，先在该空闲列表中找，找到就直接取出来用，用完再放回来。

采用这样的池化技术，能大幅减少进程的动态内存申请和释放操作，从而能够大幅度地提高运行效率。市面上很多流行的手机游戏，都会采用这样的技术优化一些初始化开销比较大的游戏对象，如战场中的战斗单位、大量的发射物和特效资源等，来减少这些对象在创建时引起的游戏卡顿。

#### 4.3 避免内存页被换出

在 Linux
中，所有进程的内存占用总和，是可以大于系统的物理内存容量的，这是靠交换的思想实现的。当系统发现当前的空闲物理内存不能满足内存申请需要时，会把一部分近期内访问较少的内存页换出到交换分区上。但是这个过程会引起比较严重的性能问题，因为交换分区是用相对慢速得多的外部存储器来实现的。

如果进程中存在对运行性能特别关键的数据，可以选择把这块关键内存保持锁定在物理内存中，使之永远不会被交换算法选中而换出到交换分区上，从而可以在高内存负载下，也能一定程度上保证其运行性能。更详细的内容，读者可参考《第
13 课：活用内存映射与虚拟内存，让应用更高效》中的内容。

### 5 CPU性能优化

在 CPU 的使用上，常见的优化手段包括以下几种。

  * 缓存中间结果，避免重复计算

比如，在信号处理界非常有名的快速傅立叶变换，其核心思想就是充分利用已经得出的三角函数结果，从而避免了大量重复的对相同角度的正余弦运算。

  * 充分利用高速缓存和热点数据

这主要是对多核 CPU 来说的，比如，要尽量避免同一个进程在不同的 CPU 之间频繁切换。因为在切换到不同的 CPU 之后，需要把在上一个 CPU
上修改过的内存数据同步到新的 CPU 上，而不能直接利用之前已经缓存在 CPU 的高速缓存上的数据。这可以《第 14
课：合理控制优先级，根据职责赋予权利》中的 CPU 亲和力 API 实现。

另外一个充分利用 CPU 的热点数据优化性能的思路是，让来自相同用户的网络请求，总是交给相同的 CPU
来处理。比如，我曾经参与研发的一个网络防火墙产品，在把来自网络的处理任务分配给不同的工作线程时，用数据来源的 IP 和 Port
作为哈希算法的输入，这就可以保证来源相同的网络请求，总是会被分配给相同的工作线程。同时，因为每个工作线程都绑定在固定的 CPU
核心上，所以，实际上会交给相同的 CPU 去处理。

  * 充分利用 CPU 的分支预测加速

在现代的 CPU
中，有一种为了提高指令序列的执行速度而引入的分支预测技术，它会对程序即将执行的分支流程进行预测，并预先读取预测的分支的指令并解码。如果分支命中正确，那么该分支上的指令就会因减少了译码等待时间而加速。充分利用
CPU 的这个特性也是优化程序性能的有效手段。

比如，在内核代码中，经常可以见到像下面这样的片段：

    
    
    if(likely(xxxx)) {
        ......
    }
    
    if(unlikely(xxxx)) {
        ......
    }
    

这就是在告诉编译器，条件判断中的情况是否是大概率能够满足的，以此提供分支预测的信息，使得编译器能够生成速度更快的机器指令序列。

此外，有时候，适当调整代码中循环和条件判断的组织顺序，也会对分支预测的成功率产生显著的影响。

### 6 总结

在本节课中，我们 **从网络、文件、内存以及 CPU 的角度，分别列举了常见的性能优化手段，并阐释了它们能够生效的底层机理**
。当然，性能优化的手段远远不止本节课所列举的这几个，但是，这里列出的优化方法，是我曾经参与过的项目中实际用过，而且优化效果非常明显的。

最后，要提醒的是， **性能优化的正确姿势，是先准确定位出瓶颈，再针对性的采取措施** 。这就像走路，如果方向错了，只会越走越远。

