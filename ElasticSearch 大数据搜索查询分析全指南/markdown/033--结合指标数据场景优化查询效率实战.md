结合 32 课，继续讨论关于优化查询效率的问题。上个课时中我们使用 `es.search(dsl,index)`
接口查询出了北京城市的所有天气数据，即使我们使用了 _source 字段控制了不必要的网络输出，但是我们是一次性把北京城市的数据全部都取回来了，并且使用
value_cout 字段统计了有多少条数据，然后设置 size，这里因为 size 比较小，没超过 10000 条。但是如果是上百万条呢？通过
value_cout 获取数据个数，然后再设置 size 一次性取回来吗？

当然是不允许了，无需再划分取数据需求，我们可以分批取回所有数据，那就是 Scroll 接口。

### ES 优化 Scroll

指定 index，指定 DSL，配置 Scroll 有效时间是 2 分钟，每次取 1000 个。关于 Scroll 原理之前的课时也介绍得很清楚了，就是会在
ES 里面生成一个数据快照，Scroll 会直接从这个快照里面取。快照不能够避免脏数据，因为不能够跟 ES 索引保持实时一致，如果数据快照已经生成，ES
索引数据发生改变，那么这更新后的 ES 数据是不会同步到数据快照中的。

    
    
    data=es.search(index=index,body=dsl,scroll='2m',size=1000)
    

打开 data 面板，可以看到除了跟之前的相同字段外，多了一个 _scroll_id 字段，这个字段就是一个 token，拿着这个 token
就可以去相应的 ES 数据快照取。Scroll 的 timeout 设置也是比较重要的，如果一次任务 2
分钟执行不完，那么数据快照将会过期，那么后面的数据都将丢失，但是也不能够设置太久，如果太久数据快照久久不能清除，在 ES 中堆积得越来越多会比较消耗 ES
内存资源。

![image-20200411193855726](https://images.gitbook.cn/dc9cc400-99f5-11ea-a84f-f7d3d4dae1cc)

### 循环 Scroll

Scroll 接口需要配置两个参数，本次 Scroll 查询的 id，与数据快照过期时间，这个过期时间每次都要配置，这样的话每次 Scroll
一次，快照过期时间又会被重新设置成 2 分钟。

    
    
    tmp=es.scroll(scroll_id=scroll_id,scroll='2m')
    

首先定义一个解析方法，这个解析方法专门用来解析 Scroll 数据的，共有两个参数，DataFrame 表与 ES 传送的数据。

    
    
    def parserHits(wether_table,data):
        hits=data["hits"]["hits"]
        for hit in hits:
            source=hit["_source"]
            wether_table=wether_table.append(source,ignore_index=True)
    

取出 scroll_id 与 scroll_size，scroll_size 是判断这个 Scroll 共取回来多少条数据。

    
    
    scroll_id=data["_scroll_id"]
    scroll_size=len(data["hits"]["hits"])
    

写个循环体，不停地去 Scroll，直到取回的数据个数是 0，说明已经完全地把数据遍历一遍了。

    
    
    while scroll_size>0:
        tmp=es.scroll(scroll_id=scroll_id,scroll='2m')
        parserHits(wether_table,tmp)
        scroll_id=tmp["_scroll_id"]
        scroll_size=len(tmp["hits"]["hits"])
        print("** **",scroll_size)
    

整体代码如下。这样就可以把所有数据取回来，并且控制每次只取 1000 条。当然在实际应用中可以设置大一点，我习惯设置为 7000 到 10000
条，觉得响应速度还可以，并且不会占用 ES 太久，因为 ES 同一时间并不是只有你一个人的 job 在使用。

    
    
    import pandas as pd
    
    def parserHits(wether_table,data):
        hits=data["hits"]["hits"]
        for hit in hits:
            source=hit["_source"]
            wether_table=wether_table.append(source,ignore_index=True)
    wether_table=pd.DataFrame()     
    data=es.search(index=index,body=dsl,scroll='2m',size=1000)
    parserHits(wether_table,data)
    scroll_id=data["_scroll_id"]
    scroll_size=len(data["hits"]["hits"])
    while scroll_size>0:
    
        tmp=es.scroll(scroll_id=scroll_id,scroll='2m')
        parserHits(wether_table,tmp)
        scroll_id=tmp["_scroll_id"]
        scroll_size=len(tmp["hits"]["hits"])
        print("** **",scroll_size)
    

### 策略设计模式重构代码

当然这次涉及的业务比较简单，没有很复杂的处理数据逻辑，但是如果有呢？难道每次都要重新写一下 Scroll 的代码吗？

不用，抽象地看一下，哪里是变的，哪里是不变的，封装变的部分就行了。Scroll 的逻辑是不变的，每次解析 Scroll
的数据，不同业务需求解析方法不同，那么封装这里就好了。这里可以引用策略设计模式的思路来封装，策略设计模型的解决问题的方式是将不同的算法封装成一个一个的类，可以任意地替换。

我们先定义一个 context 类，用来接收不同的策略以及其他参数。__init__ 方法类似构造函数的方法，用来接收类初始化时候的参数，callback
参数是我们需要传入的策略。类封装完成之后，基本上就可以用了。这样的话不需要每次重新写 Scroll 逻辑，直接初始化这个类就行了。

### context 类

    
    
    class context:
        """
        构造函数，类初始化接收参数
        """
        def __init__(self,callback,ES_API):
            self.callback=callback
            self.ES_API=ES_API
            self.get_es_instance()
        """
        解析数据
        """
        def __parser(self,raw_data):
            return self.callback(raw_data)
        """
        获取 ES 实例
        """
        def get_es_instance(self):
            self.es = Elasticsearch([self.ES_API],timeout=1000)
    
        """
        执行 Scroll 方法
        """
        def scroll(self,index,dsl,timeout):
            result=[]
    
            data=self.es.search(index=index,body=dsl,scroll=timeout,size=1000)
            parser_data=self.__parser(data)
            scroll_id=data["_scroll_id"]
            scroll_size=len(data["hits"]["hits"])
            result.append(parser_data)
    
            while scroll_size>0:
    
                data=self.es.scroll(scroll_id=scroll_id,scroll=timeout)
                scroll_id=data["_scroll_id"]
                scroll_size=len(data["hits"]["hits"])
                parser_data=self.__parser(data)
                result.append(parser_data)
                print("** **",scroll_size)
    
            return result
    

### 策略方法

定义一个策略方法，这个方法比较简单，就是把 _source 结果取出来。

    
    
    def parser_strategy(data):
        sources=[]
        hits=data["hits"]["hits"]
        for hit in hits:
            source=hit["_source"]
            sources.append(source)
        return sources
    

### 客户端代码

    
    
    ES_API="localhost:9200"
    index="weather_monitor"
    dsl={
    "size":10000,
      "_source": ["temperature","timestamp"], 
      "query": {
        "bool": {
          "filter": {"term": {
            "city.keyword": "beijing"
          }}
        }
      }
    }
    timeout="2m"
    #初始化类，并注入策略
    es_main=context(parser_strategy,ES_API)
    #获取 Scroll 结果
    results=es_main.scroll(index,dsl,timeout)
    

结果图如下：

![image-20200411211133813](https://images.gitbook.cn/2ab32710-99f6-11ea-9d43-4b614dacd168)

### 小结

本课时主要介绍了如何使用 ES Scroll 方法，来提高查询效率，减少 ES 负担，不仅仅介绍了如何使用 Scroll
优化查询，还介绍了如何优化代码、重构代码，利用策略设计模式对代码进行重构，所以在提升 ES
查询效率同时，也不要忘记对代码的优化，只有高质量的代码才能维护起来方便，复用性高。

