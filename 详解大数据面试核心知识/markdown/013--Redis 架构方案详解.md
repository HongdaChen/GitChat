上一篇对 Redis 做了一个比较全面的梳理，从数据结构到场景，再到各种原理和机制，完全掌握后基本能应对大部分 Redis
相关的问题了，这一篇再从架构上做一个补充，包括基础的主从模式，哨兵模式和官方的集群方案，这些架构解决了很多 Redis
使用上的问题，但是仍然存在缺陷，所以诞生了很多社区的集群方案来解决大家普遍遇到的问题，这里就不讨论了，有兴趣的同学可以自行去了解。总的来说 Redis
还是一个非常优秀的内存数据库，在大数据的领域的应用也是非常广泛的。

**本篇面试内容划重点：主从，哨兵，故障恢复，集群，数据分区**

### 主从模式

**![image.png](https://images.gitbook.cn/2020-06-11-070022.png)**如图所示，主从复制的架构非常简单，
**一主多从** 。左边的结构会加重 Master 的主从复制负担，因为多个从节点都会从 Master 复制数据，右边这种结构的设计就是为了减轻
Master 的负担，但是会带来 slave 的单点问题。 **一般情况下，一主一从就够用了** 。来看看复制的流程：

  1. Slave 向 Master 发送 sync 命令，携带 master 的 runId 和数据的 offset；

  * runId 为 master 启动时生成的唯一标识 ID
  * offset 是复制的偏移量，用来记录 Slave 当前时刻同步到的数据的位置。

  1. Master 对比传来的 runId 和自身的 id 是否一致，不一致则进行 **全量复制** 。
  2. Master 对比传来的 offset 是否在缓冲区内，如不在也进行 **全量复制** 。
  3. 如都验证通过，则主服务器将 offset 后的所有数据发送给从服务器。

**主从全量复制流程？**

  1. Master 启动一个后台进程，将 Redis 中的数据快照 rdb 保存到文件中，同时，Master 会将保存数据快照期间接收到的写命令缓存起来。
  2. Master 完成写文件操作后，将 rdb 发送给 Slave，Slave 将 rdb 保存到磁盘上，然后加载 rdb 数据到内存中。
  3. 当 Slave 完成数据快照的恢复后，Master 将这期间收集的写命令发送给 Slave 端。
  4. 后续 Master 收集到的写命令都会通过之前建立的连接，增量发送给 slave 端。

**主从复制的优点？** **数据冗余** ，主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式； **故障恢复**
，当主节点出现问题时，可以临时将从节点设置为主节点提供服务，实现快速的故障恢复； **读写分离，负载均衡**
。主节点负载读写，从节点负责读，提高服务器并发量； **基础服务，** 高可用的方案哨兵模式和集群模式都是 **基于主从来实现** 的。

**主从复制的缺点？** **无法主动进行容错处理和数据恢复** 。主节点宕机会导致客户端程序读写请求失败，要切换客户端 ip 或者重启主节点才能恢复异常；
**无法保证数据的完整性** ，主从数据同步存在一定的延迟，没法做到主从数据的完全一致； **每个节点存全量数据，无法扩容。**

### 哨兵模式

![image.png](https://images.gitbook.cn/2020-06-11-070024.png) **哨兵模式的工作流程？**

  * 每个 Sentinel 进程会定时向所有节点发送 PING，用于 **检测监控节点是否网络可达** ，向被监控的节点发送 INFO，用于 **获得节点信息** 。
  * 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 进程标记为 **主观下线（SDOWN）。**
  * 如果一个 Master 被标记为 SDOWN，则正在监视这个 Master 的所有 Sentinel 进程都要确认这个 Master 是否处于 SDOWN 状态。
  * 当确认该 Master 进入 SDOWN 状态的 Sentinel 达到阈值，则 Master 会被标记为 **客观下线（ODOWN）。**

**哨兵模式的故障恢复流程？**

  1. sentinel 节点选出 leader 来领导完成这次 failover
  2. Leader 选择出最佳的可成为 master 的节点，判断依据是：

  * **配置里的优先级** ，选优先级最高的；
  * **数据的 offset 更新偏移** ，选数据最新的；
  * **runid** ，实例启动时随机生成的 id，选最小的。

  1. 将其它节点设置为新 Master 的 Slave 节点
  2. 完成数据同步

**哨兵模式的优点？** 从架构图其实就已经可以看出来，哨兵模式是基于主从模式的，所以 **主从的优点** ，哨兵模式都具有；哨兵在主从的基础上增加了
**自动切换主节点的功能** ，提高了系统的可用性，不需要客户端再手动切换 IP。

**哨兵模式的缺点？** **数据完整性和无法扩容** 的问题在这个模式下依然存在； **资源浪费** ，slave 的存在仅仅是冷备，无法缓解读压力

### Cluster 模式

![image.png](https://images.gitbook.cn/2020-06-11-070025.png) Redis 集群实现了
**数据分区，将数据分散到多个节点** ，突破了 Redis 单机内存大小的限制。它内置了 **16384 个哈希槽** ，并根据节点数将这些
**哈希槽均匀地映射到不同的节点上** 。当客户端需要对某个 key 值进行操作时，就会算出它的 Hash
值，找到对应的哈希槽和对应的存储节点。集群工作的具体流程如下：

  * Client 向集群中的某个 Master 节点发送 key 相关操作的命令。
  * 该节点计算出这个 key 属于哪个哈希槽。如果该哈希槽在当前节点则直接执行这个命令。
  * 如果在其他节点上，则向客户端返回一个 MOVED 信息，引导客户端 **重定向(redirect)** 到哈希槽所在的节点并执行命令。

**cluster 模式的优点？** cluster 模式会将数据分散到多个节点，不再是单实例存储全量的数据，所以 **存储容量大大增加**
；每个主节点都可以对外提供读写服务， **提高集群的响应能力；集群高可用**
，支持主从复制和主节点的自动故障转移，当任一节点发生故障时，集群仍然可以对外提供服务；可线性扩展到 1000 多个节点 **，节点可动态添加或删除;**
** **cluster 模式的缺点？** 主从数据仍然通过异步复制， **不保证数据的强一致性；无法做资源隔离**
，多个业务使用同一套集群时，容易出现相互影响的情况，比如一个业务出现慢查询会影响整个集群； **不支持多库** ，不好划分业务； **资源浪费**
，slave 的存在仅仅是冷备，无法缓解读压力； **不支持跨节点的事务。**

#### Cluster 模式的集群数据是如何分区的？

**什么是一致性哈希算法？** redis cluster 用的分区方式是“ **带有虚拟节点的一致性哈希分区”，**
在说这种分区方式之前很有必要先说一下一致性哈希算法，首先哈希算法大家应该都熟悉就不再说了，一致性哈希算法跟哈希算法不一样，一致性哈希算法会将服务器节点和数据都通过哈希函数映射到一个首尾相连的哈希环上，然
**后数据按照顺时针的方向查找存储节点，即从数据映射在环上的位置开始，顺时针方向找到的第一个存储节点，那么他就存储在这个节点上** 。
一致性哈希的问题是会造成数据倾斜问题，当一台服务器宕机，那么该服务器上的数据会全部都转移到该服务器的顺时针后继节点上。

**带有虚拟节点的一致性哈希分区？**
![image.png](https://images.gitbook.cn/2020-06-11-70026.png)

带虚拟节点的一致性哈希算法解决了上述的问题，它的核心思想是： **根据每个节点的性能为每个节点划分不同数量的虚拟节点** 即
**槽（slot），并将这些虚拟节点映射到哈希环中，然后再按照一致性哈希算法进行数据映射和存储** 。

如上图，A、B、C 为三台物理服务器，B 的性能是 C 的两倍，A 的性能是 C 的三倍，那么根据上面提到的算法思想，A 有虚拟节点 **A _1、A_
2、A _3_** ，B 有 **B1、B _2_** ，C 有 **C1**
，所有节点均匀分布在哈希环上，落到虚拟节点上的数据都会顺时针存到对应的物理服务器上，所以通过带虚拟节点的一致性哈希算法后，数据存储结果为
data2、data3、data5 存储到服务器 A，data1 存到 B，data4、data6 存到 C 上。

这种分区算法会根据 **每个节点的性能来划分虚拟节点**
，让性能好的服务器存储更多的数据，解决了系统异构性的问题；同时由于大量的虚拟节点分布在哈希环的不同位置，可以 **减小数据迁移时某台服务器的分担压力**
，保证系统的稳定性。

