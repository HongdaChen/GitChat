在前面的 HBase 篇和 ZooKeeper 篇都有稍微提到了一点 CAP 相关的内容，这是分布式系统设计绕不开的一个话题，CAP
理论告诉我们一个真理，“没有最完美的系统，只有最合适的”，我们没法做到面面俱到，但是我们可以根据需求去选择我们需要的特性。大数据的面试这些分布式原理和理论相关的内容是少不了的，这块内容一般会出现在架构设计的场景问题中。

**本篇面试内容划重点：一致性问题。**

### 什么是 CAP？

说 CAP
之前必须要明白的一个问题是，什么是分布式系统？随着技术和社会的发展，互联网服务的用户量和数据量爆发式增长，性能有限和稳定性差的单节点服务逐渐无法满足公司的需求，既然一台服务器不行，那就多台服务器一起提供服务，让多台服务器分担单节点的压力，这就是分布式。分布式系统看起来很美好，能解决扩展性、稳定性、高可用、高性能、高并发等问题，但是其实让多台服务器协同工作并不是那么简单的一件事情，看似美好的同时我们还有很多的问题要解决。比如
CAP 的取舍问题。

在理论计算机科学中，CAP 定理又被称作布鲁尔定理（Brewer's
theorem），它指出对于一个分布式计算系统来说，最多只能满足“一致性（Consistency）”、“可用性（Availability）”和“分区容忍性（Partition
Tolerance）”这三项中的两项：

  * **一致性** ：一致性指的是数据的一致性，即所有节点在同一时间的数据完全一致，客户端在同一时刻无论从哪个节点获取数据都能够获取到相同的结果。
  * **可用性** ：可用性指的是系统服务的可用性，保证每次请求都能获取到系统正常的响应，即服务一直是可用的。
  * **分区容错性** ：分区容错性指的是当部分节点因为网络故障等问题出现消息丢失或者分区失联的情况下，分布式系统仍然能够继续运行。

#### **CAP 的实际应用**

  * CA：放弃分区容错性，选择强一致性和可用性，这是传统的单机数据库的选择。
  * AP：放弃强一致性，追求分区容错性和可用性。这里说的放弃不是指不需要一致性，而是这个一致性可以是弱一致或者最终一致，比如分布式场景中常见的投票问题，半数以上同意即可 commit，这里就是先保证半数以上的节点一致，让结果可用，然后剩下的节点最终一致即可。
  * CP：放弃可用性，追求强一致性和分区容错性。适用于分布式场景下对一致性要求高的场景，比如分布式锁的应用场景，每个节点获取到的锁状态必须是一致的，不然这个锁毫无意义。

![image.png](https://images.gitbook.cn/fcc69c80-ed2c-11ea-a998-0df5aad54339)

根据定理，我们知道 CAP 三个特性只能三选二，但是如果我们放弃了分区容错性就是上述 CA
的单机场景，而不是我们讨论的分布式场景了，所以对于分布式系统而言，网络问题是一个必定会出现的异常情况，因此分区容错性也就成为了一个分布式系统必然需要面对和解决的问题，即如何保证单台节点宕机失联的情况下不影响整个集群的正常运行，所以
Partition Tolerance 是必须的，我们只能基于“P”来选择“C”、“A”了。

看几个 CAP 在大数据组件中的实际例子：

  * HBase 是个“CP”系统，在网络分区 RegionServer 失联时，HBase 首先保证的是数据的一致性，不出现多个版本的数据，因为一条数据只会存在在一个 Region 中，RegionServer 宕机期间，Region 的数据是无法正常提供服务的。
  * ZooKeeper 也是个“CP”系统，但是我觉得严格来说它把“CP”、“AP”的选择权交给了用户，为了保证强一致性 ZooKeeper 提供了 sync 的方式来写数据，所有节点写入成功才算是写入成功，能够保证所有节点的数据完全一致。但是 sync 会带来一些延迟的问题，有些场景是需要保证较强的可用性，对一致性的要求没有那么高，所以 ZooKeeper 还提供了“一半以上成功即成功”的数据同步方式，这可能会导致部分节点的数据不一致。这相当于把 C 和 A 的选择问题交给了用户。

上述 AP 的架构中我们提到了一个名词“最终一致性”，对于 AP 来说，放弃强一致性，追求分区容错性和可用性，这是很多分布式系统设计时的选择，但是 AP
不代表放弃一致性，而是对一致性做了妥协，允许最终一致，后面要说的 Base 就是根据 AP 扩展而来的一个理论。

### 什么是 BASE 理论？

为了能够适用于更多有不同的一致性要求的场景，CAP 理论衍生出了 BASE 理论，它强调的是系统的最终一致性，对可用性和一致性方面都做了一些妥协，BASE
理论主要包括一下三方面的内容。

  * Basically Available（基本可用）
  * Soft state（软状态）
  * Eventually consistent（最终一致性）

#### **基本可用性 Basically Available**

基本可用指的是系统发生故障时，允许系统损失部分的可用性（可以是损失性能也可以是功能），但是系统整体而言还是可用的，相当于提供了一个降级服务。

  * 性能：即响应时间的延迟，对于一个分布式的服务，可能正常的情况下，多个节点同时处理数据，可以做到负载均衡，响应时间短，当某几个节点宕机时，整体上还是可用的，只是处理数据的节点减少了，所以响应就会有所延迟。
  * 功能：即减少一些功能，提供一个降级服务，保证服务整体上是正常运行的，比如正常的情况下接口服务返回的是实时的报表结果，但是由于实时计算环节的异常，服务无法获取到实时结果，只能提供 T+1 的计算结果，这就是降级服务的一种。

#### **软状态 Soft state**

软状态是指允许系统存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。举个例子，ZooKeeper
非 sync
同步的场景下，半数以上同步成功就算是成功，所以可能存在少数副本短暂地数据不一致的情况，这种情况下的状态就可以称为软状态，明显这个软状态的存在不会影响系统的整体可用性。

#### **最终一致性 Eventually consistent**

最终一致性就是字面上意思，无论过程如何，最终的状态一定是一致的，强调的是结果，即系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。ZooKeeper
仍然是个很好的例子，sync 场景下保证的是强一致性，每个副本都写入数据才能算是写入成功，即保证了系统的实时强一致性，任何时刻所有副本数据都是一致的，而非
sync 场景下保证的是最终一致性。

总的来说，BASE 强调的是最终一致性，无论过程如何，结果一致即可，这是分布式系统为了保证可用性比较常见的一种设计思路，与传统数据库 ACID
追求强一致性模型的设计理念刚好是相反的。

