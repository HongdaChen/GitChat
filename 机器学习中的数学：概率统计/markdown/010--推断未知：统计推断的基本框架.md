### 进入统计学

从这一讲开始，我们进入到统计推断的主题。

统计学使用概率论的基本方法，研究怎样通过试验收集带有随机误差的样本数据，并在设定的统计模型之下，进行后续的研究工作，主要分为两大类：

  * 第一类是对这些已有的样本数据进行分析，计算它们的一些统计特征，比如样本均值、方差等等，即 **描述统计** 的范畴。
  * 第二类是更重要的，是通过这些已有的样本数据，对整个未知的总体进行推断，估计出总体当中我们感兴趣的未知参数值，即 **统计推断** 的工作，这是我们重点关注的内容。

那我们为什么需要关注统计推断的方法呢？因为，当我们需要对一个未知的对象进行分析时，一般需要通过获取数据来分析这个对象，但在现实当中，我们只能获取一部分数据而无法获取总体的全部数据。而统计推断研究的就是通过部分的样本数据来推断总体统计特征的方法。

上面的描述当中，有很多的术语和概念，为了便于大家理解，我们来举一个统计推断的例子。

### 统计推断的例子

有一家企业生产电子元器件，这些元器件的寿命服从指数分布，那么我们如何估计这些元器件的平均寿命呢？如果我们知道这个指数分布的参数 $\lambda$
的值，则可以马上回答这个问题：即平均寿命 $=\frac{1}{\lambda}$。但是现实往往是残忍的，我们在实际当中根本就不可能知道 $\lambda$
的值。

于是，我们只好从工厂所有生成的元器件当中随机抽取出 $n$ 个元器件，并测出其寿命分别为
$X_1,X_2,...,X_n$。注意此处有一个重要的前提，那就是我们需要保证这一大批元器件当中，每一个元器件都有等概率被抽取的机会。

这时候，当我们有了数据 $X_1,X_2,...,X_n$ 之后，一个自然而然的想法就是：通过计算，我们用这些样本数据的平均值
$\bar{X}=\frac{X_1+X_2+...+X_n}{n}$ 去作为所有元器件未知平均寿命 $\frac{1}{\lambda}$
的一个估计值。当然， $\bar{X}$ 可能大概率恰好不等于
$\frac{1}{\lambda}$。不过请不要担心，我们在实际的工程和研究当中，本来也不可能要求它们做到完全相等，只要具体满足一些性质和要求就可以了，那么具体应该满足什么要求，我们下面接着慢慢讲。

### 统计推断中的一些重要概念

#### 统计推断的过程总结

上面描述的就是统计推断中的一个简单的参数估计问题，因为 $\lambda$ 是元件寿命这个指数分布中的一个未知参数，而我们的目标是要估计由参数
$\lambda$ 决定的一个量，即 $\frac{1}{\lambda}$，也可以把估计的目标改为是要求估计参数 $\lambda$ 本身。然后再用参数
$\lambda$ 的估计值，回过头来计算我们想要知道的所有元器件的平均寿命，即：$平均寿命=\frac{1}{\lambda}$。

下面，我们就结合例子来讲讲总体、样本的具体概念。

#### 总体的概念

总体是指与所研究的问题有关的 **对象全体**
构成的集合。在上面的那个例子当中，工厂生产的所有电子元器件就是问题的总体，而其中每一个元器件就是一个个的个体，所有这些个体构成了问题的总体。

我们的电子元器件总体的寿命分布为指数分布，总体分布的概率模型不同，分析的方法也就不同，赋有一定概率分布的总体也称之为统计总体。因此，当总体分布为指数分布时，称之为指数分布总体，同样的，当总体分布为正态分布时，就称为是正态分布总体。

别以为这样就完了，其实总体的概念中还有许多概念值得深挖。

一方面是，虽然我们假设了电子元器件总体的寿命服从指数分布，但是其中的参数值 $\lambda$ 并没有指定，那么这个未知的 $\lambda$
原则上是可以取 $0 - \infty$ 内的任何值的。因此更正确的说法是，总体分布是一个概率分布族的一员。像指数分布这种，只包括一个参数
$\lambda$ 的，称作是单参数分布族，而像正态分布 $N(\mu,\sigma^2)$ 这种包含两个参数的分布，则是一个两参数分布族。

另一方面：在很多实际情况下，我们只能假定总体有一定的概率分布，但是无法明确其具体的数学形式，更不用说表示成我们熟悉的标准分布的形式了。当总体分布不能通过若干个未知参数表达出来的时候，这种情况称之为是非参数总体。对于非参数总体，同样存在统计推断的问题，例如去估计平均值、方差等重要的统计量，这是实际中更加常见的工作。

#### 样本的概念

有了总体的概念，我们再来看看样本。样本就是按照一定的规定，从总体中抽取出来的一部分个体，所谓“按照一定的规定”，就是指总体中的每一个个体拥有同等的被抽取的机会。

样本 $X_1,X_2,...,X_n$ 中的 $n$ 称为是样本大小或样本容量。我们也可以把 $X_1,X_2,...,X_n$ 称之为是一组样本，而
$X_i$ 称为是其中的第 $i$ 个样本。

一般而言，如果总体当中包含了大量的甚至是无限多个的个体，抽掉 $1$ 个或 $n$ 个个体，对总体的分布几乎没有影响，因此样本
$X_1,X_2,...,X_n$
是独立同分布的，它们的公共分布就是总体分布。这是应用上最为常见的情形，也是我们主要的研究目标。但是如果当总体所含的个体数目不太大时，情况就不同了。放回式抽样还是不放回抽样也要作为一个要素加入到统计模型的内容中来。

总结一下，在无限（或样本量极大）总体或者是在有限总体而抽样有放回的情况下，总体分布完全决定了样本的分布。

#### 统计量

完全由样本所决定的量叫做统计量，这里意味着，统计量只依赖于样本，而不依赖于任何其他未知的量，尤其是不能依赖于总体分布中所包含的未知参数。

很拗口吧，还是来看个例子。

例如我们从正态总体 $N(\mu,\sigma^2)$ 中抽取出样本 $X_1,X_2,...,X_n$，那么样本均值
$\bar{X}=\frac{X_1+X_2+...+X_n}{n}$ 就是一个统计量，因为它完全由样本 $X_1,X_2,...,X_n$
所决定。但是如果式子中包含了 $\mu$ 或者 $\sigma$，类似于 $\bar{X}-\mu$ 这种，就不是统计量了，因为 $\mu$
是总体的未知参数，$\bar{X}-\mu$ 并不完全由样本所决定。

这里面的道理很简单，统计量可以看做是对样本的一种加工，它把样本中所含的信息集中起来。目的就是用来估计总体当中的未知参数，如果此时在里面反而还包含了未知参数，显然就失去了意义。

一般而言，我们会使用样本均值 $\bar{X}=\frac{X_1+X_2+...+X_n}{n}$ 去作为总体均值的估计。

那么，如果想了解总体方差 $\sigma^2$ 的情况，则统计量 $\bar{X}$ 就派不上用场了，而应该使用样本方差
$S^2=\frac{1}{n-1}\sum_{i=1}^{n}{(X_i-\bar{X})^2}$ 去作为总体方差 $\sigma^2$ 的估计。

#### 样本矩

推而广之，有一类重要的统计量叫做样本矩，分为样本原点矩和样本中心矩，对于样本 $X_1,X_2,...,X_n$：

  * $a_k=\frac{X_1^k+X_2^k+...+X_n^k}{n}$ 称为 $k$ 阶样本原点矩，其中的一阶样本原点矩 $a_1=\frac{X_1+X_2+...+X_n}{n}$ 是一个非常重要的样本原点矩，也就是样本均值。
  * 而 $m_k=\frac{\sum_{i=1}^{n}{(X_i-\bar{X})^k}}{n}$，则被称为是 $k$ 阶样本中心矩。

### 估计量的偏差与无偏估计

其实看到这个地方，大家一定会有这样一个疑问，那就是为什么作为总体均值估计量的样本均值是
$\bar{X}=\frac{X_1+X_2+...+X_n}{n}$，而作为总体方差估计量的样本方差一般使用的是
$S^2=\frac{1}{n-1}\sum_{i=1}^{n}{(X_i-\bar{X})^2}$，为什么是除以 $n-1$，而不是除以 $n$。

这就涉及到估计的无偏性的问题了，这里我们先不一上来就解释无偏性的定义和概念，先来实际看一个例子吧。

#### 总体均值的估计

我们做一个小实验，我们从均值为 $0$，标准差为 $1$ 的标准正态分布中获取样本，每次获取 $100$ 个样本值，然后按照
$\bar{X}=\frac{X_1+X_2+...+X_n}{n}$ 来计算统计量，我们重复实验 $100$ 万次，把 $100$
万次得到的统计量绘制成直方图，看看它们的分布。同时计算出这 $100$
万个估计量的均值（按照大数定理可以认为它就是期望了），并与待估计量，也就是真实的总体均值进行比较。

**代码片段：**

    
    
    from scipy.stats import norm
    import matplotlib.pyplot as plt
    import numpy as np
    import seaborn
    
    seaborn.set()
    
    norm_rv = norm(loc=0, scale=1)
    x = np.linspace(-1, 1, 1000)
    
    sample_n = 100
    x_array = []
    for i in range(1000000):
        norm_rvs = norm_rv.rvs(size=sample_n)
        x_bar = sum(norm_rvs) / float(sample_n)
        x_array.append(x_bar)
    
    print(np.mean(x_array))
    plt.hist(x_array, bins=100, normed=True, alpha=0.6)
    plt.axvline(0, ymax=0.8, color='r')
    plt.gca().axes.set_xlim(-0.4, 0.4)
    plt.show()
    

**运行结果：**

    
    
    8.422755440900372e-06
    

![图1.总体均值估计量的分布](https://images.gitbook.cn/11c2f830-c2ff-11e9-91a7-bbf72a7d1a0f)

很显然，作为估计值的随机样本统计量（在这个例子中就是 $100$ 个个体的样本均值）肯定不可能和未知参数（总体的均值
$\mu$）完全相等，它们之间一定存在着非零的 **估计误差** 。

但是一个好的估计量应该具备这样的性质，那就是这个估计误差的期望为 $0$。换句话说，也就是估计值的期望应该等于被估计的未知参数的真值。这个性质叫作
**无偏性** ，这样的估计值称作是 **无偏** 的。

可以看出 $\bar{X}=\frac{X_1+X_2+...+X_n}{n}$
是对总体均值的一个很好的估计，因为它均匀地分布在待估计参数真实值的周围，并且最为关键的是，它的期望（近似计算出的均值
$8.422755440900372e-06 \approx 0$）就是总体的均值，因此样本均值
$\bar{X}=\frac{X_1+X_2+...+X_n}{n}$ 就是总体均值的无偏估计。

证明过程也很简单：

$E(\bar{X})=E(\frac{X_1+X_2+...+X_n}{n})$
$=\frac{1}{n}(E(X_1)+E(X_2)+...+E(X_n))$ $=\frac{1}{n}(n\mu)=\mu$

#### 总体方差的估计

同样我们再看看，如果把 $\frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X})^2}$ 作为总体方差的估计，到底合不合适。

同样的，我们还是从均值为 $0$，标准差为 $1$ 的标准正态分布中获取样本，每次获取 $100$ 个样本值，然后按照
$\frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X})^2}$ 来计算统计量，我们重复实验 $100$ 万次，把 $100$
万次得到的统计量绘制成直方图，看看它们的分布，并与真实的总体方差进行比较。

**代码片段：**

    
    
    from scipy.stats import norm
    import matplotlib.pyplot as plt
    import numpy as np
    import seaborn
    
    seaborn.set()
    
    norm_rv = norm(loc=0, scale=1)
    x = np.linspace(0, 2, 1000)
    
    sample_n = 100
    s_array = []
    for i in range(1000000):
        norm_rvs = norm_rv.rvs(size=sample_n)
        x_bar = sum(norm_rvs) / float(sample_n)
        s = sum(np.square((norm_rvs - x_bar))) / float(sample_n)
        s_array.append(s)
    
    print(np.mean(s_array))
    plt.hist(s_array, bins=100, normed=True, alpha=0.6)
    plt.axvline(1, ymax=0.8, color='r')
    plt.gca().axes.set_xlim(0.4, 1.6)
    plt.show()
    

**运行结果：**

    
    
    0.989923522772342
    

![图2.总体方差估计量的分布](https://images.gitbook.cn/9e4e4750-c2ff-11e9-aa00-e5083e774830)

总体方差的真实值是 $1$，而这里我们发现样本统计量的期望为
$0.9899$，是要明显小于实际的方差真实值的。并且更重要，也更直接的是，我们从图上可以看出整个 $100$
万个统计结果的分布是整体偏左的，也就是整体偏小的。

这意味着 $\frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X})^2}$
作为总体方差的估计是带有系统误差的，它并不是一个无偏估计，而是有偏的。

那么这个系统偏差是多大？我们应该如何调整，从而得到总体方差的无偏估计呢？我们下面来进行严密的推理证明。

对于一个一般性的总体，我们假设它的总体均值的真值是 $\mu$，总体方差的真值是 $\sigma^2$，样本均值是 $\bar{X}$，我们来计算估计量
$\frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X})^2}$ 的期望：

$E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\bar{X})^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}((X_i-\mu)-(\bar{X}-\mu))^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}((X_i-\mu)^2-2(\bar{X}-\mu)(X_i-\mu)+(\bar{X}-\mu)^2)]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2-\frac{2}{n}(\bar{X}-\mu)\sum_{i=1}^{n}(X_i-\mu)+\frac{1}{n}\sum_{i=1}^{n}(\bar{X}-\mu)^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2-\frac{2}{n}(\bar{X}-\mu)\sum_{i=1}^{n}(X_i-\mu)+(\bar{X}-\mu)^2]$

我们进一步进行推导：

$$\bar{X}-\mu=\frac{1}{n}\sum_{i=1}^{n}X_i-\mu$$
$$=\frac{1}{n}\sum_{i=1}^{n}X_i-\frac{1}{n}\sum_{i=1}^{n}\mu=\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)$$

因此，我们有：

$$\sum_{i=1}^{n}(X_i-\mu)=n(\bar{X}-\mu)$$

我们把这个关系式带回到等式当中：

$E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2-\frac{2}{n}(\bar{X}-\mu)\sum_{i=1}^{n}(X_i-\mu)+(\bar{X}-\mu)^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2-\frac{2}{n}(\bar{X}-\mu)n(\bar{X}-\mu)+(\bar{X}-\mu)^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2-\frac{2}{n}(\bar{X}-\mu)n(\bar{X}-\mu)+(\bar{X}-\mu)^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2-2(\bar{X}-\mu)^2+(\bar{X}-\mu)^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2-(\bar{X}-\mu)^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2]-E[(\bar{X}-\mu)^2]$

之前我们学过，方差 $\sigma^2$ 的定义是随机变量到总体均值之差的平方的期望：

$$\sigma^2=E[(X-\mu)^2]$$

并且，我们说过，样本服从总体的分布，因此 $E[X_i]=E[X]$

$E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2]$
$=E[\frac{1}{n}n(X-\mu)^2]=E[(X-\mu)^2]=\sigma^2$

显然：

$E[(\bar{X}-\mu)^2]$ $=E[(\frac{X_1+X_2+X_3+...+X_n}{n}-\mu)^2]$
$=E[(\frac{1}{n}(X_1+X_2+X_3+...+X_n-n\mu))^2]$
$=E[\frac{1}{n^2}((X_1-\mu)^2)+(X_2-\mu)^2)+...(X_n-\mu)^2)]$
$=\frac{1}{n}E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2]$

曙光已经初现，我们把它合并回等式中去：

$E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2]-E[(\bar{X}-\mu)^2]$
$=E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2]-\frac{1}{n}E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2]$
$=\frac{n-1}{n}E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2]$
$=\frac{n-1}{n}\sigma^2$

看到了吗？我们的估计值的期望：

$$E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\bar{X})^2]=\frac{n-1}{n}\sigma^2$$

这就是它为什么整体偏小的原因，原来它的期望并不是总体的方差，而是方差的 $\frac{n-1}{n}$。回想一下吧，我们总体方差的真实值是
$1$，我们的样本容量是 $100$，那么我们这个估计值的期望就是 $\frac{99}{100}=0.99$，是不是正好和我们上面的试验结果一样呢？

那么如果想要得到总体方差的无偏估计，就得修正我们统计量的表达式，很简单，由于：

$$E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\bar{X})^2]=\frac{n-1}{n}\sigma^2$$

那么：

$$\frac{n}{n-1}E[\frac{1}{n}\sum_{i=1}^{n}(X_i-\bar{X})^2]=\sigma^2$$

最后稍作整理：

$$E[\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2]=\sigma^2$$

因此这就是为什么总体方差的无偏估计是 $\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2$，而不是
$\frac{1}{n}\sum_{i=1}^{n}(X_i-\bar{X})^2$ 的原因了。

最后我们把上面的代码中，方差估计的表达式调整成 $\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2$：

    
    
    s = sum(np.square((norm_rvs - x_bar))) / float(sample_n-1)
    

观察一下试验结果：

**运行结果：**

    
    
    1.0000016490508186
    

![图3.总体方差无偏估计的分布](https://images.gitbook.cn/17a50da0-c300-11e9-9041-1ba73b00aa3e)

从结果中我们可以看出：方差估计值的期望和总体方差一致，结果是无偏的，正是我们想要的。

### 小结

在本篇中，我们系统地讲述了统计推断的基本概念，那么具体在工程实践中有哪些实际使用的方法呢？我们在后面两篇里会详细的介绍。

