有了前面两讲的理论铺垫，我们对矩阵相似和对角化有了深入了解，最终，我们的落脚点就是特征值和特征向量。在这一讲当中，我们将这一块儿的内容彻底解决，一方面系统性地梳理一下的相关重要特性，另一方面从技术层面来讲解特征值和特征向量的求解方法。

### 几何意义回顾

我们简要的再回顾一下 $Ap=\lambda p$ 这个核心表达式：从空间几何意义的角度来理解，对于一个方阵 A，若 p 是的特征向量，$\lambda$
是对应的特征值，则意味着向量 p 在方阵 A 的作用下，的空间变换就是其长度沿着向量的方向进行 $\lambda$ 倍的伸缩。

所表达的几何意义简单、明晰。一般来说，一个向量在某个矩阵的作用下，其空间变换反映为长度和方向的改变：即旋转、平移和拉伸，有些情况下甚至连维度都会发生变化，而这里的特殊之处就在于，矩阵作用于它的特征向量，仅仅只有长度发生了改变。

### 一系列重要性质

那么我们结合特征向量和特征值的几何意义，很容易分析出一些显而易见的结论。

#### 基本几何性质

我们针对性的讨论一些有意思的特殊情况：

1\. 特征值为 0 的情况。如果一个方阵 A 的某个特征值为 $\lambda=0$，那么当该矩阵作用在其对应的特征向量 p
上时，就有：Ap=0p=0。这意味着，该矩阵的零空间是非零向量
p，该矩阵表示的是空间压缩变换。依据之前学习的有关知识我们知道，这就是一个不可逆的矩阵，即奇异矩阵。

2\. 对角矩阵的情况。对角矩阵 $diag(1,2,3)$，其特征值就是 1、2、3，对应的特征向量即为：

$$\begin{bmatrix} 1\\\0\\\0 \end{bmatrix}，\begin{bmatrix} 0\\\1\\\0
\end{bmatrix}，\begin{bmatrix} 0\\\0\\\1 \end{bmatrix}$$

3\. 相似矩阵的情况。如果矩阵 A 的特征向量为 p，特征值为 $\lambda$，那么它的相似矩阵 $S^{-1}AS$ 的特征值不变，仍为
$\lambda$，特征向量变为了 $S^{-1}p$。这个性质的验证非常简单：

$$(S^{-1}AS)(S^{-1}p) =S^{-1}ASS^{-1}p =S^{-1}Ap $$ $$=S^{-1}\lambda p
=\lambda (S^{-1} p)$$

即：$(S^{-1}AS)(S^{-1}p)=\lambda (S^{-1} p)$，结论一目了然。

#### 特征向量的线性无关性讨论

1\. 如果一个 n 阶方阵 A，有 n 个两两不相同的特征值
$\lambda_{1},\lambda_{2},...,\lambda_{n}$，那么这些特征值所对应的特征向量
$p_{1},p_{2},...,p_{n}$ 线性无关。

这个道理很容易明白。我们可以用反证法进行简单的证明：

> 我们假设 $\lambda_{1}\ne \lambda_{2}$，而其对应的特征向量 $p_{1}$ 和 $p_{2}$ 线性相关，即 $p_{1}
> = \alpha p_{2}$，那么，$Ap_{1}$$=\alpha A p_{2}$ $=\alpha\lambda_{2}p_{2}$ $=
> \lambda_{2}p_{1}$；同时我们知道，$Ap_{1}=\lambda_{1}p_{1}$，那么就得满足 $\lambda_{1}p_{1}
> = \lambda_{2}p_{1}$，由于 $p_{1}\ne o$，则必须要求
> $\lambda_{1}=\lambda_{2}$，而这，与我们的假设是显然矛盾的。

感觉还差点味儿，我们还得拓展到多个向量的线性无关性上来，我们举三个向量的例子看看，假设 $\lambda_1 \ne \lambda_2 \ne
\lambda_3$，而却有对应的三个特征向量线性相关，即 $p_1=\alpha p_2+\beta p_3$，其中，$\alpha,\beta \ne
0$（即 $p_1$ 和 $p_2$ 之间以及 $p_1$ 和 $p_3$ 之间是线性无关的）。

两边同时乘以矩阵 A：

$$Ap_1=A(\alpha p_2+\beta p_3) =\alpha Ap_2+\beta Ap_3$$

进一步处理有：$\lambda_1p_1=\lambda_2 \alpha p_2+\lambda_3 \beta p_3$，代入等式 $\alpha
p_2=p_1-\beta p_3$，我们最终整理得到一个等式：

$$(\lambda_1-\lambda_2)p_1+(\lambda_2-\lambda_3)\beta p_3=0$$

由于 $p_1$ 和 $p_3$ 是线性无关的，要满足等式成立，则要求
$\lambda_1=\lambda_2,\lambda_2=\lambda_3$。显然也与假设矛盾。

2\. 接着上面的推理，如果 n 阶方阵 A 有 n
个特征值：$\lambda_{1},\lambda_{2},...,\lambda_{n}$，且其两两不同，那么其特征向量
$p_{1},p_{2},...,p_{n}$ 依次排列所组成的方阵 P 就是可逆的，依据上一节所讲的内容，通过 $P^{-1}AP=\Lambda$
可以将其对角化，其中 $\Lambda=diag(\lambda_{1},\lambda_{2},...,\lambda_{n})$。

3\. 由此我们得知：不同的特征值肯定对应着线性无关的特征向量，但是不能说相同的两个特征值对应的特征向量就一定线性相关，比如我们最熟悉的单位对角矩阵
$diag(1,1,1)$，它的三个特征值都是 1，但是其特征向量分别是:

$$\begin{bmatrix} 1\\\0\\\0 \end{bmatrix}，\begin{bmatrix} 0\\\1\\\0
\end{bmatrix}，\begin{bmatrix} 0\\\0\\\1 \end{bmatrix}$$

### 特征值与特征向量的求解方法

我们熟悉了特征向量、特征值的一些几何特性，那最后我们来看看应该如何利用 Python 工具对其进行求解呢？很简单，我们看看以下几种情况。

#### 特征值不相等的情况

首先看一个简单的 2 阶方阵：

$$A=\begin{bmatrix} 2&1 \\\ 1&2\end{bmatrix}$$

我们来求它的特征值和特征向量：

**代码片段：**

    
    
    import numpy as np
    from scipy import linalg
    
    A = np.array([[2, 1],
                  [1, 2]])
    
    evalue, evector = linalg.eig(A)
    print(evalue)
    print(evector)
    

**运行结果：**

    
    
    [ 3.+0.j  1.+0.j]
    [[ 0.70710678 -0.70710678]
     [ 0.70710678  0.70710678]]
    

程序返回的特征根是 evalue，分别是 3 和 1。而变量 evector
所表示的是由特征向量组成的特征矩阵，在这个矩阵中，每一列都是与特征值依序对应的特征向量。因此特征值 3 对应的特征向量为 $\begin{bmatrix}
0.7071\\\0.7071 \end{bmatrix}$，特征值 1 对应的特征向量为 $\begin{bmatrix}
-0.7071\\\0.7071\end{bmatrix}$。

特别补充一句，我们按照大学课堂里教的特征方程定义法，笔算求得的特征向量会是 $\begin{bmatrix} 1\\\1 \end{bmatrix}$ 和
$\begin{bmatrix} -1\\\1\end{bmatrix}$，和我们程序算出来的本质是一样的。Python
程序里结果数字不太好看，实质上是因为被处理成模长为 1 的单位向量了。

再看一个三阶方阵：

$$A=\begin{bmatrix} 1&0&0 \\\ 0&2&0\\\ 0&0&5\end{bmatrix}$$

我们还是用同样的方法来求其特征值和特征向量。当然这个例子我们一眼就能看出结果，这里我们的目的是来展现一下如何利用 Python 进行求解。

**代码片段：**

    
    
    import numpy as np
    from scipy import linalg
    
    A = np.array([[1, 0, 0],
                  [0, 2, 0],
                  [0, 0, 5]])
    
    evalue, evector = linalg.eig(A)
    print(evalue)
    print(evector)
    

**运行结果：**

    
    
    [ 1.+0.j  2.+0.j  5.+0.j]
    [[ 1.  0.  0.]
     [ 0.  1.  0.]
     [ 0.  0.  1.]]
    

从结果中我们可以看出，它的三个特征值分别为 1、2、5，对应的特征向量分别为

$$\begin{bmatrix} 1\\\0\\\0 \end{bmatrix},\begin{bmatrix} 0\\\1\\\0
\end{bmatrix},\begin{bmatrix} 0\\\0\\\1 \end{bmatrix}$$

这两个例子都没有特殊情况，它们的特征值两两不相等，因此其对应的特征向量线性无关，组成的特征矩阵可逆。

#### 有特征值相等的情况

那我们再看一组特殊的例子，正如我们说的，如果有两个相同的特征值，其特征向量会表现如何？

**幸运的情况：**

我们来看这个矩阵的情况：

$$A=\begin{bmatrix} 1&6&0 \\\2&2&0\\\0&0&5\end{bmatrix}$$

**代码片段：**

    
    
    import numpy as np
    from scipy import linalg
    
    A = np.array([[1, 6, 0],
                  [2, 2, 0],
                  [0, 0, 5]])
    
    evalue, evector = linalg.eig(A)
    print(evalue)
    print(evector)
    

**运行结果：**

    
    
    [-2.+0.j  5.+0.j  5.+0.j]
    [[-0.89442719 -0.83205029  0.        ]
     [ 0.4472136  -0.5547002   0.        ]
     [ 0.          0.          1.        ]]
    

从结果中我们可以看出，它有一个 2 重的特征值 5 和另一个特征值 -2，但是幸运的是对于 2 重特征值 5，我们可以找到两个线性无关的特征向量
$\begin{bmatrix} -0.8321\\\\-0.5547\\\0 \end{bmatrix}$ 和 $\begin{bmatrix}
0\\\0\\\1 \end{bmatrix}$，联合另一个特征值 -2 对应的特征向量 $\begin{bmatrix}
-0.8944\\\0.4472\\\0 \end{bmatrix}$（当然这三个向量也是模长为 1
的单位向量），我们依旧找到了三个线性无关的特征向量，组成了一个可逆的特征矩阵，依照定理，该矩阵也是可以进行对角化的。

**不太走运的情况：**

正如我们在上一段中说的，这个有 2 重特征根的矩阵 A，幸运的拥有 3 个线性无关的特征向量，那换言之，是不是还有不幸的情况呢？是的。

我们再看看这个例子：

$$A=\begin{bmatrix} 6&-2&1 \\\ 0&4&0\\\0&0&6\end{bmatrix}$$

**代码片段：**

    
    
    import numpy as np
    from scipy import linalg
    
    A = np.array([[6, -2, 1],
                  [0, 4, 0],
                  [0,0,6]])
    
    evalue, evector = linalg.eig(A)
    print(evalue)
    print(evector)
    

**运行结果：**

    
    
    [ 6.+0.j  4.+0.j  6.+0.j]
    [[  1.00000000e+00   7.07106781e-01  -1.00000000e+00]
     [  0.00000000e+00   7.07106781e-01   0.00000000e+00]
     [  0.00000000e+00   0.00000000e+00   1.33226763e-15]]
    

我们发现，同样的，这个矩阵有 2 重特征值 6，但是这次就没有那么好的运气了，我们发现 2 重特征值对应的两个特征向量 $\begin{bmatrix}
1\\\0\\\0 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\\0\\\1.33e-15 \end{bmatrix}$
是线性相关的（机器运算的结果，可视作：$1.33e-15\approx 0$），因此组成的特征矩阵不可逆，自然矩阵 A
就无法按照我们之前介绍的方法进行对角化了。

那么此时我们该怎么办，怎么对其进行对角化呢？这里我们只简单地提一句：面对这种情形，我们需要通过其他方式，将其化作与对角矩阵非常接近的 Jordan
标准型，有兴趣的话可以查阅其他有关资料，我们就不过多地展开了。

### 小结

那么结合讨论的几个例子，我们来总结一下。

对于一个 n 阶方阵 A，包括多重特征值在内，一共有 n 个特征值。对于任意特征值，如果对应的线性无关的特征向量与其重数相同，即：其一共有 n
个线性无关的特征向量，那么组成的特征矩阵可逆，矩阵 A 可以对角化。

