在前面几节我们学习的都是 **单向的 RNN**
，单向的结构有个局限，就是在当前时间点上只能利用过去的信息，而无法利用未来的序列信息的，这会影响一些需要上下文背景的任务效果。

例如命名实体识别中，有些名字在某些语境中也许代表的是玩具的名字，如果不考虑下文，很可能就被识别为人名；或者在手写识别中，知道当前位置的前面和后面是什么样子的，可以更好地判断这是什么字，提高预测准确率；又或者想要预测序列中的缺失值，就不仅要考虑它前面的词，还要考虑后面的词是什么；此外还可以用于语音识别、机器翻译、蛋白质结构预测、词性标注、依赖解析等任务中。

为了对单向结构的这个局限做出改进，于是就有了双向 RNN。

### 什么是双向 RNN

![](https://images.gitbook.cn/00b491f0-6f1d-11ea-9d98-f7fceb2428d3)

如上图所示，Bidirectional Recurrent Neural Networks—— **双向 RNN** 就是把两个普通的单向 RNN
叠加在一起，输入序列以正向的时间顺序输入进其中一个网络，再以反向的时间顺序输入进另一个网络，这样就分别从两个方向计算序列的 output 和
state，然后将两个网络的激活值连接起来计算最终的输出值 y，有时也可以用求和的方式，这样
**在每个时间点，既可以利用之前的序列信息，也可以利用之后的序列信息** 。

下面我们来举个例子更具体地看一下这个模型：

![](https://images.gitbook.cn/9bb4a270-6f1e-11ea-8807-c9303eb74ab1)

**例如，我们有 $x_1$ 到 $x_4$ 四个词，想要得到 $t=3$ 时刻的预测值 $y_3$：**

  * 首先计算前向的隐藏层单元，我们用右箭头表示前向，用 $x_1$ 计算得到 $h_1$，然后用 $x_2$ 和 $h_1$ 得到 $h_2$，同理得到 $h_3$。
  * 再计算反向的隐藏层单元，用左箭头表示，用 $x_4$ 得到 $h_4$，流到 $x_3$，由 $x_3$ 和 $h_4$ 计算出 $h_3$。注意，反向的这个 RNN 实际上也是在做前向传播，只不过是从序列的末端开始向前输入数据，而且正向的节点和反向的节点是不共用的。
  * 最后可以计算 $t=3$ 时刻的预测值 $y_3$ 了，这时需要将正向 $h_3$ 和 反向 $h_3$ 合在一起。

**用公式表示为：**

$$\overrightarrow{h_t} = f( \overrightarrow{W} x_t + \overrightarrow{V}
\overrightarrow{h}_{t-1} + \overrightarrow{b} )$$

$$\overleftarrow{h_t} = f( \overleftarrow{W} x_t + \overleftarrow{V}
\overleftarrow{h}_{t+1} + \overleftarrow{b} )$$

$$y_t = g( U h_t + c ) = g( U [ \overrightarrow{h_t} ; \overleftarrow{h_t} ] +
c )$$

这样得到的 $y_3$ 既有了过去的信息 $x_1$、$x_2$，和当前的信息 $x_3$，还有未来的信息 $x_4$。

**此外可以看到在 BRNN 这个图中有六个权重** ，分别为：向前/向后各自的输入层与隐藏层之间的 $(w_1,w_4)$，隐藏层到隐藏层的
$(w_2,w_5)$，隐藏层到输出层的 $(w_3,w_6)$，注意向前和向后两个网络的隐含层之间是没有联系的。

![](https://images.gitbook.cn/d953a0e0-6f1e-11ea-832c-2703165cf4af)

**另外 RNN 的这些单元可以是标准的 RNN，也可以是 GRU、LSTM 单元** ，在 NLP 任务中比较常用的是 LSTM 单元。

### 多层双向 RNN

双向 RNN 也可以像单向的一样叠加多层，结构如下：

![](https://images.gitbook.cn/f30207c0-6f1e-11ea-9591-0102be8ba87c)

图片来源：[wildml](http://www.wildml.com/2015/09/recurrent-neural-networks-
tutorial-part-1-introduction-to-rnns/)

从第二层开始，每个神经元接收来自同一层的前一时刻的激活值，和前一层传递过来的两个值，一个是正向得到的，一个是反向得到的。

用公式表示为：

$$\overrightarrow{h^i_t} = f( \overrightarrow{W^i} h^{i-1}_t +
\overrightarrow{V^i} \overrightarrow{h^i}_{t-1} + \overrightarrow{b^i} )$$

$$\overleftarrow{h^i_t} = f( \overleftarrow{W^i} h^{i-1}_t +
\overleftarrow{V^i} \overleftarrow{h^i}_{t+1} + \overleftarrow{b^i} )$$

$$y_t = g( U h_t + c ) = g( U [ \overrightarrow{h^L_t} ; \overleftarrow{h^L_t}
] + c )$$

### 双向 RNN 的缺点

双向 RNN 虽然在一些任务上表现优于单向 RNN，但是它也有个限制，就是 **它需要知道完整的序列数据，才能对任意位置进行预测**
。例如一个语音识别系统，需要知道整个语音表达，就意味着需要等这个人全部说完，才能开始处理这段语音，所以实际的语音识别系统会有更复杂的结构；同样的在实时翻译中也不能直接用双向的
RNN。不过对于一些可以即时获得整个序列的 NLP 任务，标准的双向 RNN 还是很有效的。

### 应用：手写识别

MNIST 的例子，相信大家已经很熟悉了，相当于图像领域的 Hello World，常用 CNN
等网络对其进行训练学习和预测，其实序列模型也可以用来识别图像，今天我们用 **双向 RNN** 来处理一下，看看其效果。

我们所用的 MNIST 是一个手写数字的数据集，共有三部分：训练集（mnist.train）55000
个样本，测试集（mnist.test）10000，验证集（mnist.validation）5000 个。

每个数字的图片已经标准化为 28*28 像素，并被展开为含有 784（28*28）个特征的一维数组，值在 0~1 之间。

每个图片还有对应的真实数字标签（mnist.train.labels），标签向量长度为 10，以 one-hot 方式表示相应图片代表的真实数字。
我们的任务就是要识别出图片上面的数字。

**整个过程分为下面几步：**

  1. 加载数据
  2. 设置参数
  3. 创建输入 x 和学习目标 y 的 placeholder
  4. 随机初始化权重和偏置
  5. 定义 Bidirectional LSTM 网络
  6. 定义损失，优化算法，准确率
  7. 加载测试集用于测试
  8. 定义可视化结果的辅助函数
  9. 训练模型并对结果可视化

#### **1\. 加载数据**

    
    
    import tensorflow as tf
    import numpy as np 
    from tensorflow.examples.tutorials.mnist import input_data
    
    mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)
    

#### **2\. 设置参数**

我们要建立的模型结构如下图所示：

![](https://images.gitbook.cn/42a2b450-6f1f-11ea-832c-2703165cf4af)

  * MNIST 的每个图片是 28*28 像素，我们将它看成一个长度为 28 的序列，即 `n_steps = 28`，如图所示，每行数据作为 xt 输入到双向 RNN 中；
  * 这个序列在每个时间点上的输入是长度为 28 的向量，所以 `n_inputs = 28`；
  * 隐藏层单元的维度为 128；
  * 因为这是个分类问题，预测的目标是 0~9 这10个数字，所以有 10 个类别，则输出层维度是 10。

    
    
    n_inputs = 28            # 输入层维度
    n_hidden = 128        # 隐含层维度
    n_outputs = 10        # 输出层长度
    n_steps = 28            # RNN 步数
    
    learning_rate = 0.001
    batch_size = 128
    n_epochs = 10
    

#### **3\. 创建输入 x 和学习目标 y 的 placeholder**

每个图片被看作为一个时间序列，第一个维度是时间步 `n_step`，第二个维度是每个时间点的数据 `n_inpts`。

    
    
    x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
    y = tf.placeholder(tf.float32, [None, n_outputs])
    

#### **4\. 随机初始化权重和偏置**

因为是有两个方向，所以权重维度需要是 2 倍。

    
    
    weights = tf.Variable(tf.random_normal([2 * n_hidden, n_outputs]))
    biases = tf.Variable(tf.random_normal([n_outputs]))
    

#### **5\. 下面定义 Bidirectional LSTM 网络**

    
    
    def BiRNN(x, weights, biases):
    
        # 将维度 [batch_size, timesteps, n_input] 变成长为 time steps 个 [batch_size, num_input]，即（28，batch_size，28）
        x = tf.unstack(x, n_steps, 1)
    
        lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)
        lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)
    
        # [28，batch_size, n_hidden*2] 即 （28，128，256）
        outputs, _, _ = tf.nn.static_bidirectional_rnn(lstm_fw_cell,
                                                       lstm_bw_cell, 
                                                       x,
                                                       dtype = tf.float32)
    
        return tf.matmul(outputs[-1], weights) + biases
    

**首先，将 x 调整为 RNN 要求的形状：**

当前的维度是 `[batch_size, timesteps, n_input]`，通过 unstack 变成一个 list，长度为 time
steps，每个时间点上的形状为 `[batch_size, num_input]`。

![](https://images.gitbook.cn/bbd6ddd0-6f27-11ea-ab1a-832c54b4f266)

**`static_bidirectional_rnn` 的用法：**

用 `tf.nn.static_bidirectional_rnn` 建立一个双向 RNN，它的输入参数为：

    
    
    tf.nn.static_bidirectional_rnn(
        cell_fw,                        # 前向 rnn 的 cell
        cell_bw,                         # 反向 rnn 的 cell
        inputs,                         # 输入序列
        initial_state_fw=None,            # 前向rnn_cell的初始状态
        initial_state_bw=None,            # 反向rnn_cell的初始状态
        dtype=None,                        # 初始化和输出的数据类型
        sequence_length=None,            # 输入序列的实际长度（默认为输入序列的最大长度）
        scope=None
    )
    

在使用时，首先需要定义前向和反向的 RNN 单元 `cell_fw`、`cell_bw`，正向的就是基本单向 RNN 的实现；反向部分相对复杂一点，它是双向
RNN 的核心所在，在函数内部，会通过两次逆序来达到反向 RNN 的效果：

  * 第一次是将输入序列进行逆序, 输入给单向 RNN，即输入为 $x_t, x_{t-1}, ..., x_2, x_1$，这样得到的输出序列相当于是 $y_t, y_{t-1}, ..., y_2, y_1$，以 $y_2$ 为例，它在反向网络这里就是利用了 $x_3$ 及其后的信息，而在前向网络中 $y_2$ 是利用了 $x_1$ 即其前的信息；
  * 第二次是将单向 RNN 返回的 outputs 再做一次逆序, 使正向和反向的位置是对应的，即 $y_t, y_{t-1}, ..., y_2, y_1$ 变成了 $y_1, y_2, ..., y_{t-1}, y_t$，将相同时刻的来自两个方向的 y 串联起来，例如 $y_2$ 此时就既包括了 $x_1$ 的信息，也包括了 $x_3$ 的信息了。

函数的返回值是一个 `[outputs, output_state_fw, output_state_bw]` 元组：

  * 其中 outputs 是一个长度为 timesteps 的 list，每个时间点对应当前的 output。这里每个 output 都是由前向和反向 RNN 的输出叠加串联而成，即 outputs 的形状为 `[time][batch][cell_fw.output_size + cell_bw.output_size]`。
  * 因为是两个方向的结果的叠加，所以维度变为 `n_hidden * 2`， 即 `outputs[:][:][0:n_hidden, :]` 对应的是前向 fw， `outputs[:][:][n_hidden:n_hidden*2, :]` 对应的是反向 bw。

![](https://images.gitbook.cn/98b2deb0-6f1f-11ea-9d98-f7fceb2428d3)

  * 返回值中后面两个 `output_state_fw, output_state_bw` 分别为前向网络和反向网络的最终状态。

#### **6\. 定义损失，优化算法，准确率**

我们用 `tf.nn.softmax_cross_entropy_with_logits_v2` 进行 Softmax 处理，再计算交叉熵损失，优化方法用
Adam。

再用 `tf.argmax` 取出 pred 向量中值最大的那一个标签作为预测值输出。

    
    
    pred = BiRNN(x, weights, biases)
    
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))
    
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
    training_op = optimizer.minimize(cost)
    
    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    
    init = tf.global_variables_initializer()
    

#### **7\. 加载测试集用于测试**

    
    
    x_test = mnist.test.images.reshape((-1, n_steps, n_inputs))
    y_test = mnist.test.labels
    

#### **8\. 可视化结果的辅助函数**

    
    
    import matplotlib.pyplot as plt
    %matplotlib inline
    

**`plot_images` 用来建立一个 3x3 的图，来显示预测正确的图片：**

images 是要显示的图片，`cls_true` 是图片对应的真实数字，`cls_pred` 是预测的数字。

    
    
    def plot_images(images, cls_true, cls_pred=None, title=None):
    
        fig, axes = plt.subplots(3, 3, figsize=(9, 9))
        fig.subplots_adjust(hspace=0.3, wspace=0.3)
    
        for i, ax in enumerate(axes.flat):
            # 画图
            ax.imshow(np.squeeze(images[i]).reshape(28, 28), cmap='binary')
    
            # 显示出实际和预测的数字标签
            if cls_pred is None:
                ax_title = "True: {0}".format(cls_true[i])
            else:
                ax_title = "True: {0}, Pred: {1}".format(cls_true[i], cls_pred[i])
    
            ax.set_title(ax_title)
    
            ax.set_xticks([])
            ax.set_yticks([])
    
        if title:
            plt.suptitle(title, size=20)
    
        plt.show(block=False)
    

**`plot_example_errors` 用来显示预测错误的图片，输入参数的意义同上：**

    
    
    def plot_example_errors(images, cls_true, cls_pred, title=None):
    
        # 锁定预测错误的那些图片位置
        incorrect = np.logical_not(np.equal(cls_pred, cls_true))
    
        # 获得预测错误的图片
        incorrect_images = images[incorrect]
    
        # 得出这些图片的真实标签和预测标签
        cls_pred = cls_pred[incorrect]
        cls_true = cls_true[incorrect]
    
        # 画出前 9 个图
        plot_images(images=incorrect_images[0:9],
                    cls_true=cls_true[0:9],
                    cls_pred=cls_pred[0:9],
                    title=title)
    

#### **9\. 训练模型并对结果可视化**

    
    
    with tf.Session() as sess:
        init.run()
    
        for epoch in range(n_epochs): 
    
            for iteration in range(mnist.train.num_examples // batch_size):
    
                # 随机抽出这一次迭代训练时用的数据，(batch_size, 784)
                x_batch, y_batch = mnist.train.next_batch(batch_size)
    
                # 对数据进行处理，使得其符合输入要求，(batch_size, 28, 28)
                x_batch = x_batch.reshape((-1, n_steps, n_inputs))
    
                sess.run(training_op, feed_dict={x: x_batch, y: y_batch})
    
            acc_train = accuracy.eval(feed_dict={x: x_batch, y: y_batch})
            acc_test = accuracy.eval(feed_dict={x: x_test, y: y_test})
    
            print(epoch, "Train accuracy:", acc_train, "Test accuracy:", acc_test)
    
        # 可视化结果，分别展示预测正确的数字，和预测错误的数字
        cls_prediction = tf.argmax(pred, 1)
        feed_dict_test = {x: x_test[:1000].reshape((-1, n_steps, n_inputs)), y: y_test[:1000]}
    
        cls_pred = sess.run(cls_prediction, feed_dict = feed_dict_test)
        cls_true = np.argmax(y_test, axis = 1)
    
        plot_images(x_test, cls_true, cls_pred, title='Correct Examples')
        plot_example_errors(x_test[:1000], cls_true[:1000], cls_pred, title='Misclassified Examples')
        plt.show()
    

![](https://images.gitbook.cn/cbd56290-6f1f-11ea-832c-2703165cf4af)

![](https://images.gitbook.cn/de493370-6f1f-11ea-8377-13f07d2f46fb)

经过 10 轮的学习，BRNN 可以在一些简单的数字上表现良好，如 1 和 2，在复杂的数字上如 5、6、8 就会有较多判断错误。

### 用 Keras 建立双向 RNN 模型

上面是用 TF1 实现的双向 RNN 模型，同样的模型我们再用 TF2 中的 Keras
来搭建一下，基本步骤和参数的设置都是一样的，所以就不赘述了，大家有兴趣可以进行调参或者更换模型等看看会有什么样的效果。

    
    
    from __future__ import absolute_import, division, print_function, unicode_literals
    
    import collections
    import matplotlib.pyplot as plt
    import numpy as np
    
    try:
      # %tensorflow_version only exists in Colab.
      %tensorflow_version 2.x
    except Exception:
      pass
    import tensorflow as tf
    
    from tensorflow.keras import layers
    
    import matplotlib.pyplot as plt
    %matplotlib inline
    

#### **加载数据**

训练集 `x_train.shape` 是 (60000, 28, 28)，测试集 `x_test.shape` 是 (10000, 28, 28)。

    
    
    mnist = tf.keras.datasets.mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0
    

#### **设置超参数**

    
    
    batch_size = 128
    input_dim = 28
    units = 128
    output_size = 10  
    

#### **建立模型**

    
    
    model = tf.keras.Sequential()
    model.add(layers.Bidirectional(layers.LSTM(units, input_shape=(None, input_dim))))
    model.add(layers.Dense(output_size))
    
    
    
    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), 
                  optimizer='adam',
                  metrics=['accuracy'])
    

#### **训练模型**

    
    
    history = model.fit(x_train, y_train,
              validation_data=(x_test, y_test),
              batch_size=batch_size,
              epochs=10)
    

#### **画出模型的损失和准确率**

    
    
    print(history.history.keys())
    
    
    
    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    

![](https://images.gitbook.cn/10c51710-6f20-11ea-8377-13f07d2f46fb)

    
    
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    

![](https://images.gitbook.cn/21dcb350-6f20-11ea-a6e5-c1244b77f602)

从这两个图中我们可以看出在训练 6 轮左右时，模型就可以达到不错的效果了。

为了更好地对比效果，此外还训练了一个单向的 LSTM 网络，下面是它在同样超参数设置下的 10 轮训练损失和准确率，可见双向的表现要比单向的更好更稳定：

![](https://images.gitbook.cn/3377d770-6f20-11ea-9d98-f7fceb2428d3)

![](https://images.gitbook.cn/42ce89d0-6f20-11ea-8807-c9303eb74ab1)

#### **识别结果可视化**

    
    
    y_test_predict = model.predict(x_test)
    
    cls_predict = np.argmax(y_test_predict, axis = 1)
    

**预测正确的结果示例：**

    
    
    def plot_images(images, cls_true, cls_pred=None, title=None):
    
        fig, axes = plt.subplots(3, 3, figsize=(9, 9))
        fig.subplots_adjust(hspace=0.3, wspace=0.3)
    
        for i, ax in enumerate(axes.flat):
            # 画图
            ax.imshow(np.squeeze(images[i]).reshape(28, 28), cmap='binary')
    
            # 显示出实际和预测的数字标签
            if cls_pred is None:
                ax_title = "True: {0}".format(cls_true[i])
            else:
                ax_title = "True: {0}, Pred: {1}".format(cls_true[i], cls_pred[i])
    
            ax.set_title(ax_title)
    
            ax.set_xticks([])
            ax.set_yticks([])
    
        if title:
            plt.suptitle(title, size=20)
    
        plt.show(block=False)
    
    
    
    plot_images(x_test, y_test, cls_predict, title='Correct Examples')
    plt.show()
    

![](https://images.gitbook.cn/56a37150-6f20-11ea-9d5e-29b50a74a9eb)

**预测错误的结果示例：**

    
    
    def plot_example_errors(images, cls_true, cls_pred, title=None):
    
        # 锁定预测错误的那些图片位置
        incorrect = np.logical_not(np.equal(cls_pred, cls_true))
    
        # 获得预测错误的图片
        incorrect_images = images[incorrect]
    
        # 得出这些图片的真实标签和预测标签
        cls_pred = cls_pred[incorrect]
        cls_true = cls_true[incorrect]
    
        # 画出前 9 个图
        plot_images(images=incorrect_images[0:9],
                    cls_true=cls_true[0:9],
                    cls_pred=cls_pred[0:9],
                    title=title)
    
    
    
    plot_example_errors(x_test, y_test, cls_predict, title='Misclassified Examples')
    plt.show()
    

![](https://images.gitbook.cn/674f5370-6f20-11ea-9d5e-29b50a74a9eb)

参考文献：

  * [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn)
  * aymericdamien，[Bidirectional_Rnn](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/bidirectional_rnn.py)

