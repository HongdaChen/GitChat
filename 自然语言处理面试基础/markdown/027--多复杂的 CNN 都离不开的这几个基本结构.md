今天我们来学习 CNN，大家可能都知道 CNN 主要应用于图像领域，但其实近几年在自然语言处理领域也经常使用 CNN 来做一些任务，这篇文章我们先介绍一下
CNN 的基础，下一篇将介绍一个很擅长处理图像任务的模型要如何用于文本序列任务。

### 什么是 CNN

**CNN：Convolutional Neural Network，卷积神经网络**
，主要用于图像领域，可以用来做图像分类任务，比如大家熟知的手写识别、聚类任务、如图片搜索，此外还有物体识别、人脸识别、自动驾驶、无人机、机器人学，医学诊断等领域中也表现出色。在
2016 年的 ImageNet Large Scale Visual Recognition Challenge（ILSVRC）的图像分类任务中，CNN
在 1000 个不同类别中就已经可以达到 98% 的准确率了。

### 都有哪些著名的卷积神经网络

在进入详细的理论部分，我们先看一下几大著名的卷积神经网络，这对我们后面了解基础结构也有一定的帮助。

我们将按照时间顺序简单介绍下面八种结构：

  * LeNet-5
  * AlexNet
  * VGG-16
  * Inception-v1
  * Inception-v3
  * ResNet-50
  * Xception
  * ResNeXt-50

Alfredo Canziani 等人曾经发过一篇论文 [_AN ANALYSIS OF DEEP NEURAL NETWORK MODELS FOR
PRACTICAL
APPLICATIONS_](https://arxiv.org/pdf/1605.07678.pdf)，里面比较了这几种神经网络的运算量和准确率，下图便是他们的实验结果：

![](https://images.gitbook.cn/e5d1c440-7f37-11ea-a205-47a8f48db192)

接下来主要介绍这几个网络的结构，在论文原图的后面会有一个简图，方便大家观察它们的组成部分和连接方式，里面涉及到的基础概念我们会在后面内容中详细介绍。

**1998，Yann LeCun 的 LeNet5**

LeNet5 包括 2 个卷积层和 3 个全连接层，也正是名字中 5 的由来，在每个卷积层后面会跟着一个 average pooling
均值池化层。LeNet5 这个结构现在成为了卷积神经网络的标准模版，就是将卷积层、池化层、全连接层这三个层结构堆叠起来：

![](https://images.gitbook.cn/34f0bdb0-7f38-11ea-b7e8-9964a7b45d0e)

![](https://images.gitbook.cn/41a32b10-7f38-11ea-8ec2-752fc54f41de)

**2012，Alex Krizhevsky 的 AlexNet**

AlexNet 包括 8 层，其中 5 个卷积层和 3 个全连接层，在卷积层后面接着 max pooling 最大池化层，这个结构是率先使用
Rectified Linear Units 作为激活函数的：

![](https://images.gitbook.cn/51be8d00-7f38-11ea-8ec2-752fc54f41de)

![](https://images.gitbook.cn/5dae94c0-7f38-11ea-aef6-539c3826c714)

**2015，牛津大学的 VGG-16**

这个结构和前面相比，就是更深了，差不多是 AlexNet 的二倍，在每个卷积层中使用更小的 3×3 滤波器，并将它们组合成卷积序列，虽然小，但是多个 3×3
卷积序列可以模拟更大的接收场的效果：

![](https://images.gitbook.cn/74bfbb80-7f38-11ea-b7e8-9964a7b45d0e)

![](https://images.gitbook.cn/8196eef0-7f38-11ea-b7e8-9964a7b45d0e)

**2014，Google Christian Szegedy 的 Inception**

这个结构就更深了，有 22 层，并且它不是直接堆叠卷积层，而是堆叠模块，在每个模块中再由多个卷积层组成：

![](https://images.gitbook.cn/c2c4e080-7f38-11ea-b7b0-e1d3106a8702)

![](https://images.gitbook.cn/cf6832b0-7f38-11ea-b497-6b28b57af19c)

**2015年12月，Christian 团队的 Inception V3**

这个网络具有 42 层，参数多达 24M，在这个结构中率先使用了 batch normalisation
批正则化，而且构建网络时仔细平衡深度和宽度，使流入网络的信息最大化，尽量只使用 3x3 的卷积：

![](https://images.gitbook.cn/df391e20-7f38-11ea-bee5-61432feb39ea)

[图片来源](https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-
classification-in-ilsvrc-2015-17915421f77c)

![](https://images.gitbook.cn/ec9ab740-7f38-11ea-9bbe-b79e71d58acf)

**2015，Kaiming He、Xiangyu Zhang、Shaoqing Ren、Jian Sun 的 ResNet**

在前面可以看出这些网络的层数越来越多，准确率也的确越来越好，不过随着网络深度的增加，准确率会达到一个瓶颈甚至下降，于是微软团队通过使用 skip
connections 来改善这个问题，可以建立深度为 152 的网络，是第一次训练了大于 100 层的网络：

![](https://images.gitbook.cn/0779d5f0-7f39-11ea-9e50-d754b71d2fe2)

![](https://images.gitbook.cn/abda1100-7f39-11ea-b7b0-e1d3106a8702)

**2016，François Chollet 的 Xception**

这个网络和 ResNet 一样有效，而且用了更简单优雅的结构，它有 36 个卷积层，和 ResNet-34 相似，不过模型和代码和 ResNet
一样简单，还容易理解：

![](https://images.gitbook.cn/be9b8cb0-7f39-11ea-9e50-d754b71d2fe2)

![](https://images.gitbook.cn/cbe976c0-7f39-11ea-a918-478f642cdd64)

**2017，ResNeXt-50**

ResNeXt-50 和 ResNets 的区别是，在每个模块内都添加了并行的塔楼/分支/路径，如下图所示在卷积块和 Identity 块中都有 32
个塔楼：

![](https://images.gitbook.cn/ddaa9970-7f39-11ea-9bbe-b79e71d58acf)

![](https://images.gitbook.cn/ea8464f0-7f39-11ea-a205-47a8f48db192)

前面介绍了这么多流行的卷积神经网络，大家可以观察一下，无论结构多么复杂，基本层只有三种：卷积层、池化层和全连接层，不同的是数量和连接方式。下面我们就详细介绍这三种基本层结构。

### 卷积神经网络的基础结构

#### **卷积层**

**1\. 首先，什么是卷积？**

我们可以先看卷积做了一件什么事情：

![](https://images.gitbook.cn/0b841e20-7f3a-11ea-91b5-2b28d93e0243)

例如，最下面的矩阵代表一张图片，中间蓝色矩阵是卷积核（kernel），也叫滤波器（filter），或者特征探测器（feature
detector），红色部分是卷积核所覆盖的原图中区域，最上面的小矩阵是卷积结果，也叫 Convolved Feature、Activation
Map，或者 Feature Map。

对图片做卷积，就是用一个滑动窗口即卷积核，从图片的左上角开始向右平移，在每一步上，卷积核与它所覆盖的矩阵区域做元素相乘再求和，得到的这个值作为结果矩阵上相应位置的数值，一行移动完再移动到下一行，一直移动到图片的右下角。

在上述卷积操作中，会涉及到下面几个变量。

  * **步长 Stride** ，在卷积核移动时，可以设置步长，就是无论在水平方向和竖直方向上，两次移动之间间隔的长度，下图是步长为 2 的，在这个图中可以看到扩大了步长后，各个局部区域之间重复的面积也减小了，得到的结果长度就越小，计算量也越少。

![](https://images.gitbook.cn/5d500f20-7f3a-11ea-8ec2-752fc54f41de)

  * **填充 Zero-padding** ，指的是在原图的四周补充一圈 0，补充多宽也是可以设定的，这样原图的边缘信息也可以被更有效地捕捉到卷积结果中。没有用 zero-padding 的叫做窄卷积，用 zero-padding 的叫做宽卷积。

![](https://images.gitbook.cn/77d993c0-7f3a-11ea-8ec2-752fc54f41de)

  * **深度 Depth** ：如果对一张图片使用 N 种不同的卷积核，就会得到 N 种不同的 feature map。

此外在实际操作时我们还需要定义卷积核的数量和大小等超参数，而卷积核矩阵的具体值是自动学习出来的。

**2\. 那么，卷积操作起了什么作用？**

卷积核的作用其实就是提取图片的特征，同一个图片上使用不同的卷积核可以得到不同的 Feature Map，也就会有不同的效果，如下图所示：

![](https://images.gitbook.cn/887485f0-7f3a-11ea-bee5-61432feb39ea)

如果将每个像素与其周围的像素做平均值，那么可以达到“图像模糊”的效果。

如果用每个像素与其周围的像素做差，那么相同颜色的地方会变成 0，而有明显轮廓的地方因为颜色相差比较大就会凸显出来，这样就可以达到“识别图像轮廓”的效果。

而且在卷积神经网络中，越靠后面的卷积层可以学习到越复杂的特征，例如下图，第一层卷积可以学到一些边边框框，第二个卷积层可以学习到眼睛，鼻子，嘴巴等部位，第三个卷积层可以学习出人脸的基本样貌：

![](https://images.gitbook.cn/a134bc40-7f3a-11ea-aef6-539c3826c714)

**3\. 卷积操作有什么特点？**

卷积操作更多地是关注图片里是否有某个特征，而不会过多关注这个特征的具体位置。

例如一个卷积核代表了小狗的耳朵，那么在窗口移动的过程中，如果遇到了像耳朵的区域，就会被识别出来，但它不会记录这个特征到底在什么位置，这个特点也叫位置不变性（location
invariance）。

#### **池化层**

**1\. 什么是池化？**

池化 Pooling 也叫下采样
downsampling，就是将一个矩阵分成若干个指定大小的小池子，在每个小池子内进行相应的运算，然后得到一个标量作为结果矩阵中相应位置的值。

常用的池化操作有 max-pooling 和 average-pooling：

  * max-pooling 就是在每个小池子中取其中最大的那个值作为结果，
  * average-pooling 就是在每个小池子中取平均值作为结果：

![](https://images.gitbook.cn/cab19d90-7f3a-11ea-9456-634f43a6106e)

**2\. 池化操作有什么作用呢？**

首先，它可以降低中间结果的维度，如上图所示，一个 4x4 的矩阵可以变成 2x2
的矩阵。而且池化在减少维度的同时仍能够保持最关键的信息，如最大值和平均值都可以代表主要信息。降维也减少了参数的个数，进而控制过拟合。

其次，可以保证输出的维度是固定的，例如有 100 个池化单元，那么不管滤波器的维度是什么，不管输入数据的维度是什么，经过池化后结果的维度就是 100。

此外，池化可以降低图片发生平移或变形后造成的影响，也叫保持平移，旋转和缩放的不变性。假设一个图片发生了平移，那么对两种状态的图片做同样的池化操作，如取最大值，得到的池化结果其实是一样的，不会受到偏移的影响。如下图所示，左边的原图在
y 轴上平移一块，卷积后的矩阵虽然会有不同，但是经过最大池化后的结果是一样的：

![](https://images.gitbook.cn/e6fbe500-7f3a-11ea-a918-478f642cdd64)

我们还可以看一下实际效果，下图是在卷积+ReLu之后使用 Max 和 Sum 两种池化后的效果图，可以观察到经过 sum
池化后的图中还隐约可以看到物体的轮廓：

![](https://images.gitbook.cn/f2f7d3a0-7f3a-11ea-bee5-61432feb39ea)

#### **全连接层**

全连接层就是每个输入与每个输出都会相连，也因此它可以学习全局的信息。

在卷积神经网络中，前面的卷积操作可以学习到很多局部的信息，但是缺少一个全局观，而全连接层可以将这些局部特征从全局的角度连接起来，
**将这些特征做一个非线性的组合来组成更有意义的结果。**

最后一个全连接层也叫做输出层，它的激活函数是 softmax， **用来得到各个类别的概率** ，在这里全连接层将前面学到的高级特征整合到最终的分类结果。

![](https://images.gitbook.cn/06a90680-7f3b-11ea-b497-6b28b57af19c)

#### **ReLU 层**

除了前面三个主要的层结构，其实在每个卷积层之后都会有一个 ReLU 层，在第二部分介绍主要卷积神经网络结构时，就是在简图中每个位于卷积层右上角的 R 标志。

它的公式和图像如下图所示：

![](https://images.gitbook.cn/198b50a0-7f3b-11ea-9e50-d754b71d2fe2)

我们知道它在深度学习中是被广泛使用的激活函数， **这里的 ReLU 操作是像素级的，它将卷积结果的所有负值像素替换为 0。**

**ReLU 的作用是引入非线性** ，卷积操作本身是线性的，因为它就是矩阵元素乘积再求和，这些都是线性的操作，而 CNN
需要处理的任务大多是非线性的，所以需要引入非线性的操作。

下图是使用 ReLU 的前后效果图，当它将负值替换为 0 后，一些不重要的干扰线条消失，重要的特征才更容易体现出来：

![](https://images.gitbook.cn/2cc27180-7f3b-11ea-b497-6b28b57af19c)

### 再看卷积神经网络

将卷积神经网络的几个主要组件介绍完后，我们再将其组装起来整体看一下 CNN 在做一件什么事情。

![](https://images.gitbook.cn/3d2feb10-7f3b-11ea-a205-47a8f48db192)

例如上面这个图是一个基本的用于图像分类任务的 CNN 结构：

  * CNN 的输入数据是一张彩色图片，一般用 RGB 三个通道表示，每个通道都可以看成一个二维矩阵，矩阵的每个元素代表像素，数值从 0 到 255 来表示颜色的深浅。建立模型时可以对不同的通道采取不同的权重参数。
  * 输入图像后，先经过一个卷积层，前面我们提到过卷积层是用来提取特征的，最初的卷积层可以学习出比较基础的特征，比如图像的边界。

以图像分类为例：

![](https://images.gitbook.cn/4fa7b390-7f3b-11ea-8ec2-752fc54f41de)

左边这只小狗是输入图片，被分割成一个一个小区域，每个区域包含着各自的图像特征信息，我们用一个卷积核矩阵，它可能代表着一个小狗的脖子那条弧线，当它与各个区域做卷积操作后，可以看到原图空白区域得到的卷积结果是
0，耳朵区域得到的卷积结果会是一个比较小的值，而当遇到脖子区域后得到的结果数值就很大。也就是说卷积核所代表的模式，如果在哪个小区域可以找到，那么这个区域得到的卷积值就很大，否则就很小，
**经过卷积操作最后得到的矩阵就是来显示图片的各个区域是否具有相应的模式。**

  * 然后卷积结果经过一个池化层，进行降维并保留主要信息。
  * 之后再经过一个卷积层，这时它可以学习出比较高级的特征，如基本形状，物体的部位等等。
  * 接着又是一个池化层，这些池化层除了降维还可以保持图像位置的不变性，减小偏移造成的影响。
  * 最后经过全连接层，再得到最后的分类结果。

为了更形象的展示 CNN
每一层到底发生了什么，我们可以看一下[这个可视化交互界面](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)，可以直接在页面上手写一个数字，就可以给出
CNN 每一层学到的结果：

![](https://images.gitbook.cn/6a553af0-7f3b-11ea-91b5-2b28d93e0243)

在这个数字识别任务中，例如我们在页面写个 8，输入图片有 32 x 32 = 1024 像素：

  * 第一个卷积层有 6 个不同的卷积核，每个大小都是 5 × 5，stride 为 1，可以看到这几个卷积核 **学到了数字的不同部分的特征** ；
  * 第一个池化层对前面 6 个卷积核执行 2 × 2 的 max pooling，stride 为 2，和第一个卷积层相比，的确 **保留了最关键的信息** ；
  * 第二个卷积层有 16 个不同的卷积核，每个大小都是 5 × 5，stride 为 1；
  * 第二个池化层也是 2 × 2 的 max pooling，stride 为 2；
  * 第一个全连接层有 120 个神经元；
  * 第二个全连接层有 100 个神经元；
  * 第三个全连接层也叫输出层，有 10 个神经元代表 10 个不同的类别，可以看到 **它在 8 所对应的位置得到的概率最大，因此识别为 8** 。

### CNN 模型的训练

知道了模型每一层的作用，我们再来看看模型是如何训练的。

同样还是图像分类任务，左边是输入的图片，假设我们想要识别图像中是否包含某一类事物，一共有四类：狗，猫，船，鸟。

我们希望模型可以识别出这个图片里的主体是船，即它的分类结果应该是 [0, 0, 1, 0]，这也就是我们训练模型的预测目标值。

![](https://images.gitbook.cn/f68dfd40-7f3b-11ea-b7e8-9964a7b45d0e)

**训练步骤：**

  1. 随机初始化所有的卷积核，权重等参数。
  2. 输入图片数据进入网络，通过前向传播执行卷积操作，ReLU，池化，进入全连接层，最后输出它在每个类别的概率，假设为 [0.2, 0.4, 0.1, 0.3]。
  3. 计算输出层的整体误差：$Total Error = \frac{1}{2} \sum (probability_{target} – probability_{output})^2$。
  4. 使用反向传播计算误差对所有权重的梯度，并用梯度下降法更新权重，使误差最小化。这样当同样的图片再经过网络的前向传播后得到的结果可能就是 [0.1, 0.1, 0.7, 0.1]，在船这个类别上的概率更大了，说明网络可以更好地学习出类别了。
  5. 对训练集的所有图片重复 2~4 步。

卷积核的个数、大小、神经网络的结构都是固定的，卷积核的具体数值和权重参数会随着训练不断地更新。

模型训练好后，将新的图片输入网络后，就可以得到一个概率向量，预测它所在的类别。

### CNN 中各层的维度和参数个数计算

在这里我要介绍一个之前没有提到过的问题，就是计算网络的Tensor维度和参数个数。其实这些数字我们是可以通过 TensorFlow，Keras
等框架自动得到的，但是如果我们能够知道它们是怎么得来的，可以帮助优化模型的结构，进而提升模型的效率。而且还有助于更深刻地理解模型的本质原理，包括数据在模型中是如何变化的，要求的参数是什么样的。

下面我们就来手动计算一下 CNN 的参数个数。

我们 **以 AlexNet 为例** ，它比 LeNet5 大一些，但还不至于特别深，很适合作为一个手动计算的例子：

![](https://images.gitbook.cn/284afdb0-7f3c-11ea-aef6-539c3826c714)

首先看模型的结构：

  * Input：维度为 227x227x3。
  * Conv-1：有 96 个卷积核，大小为 11×11，步长为 4，padding 为 0。
  * MaxPool-1：池化矩阵大小为 3×3，步长为 2。
  * Conv-2：有 256 个卷积核，大小为 5×5，步长为 1，padding 为 2。 
  * MaxPool-2：池化矩阵大小为 3×3，步长为 2。
  * Conv-3：有 384 个卷积核，大小为 3×3，步长为 1，padding 为 1。 
  * Conv-4：和 Conv-3 一样，有 384 个卷积核，大小为 3×3，步长为 1，padding 为 1。 
  * Conv-5：有 256 个卷积核，大小为 3×3，步长为 1，padding 为 1。 
  * MaxPool-3：池化矩阵大小为 3×3，步长为 2。
  * FC-1：有 4096 神经元。
  * FC-2：同样有 4096 神经元。
  * FC-3：有 1000 神经元。

首先看各层输出结果的维度。

**1\. 卷积层的输出结果大小计算公式为：**

$$output = \frac{I-K+2P}{S} + 1$$

令：

  * I = 输入图片的宽度
  * K = 卷积核的宽度
  * S = 步长
  * P = Padding 的长度

例如，第一个卷积层，I = 227，K = 11，S = 4，padding = 0，所以卷积矩阵的宽度为

$$output = \frac{227-11+2*0}{4} + 1 = 55$$

因为有 96 个不同的卷积核，所以最后维度为 55x55x96。

**2\. 最大池化层的输出结果大小计算公式为：**

$$output = \frac{I-P_S}{S} + 1$$

令：

  * I = 输入图片的宽度
  * S = 步长
  * P_s = 池化矩阵的宽度

AlexNet 中每个最大池化层的维度是一样的 3×3，步长为 2，即 P_s = 3，S = 2，以第一个最大池化层为例，I =
55，所以池化结果的宽度为：

$$output = \frac{55-3}{2} + 1 = 27$$

最后维度是 27x27x96。

**3\. 关于全连接层，它有多少神经元，输出就是多大。**

再看各层的参数个数。

**卷积层的参数个数：**

  * $W_c$ = 卷积层的权重个数
  * $B_c$ = 卷积层的偏置个数
  * $K$ = 卷积核的宽度
  * $N$ = 卷积核的个数
  * $C$ = 输入图片的轨道数

卷积层的参数个数计算公式为：

$$W_c = k^2 * C * N$$ $$B_c = N$$ $$P_c = W_c + B_c$$

以第一个卷积层为例，C = 3，K = 11，N = 96所以计算结果为：

$$W_c = 11^2 * 3 * 96 = 34848$$ $$B_c = 96$$ $$P_c = 34848 + 96 = 34944$$

**2\. 池化层没有需要求的参数。**

**3\. 第一个全连接层，前面连接着池化层：**

  * $W_{cf}$ = 这个全连接层的权重参数个数
  * $B_{cf}$ = 这个全连接层的偏置参数个数
  * $O$ = 前面卷积层输出结果的宽度
  * $N$ = 前一层卷积核的个数
  * $F$ = 全连接层的神经元个数

连接卷积结果的全连接层，具有的参数个数计算公式为：

$$W_{cf} = O^2 * N * F$$ $$B_{cf} = F$$ $$P_{cf} = W_{cf} + B_{cf}$$

以第一个全连接层为例，O = 6，N = 256，F = 4096。所以计算结果为：

$$W_{cf} = 6^2 * 256 * 4096 = 37748736$$ $$B_{cf} = 4096$$ $$P_{cf} = W_{cf} +
B_{cf} = 37752832$$

**4\. 第二个全连接层，前面连接着全连接层：**

  * $W_{ff}$ = 此全连接层的权重参数个数
  * $B_{ff}$ = 此全连接层的偏置参数个数
  * $F$ = 此全连接层的神经元个数
  * $F_{-1}$ = 前一个全连接层的神经元个数

连接全连接层的全连接层，具有的参数个数计算公式为：

$$W_{ff} = F_{-1} * F$$ $$B_{ff} = F$$ $$P_{ff} = W_{ff} + B_{ff}$$

以第二个全连接层为例，F_{-1} = 4096，F = 1000，所以计算结果为：

$$W_{ff} = 4096 * 1000 = 4096000$$ $$B_{ff} = F = 1000$$ $$P_{ff} = W_{ff} +
B_{ff} = 4097000$$

下图是 AlexNet 各层的数值，大家感兴趣可以手动计算并验证一下其他层：

![](https://images.gitbook.cn/eef52530-7f3c-11ea-a918-478f642cdd64)

在图像领域，CNN 与全连接神经网络相比，它的优势是网络的参数会少很多，例如一个图片的维度是宽 227 x 高 227 x 颜色通道
3，那么全连接网络的第一个隐藏层的参数会有 227x227x3 = 154584 个，经过上面的计算我们可以看到第一层卷积层后的参数个数是
34944，在第一层参数个数明显少了很多。

通过前面对卷积层的详细介绍，可以看出 CNN
能够由像素学习出边，由边学习出形状，再由形状学习出更复杂的物体，也就是具有组合性（compositionality）的特点，这也是为什么 CNN
可以在计算机视觉任务上表现得很不错。

今天这篇文章中讲了 CNN 的原理，主要侧重在图像方面的运用，其实它也可以用于自然语言处理领域，并且也有重要的作用，下一篇我们将介绍 CNN 是如何应用于
NLP 任务的。

* * *

参考文献：

  * Raimi Karim，[ _Illustrated: 10 CNN Architectures_](https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d#676b)
  * ujjwalkarn，[ _An Intuitive Explanation of Convolutional Neural Networks_](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)

