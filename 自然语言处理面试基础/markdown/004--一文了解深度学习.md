其实一篇几千字的文章很难将深度学习都讲清楚，不过标题是“了解”，这篇文章的目的就是希望可以给大家带来一个深度学习的整体印象，它是什么，能干什么，处理问题的一般流程是什么，会涉及到的主要概念有哪些，有了这样的基本框架后，这样在后面的实战中，大家可以再回头来比较，看哪些是属于通用流程的，哪些是具体问题所特有的技术技巧。

在这篇文章中我们主要有以下内容：

  1. 什么是深度学习
  2. 深度学习的简要发展史
  3. 和机器学习的关系和区别
  4. 深度学习有什么应用
  5. 应用深度学习的一般流程和基本概念

* * *

### 1\. 什么是深度学习

深度学习是机器学习的一个分支，是一类让计算机直接通过大量的实例，自主地从数据中学习特征的技术。

![](https://images.gitbook.cn/SVVaIO)

在人类大脑中大约有 1000 亿个神经元和 100~1000
万亿个突触，可以进行很复杂的思维活动，处理很高级有难度的任务，受神经系统的启发，深度学习主要应用神经网络模型，来让机器更智能地完成一些任务。

**神经网络** 就是按照一定规则将多个神经元连接起来的网络，不同的神经网络具有不同的连接规则。 例如全连接神经网络，它有三种层：输入层，输出层，隐藏层，第
N 层的每个神经元和第 N-1 层的所有神经元相连，同一层的神经元之间没有连接。

![](https://images.gitbook.cn/UrQ0tv)

**深度学习的“深”** ，指的就是神经网络中隐藏层的个数。普通的神经网络只包含2-3个隐藏层，而深层网络可以包含多达几百个。

不同的层负责学习不同的特征，例如在图片识别任务中，第一层可能学习到了颜色，第二层学习到了角度，第三层学习到了纹理等。
隐藏层通常以无监督模式学习到输入数据的一些特征，输出层以监督式模式来完成分类或回归的任务。

* * *

### 2\. 深度学习的简要发展史

![](https://images.gitbook.cn/FMH4Np)

（图片来自：Andrew L. Beam https://beamandrew.github.io/deeplearning/2017/02/23/deep
_learning_ 101_part1.html）

神经网络的数学模型最早出现在 1943 年的论文 《A Logical Calculus of Ideas Immanent in Nervous
Activity》 中，这个模型的神经元也叫做 McCulloch Pitts 神经元，用一种很简单的方式来模拟人类大脑的神经元，

在二十世纪 60 年代提出了反向传播的概念，后来在 1986 年 Hinton 和其他几位作者展示了如何在神经网络中应用反向传播，1989 年 Yann
LeCun 第一次将反向传播应用于实践，用 CNN 识别手写数字。

在 2000 年发现了梯度消失问题，一般的多层神经网络的表现并不是很好，在 1997 由 Sepp Hochreiter 和 Juergen
Schmidhuber 提出的 LSTM：Long Short-Term Memory 模型恰好可以改善这个问题。

2006 年 Hinton 提出的 DBN：Deep Belief Networks 引起了神经网络的第二次发展。

2012 年，在 ImageNet Large Scale Visual Recognition Challenge (ILSVRC)
比赛中，SuperVision 团队建立的深度卷积神经网络有 7 个隐藏层，5 个卷积层，包括 6000 万个参数，650,000 个神经元，6300
万个连接，通过 1000 万个图片的训练，最后在 150,000 个图片测试集上的成绩是错误率为 15.3%。

* * *

### 3\. 和机器学习的关系和区别

传统的机器学习算法，需要应用者对某个相关领域有一些专业知识，一般流程是需要人为地根据数据构造出很多个特征，然后选择合适的模型进行分类或回归等任务。

深度学习和其他机器学习算法的区别是它能够自动地学习出数据的特征表示，不需要依赖人为做很复杂的特征工程，可以直接将原始数据投入到深层神经网络，就能够自动学习到数据中的关系和模式，而且随着数据量的增加，效果还会不断地提升，

![](https://images.gitbook.cn/JaNLpY)

* * *

### 4\. 深度学习有什么应用

随着数据量的增大，计算能力的增强，云计算等技术的发展，还有很多新的神经网络结构不断被研发出来，有 TensorFlow，Theano
等能够让开发者快速迭代验证想法的开源平台，再加上可以更有效地改善梯度消失梯度爆炸过拟合等问题的激活函数，正则化方法，优化算法等技术的应用，深度学习在很多任务上的表现越来越好。

现在深度学习被广泛应用于计算机视觉，语音识别，无人驾驶，社交网络，机器翻译，生物信息学，药物设计，医学图像分析，工业自动化，和游戏等等很多领域，而且在某些任务上面的表现甚至超过了人类。

* * *

### 5\. 应用深度学习的一般流程和基本概念汇总

当我们用深度学习模型解决问题时，一般有下面几步：

  1. 加载数据
  2. 数据预处理
    * 2.1 分为训练集和测试集
    * 2.2 数据标准化归一化
  3. 定义模型
    * 3.1 权重初始化
    * 3.2 激活函数
    * 3.3 Batch Normalization
    * 3.4 Dropout
  4. 配置模型
    * 4.1 定义损失函数
    * 4.2 L1, L2 正则化
    * 4.3 选择优化算法
    * 4.4 学习率
  5. 训练模型
  6. 评估模型
    * 6.1 定义评估指标函数
  7. 做出预测
  8. 保存模型

接下来让我们简要看看其中关键的概念：

* * *

#### 2.1 训练集，验证集，测试集

**When：** 拿到数据集后，需要将数据分为训练集、验证集、测试集。

**Why：** 训练集：算法用其进行训练，学习出模型的参数，进而得到模型 验证集：用于交叉验证，为了选择出最好的模型
测试集：训练好的模型用其进行预测，评估模型的表现

**How：** 一般可以采用这样的比例：

数据量在几万或以下级别时， 无验证集的情况：70% ： 30% 有验证集的情况：60% ： 20% ： 20%

数据量在百万级别时，验证集和测试集的比重变小，只要能达到验证模型评估模型效果即可， 百万数据量：98% ： 1% ： 1% 超过百万数据量：99.5% ：
0.25% ： 0.25%

* * *

#### 2.2 数据标准化归一化

**When：** 当样本数据的各个特征具有不同的量纲时，需要对其进行标准化。

**Why：** 作用就是在应用梯度下降等算法求成本函数的最优解时，可以加快收敛速度。
直观上，以一个最简单的成本函数为例，可以将成本函数的图像由椭圆调整为圆，这样梯度下降法求最优解时就不用走很多弯路，进而减少迭代次数，加快收敛到最优解。并且无论从哪个位置开始迭代，都可以用比较少的迭代次数找到全局最优解。

![](https://images.gitbook.cn/e21qRx)

**How：** 常用的方法有：

  1. **0 均值标准化（标准化）** ：$x^* = \frac{x−μ}{σ}$， 其中 μ 为数据的均值，σ 为标准差，转换后的数据符合标准正态分布

  2. **min-max 极差标准化（归一化）** ：$x^* = \frac{x−min}{max−min}$， 其中 min 为数据中最小值，max 为最大值，转换后的数据在 0～1 之间

* * *

#### 3.1 权重初始化

**When：** 我们在训练神经网络时，需要将权重进行初始化

**Why：** 合适的初始化方法可以在一定程度上减缓梯度消失和爆炸的速度

**How：** 常用方法有：

**1\. 随机初始化** ，使其服从标准正态分布

`w = np.random.randn(layer_size[l], layer_size[l-1])`

但这个方法在训练深度神经网络时可能会造成两个问题，梯度消失和梯度爆炸。

所以在初始化权重时，不再服从标准正态分布，而是 服从方差为 k/n 的正态分布，k 因激活函数而不同。

**2\. 对于 RELU(z)** ，用这个式子 $\sqrt{\frac{2}{size^[l-1]}}$ 乘以随机生成的 w，也叫做 He
Initialization：﻿

`w = np.random.randn(layer_size[l], layer_size[l-1]) * np.sqrt(2 /
layer_size[l-1])`

**3\. 对于 tanh(z)** ，用 Xavier 初始化方法，即用这个式子 $\sqrt{\frac{1}{size^[l-1]}}$
乘以随机生成的 w，和上一个的区别就是 k 等于 1 而不是 2。﻿

`w = np.random.randn(layer_size[l], layer_size[l-1]) * np.sqrt(1 /
layer_size[l-1])`

通过这些方式，w 既不会比 1 大很多，也不会比 1 小很多，所以梯度不会很快地消失或爆炸，可以避免收敛太慢，也不会一直在最小值附近震荡。

* * *

#### 3.2 激活函数

**What：** 在神经元中，输入的 inputs 通过加权求和后，还被作用了一个函数，这个函数就是激活函数 Activation Function。

**Why：** 激活函数能够使神经网络具有非线性，这种非线性使深度网络能够学习复杂的关系，激活函数决定着一个感知器是否应该被触发。

**How：** 常用的激活函数有：

**Sigmoid：** 可以将一个实数映射到 (0,1) 的区间，即可用于转换为概率，因此可用来做二分类，但存在梯度消失问题。

**Tanh：** 是 sigmoid 的缩放版本，将输入映射到[-1,1]范围内，是 0 均值的，应用中 tanh 会比 sigmoid 更好。

**ReLU： **用于隐藏层神经元的输出，x 大于 0 时，函数值为 x，导数恒为 1，这样在深层网络中使用 relu
激活函数就不会导致梯度消失和爆炸的问题，而且 SGD 的收敛速度会比 sigmoid, tanh 快很多。但是因为 x 小于 0 时函数值恒为
0，会导致一些神经元无法激活。

**Leaky Relu：** 为了解决 Relu 函数为 0 部分的问题，当 x 小于 0 时，函数值为 kx，有很小的坡度 k，一般为
0.01，0.02，或者可以作为参数学习而得。它具有 ReLU
的所有优点：计算高效、快速收敛。而且因为导数总是不为零，减少静默神经元的出现，允许基于梯度的学习，一定程度上缓解了 dead ReLU 问题。

![Ec8vDM](https://images.gitbook.cn/Ec8vDM)

在选择激活函数的时候，如果在不知道该选什么的时候就选择 ReLU。

* * *

#### 3.3 Batch Normalization

**When：** 在前面有提到输入数据要进行标准化，在神经网络中，不仅在输入层要做这样的预处理，在隐藏层也需要做一下标准化，

**Why：**
因为前一层的输出值，对后面一层来说，就是它的输入，而且如果某个特征数量级过大，在经过激活函数时，就会提前进入它的饱和区间，即不管如何增大这个数值，它的激活函数值都在
1 附近，不会有太大变化，这样激活函数就对这个特征不敏感。

**How：** 简单理解就是在计算出前一层的 z 后，先计算出这批数据的平均值和标准差，对每个数据做完标准化之后，再经过激活函数，进入到下一层。

![iQIUsD](https://images.gitbook.cn/iQIUsD)

* * *

#### 3.4 Dropout

**What:** Dropout
是指在深度学习网络的训练过程中，按照一定的概率将一部分神经网络单元暂时从网络中丢弃，相当于从原始的网络中找到一个更瘦的网络。
即在训练时，每个神经单元都可能以概率 p 被去除，在测试阶段不需要用 Dropout。

![N7yWWQ](https://images.gitbook.cn/N7yWWQ)

**Why:** 神经网络的规模如果很大就会有这样两个缺点：费时，而且容易过拟合，所以用 Dropout 来起到收缩的作用。

**How:**

**每层 Dropout 网络和传统网络计算的不同之处：** ![rKRFqt](https://images.gitbook.cn/rKRFqt)

**相应的公式：**

![MZwndi](https://images.gitbook.cn/MZwndi)

* * *

#### 4.1 定义损失函数

**What：** 损失函数是用来衡量模型的预测值和数据的实际值之间的差距的。

**Why：** 模型训练的目的就是通过不断的迭代来使损失函数达到最小值。

**How：** 在回归问题中，常用的损失函数是 MSE：Mean squared error

$$L(y,\hat{y})=\sum_{i}(y_i-\hat{y}_i)^{2}$$

在分类问题中，最常用的就是交叉熵损失函数：Cross entropy

$$L(y, \hat{y}) = \sum_i y_i \log \frac{1}{\hat{y}_i} = -\sum_i y_i \log
\hat{y}_i$$

* * *

#### 4.2 L1, L2 正则化

**What：** L1, L2 正则化就是要在损失函数上面加入一个惩罚项，

**Why：** L1 正则化可以产生稀疏权值矩阵，可以用于特征选择，一定程度上也可以防止过拟合。 L2 正则化用于防止模型过拟合。
因为神经网络的训练目标是使成本函数最小化，在成本函数上加入一个正则化项后，如果正则化因子 λ 设置的足够大，那么权重 W 就需要足够小，甚至趋于
0，相当于减小了很多神经元的影响，一个复杂的网络变得简单些。

**How：** L1 正则化：

$$L = L_0 + \alpha \sum_w{|w|} \tag{1}$$

L2 正则化：

$$L = L_0 + \alpha \sum_w{w^2} \tag{2}$$

* * *

#### 4.3 定义优化算法

**What：** 优化算法是用来找到目标函数的最优解的算法。

**What：** 常用的优化算法有：

**梯度下降法**
：形象地理解是如果我们在一座山上，想要到达最低点，那么沿着当前位置的梯度的负方向前进一步，到达一个新位置后同样以当前位置的梯度的负方向，这样的方法是可以最快到达最低点的。

**Batch 梯度下降** ：每次对整个训练集进行梯度下降，不过这样处理耗时会较长。

$$\theta = \theta - \eta \cdot \nabla_\theta J( \theta)$$

**Stochastic 梯度下降** ：每次只对一个样本进行梯度下降，会有很多噪音，不能通过向量化来进行加速，只会在最小值附近不断的波动。

$$\theta = \theta - \eta \cdot \nabla_\theta J( \theta; x^{(i)}; y^{(i)})$$

**Mini batch 梯度下降**
：每次处理样本的个数在上面二者之间。可以进行向量化，不用等待整个训练集训练完就可以进行后续的工作，所以更新参数更快，避免局部最优。

$$\theta = \theta - \eta \cdot \nabla_\theta J( \theta; x^{(i:i+n)};
y^{(i:i+n)})$$

**Momentum 梯度下降** ：用梯度的指数加权平均数来更新权重，减少摆动，加快最小值方向上的收敛。

$$v_t = \gamma v_{t-1} + \eta \nabla_\theta J( \theta)$$

$$\theta = \theta - v_t$$

**RMSprop** ：将微分项进行平方，用平方根进行梯度更新，可以减小某些维度上波动较大的情况，进而加快梯度下降。

$$E[g^2]_t = 0.9 E[g^2]_{t-1} + 0.1 g^2_t$$

$$\theta_{t+1} = \theta_{t} - \dfrac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_{t}$$

**Adam** ：是 Momentum 和 RMSprop 的结合，在 RMSprop 的基础上加了 bias-correction 和
momentum。

$$\theta_{t+1} = \theta_{t} - \dfrac{\eta}{\sqrt{\hat{v}_t} + \epsilon}
\hat{m}_t$$

其中，

$$\hat{m}_t = \dfrac{m_t}{1 - \beta^t_1}$$

$$\hat{v}_t = \dfrac{v_t}{1 - \beta^t_2}$$

$$m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$$

$$v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 $$

整体来讲，Adam 的效果最好，所以最常用。

* * *

#### 4.4 学习率

**What：** 在梯度下降等算法中可以看到有一个系数 α ，它决定着梯度下降的步伐快慢。

**Why：** 如果 α 太大：步伐太大，可能会造成模型训练发散而不收敛，跨过最优解，使损失函数变得更糟。 如果 α
太小：步伐太小，虽然不会跨过最优解，但是损失函数的变化速度较慢，要用更长的时间才能收敛。 如果 α 固定不变：当用 mini-batch
梯度下降法时，因为不同 batch 会存在一定的噪声，所以算法在到达最小值附近时会在一个较大范围内波动而不会精确收敛。 所以采用 α
逐渐减小的策略：开始时向最小值点方向下降较快，α 逐渐减小，下降步伐逐渐变小，最终在最小值附近一个较小范围内波动。

**How：** 常用的学习率下降方法有：

常用： $$\alpha = \dfrac{1}{1+decay\\_rate*epoch\\_num}\alpha_{0}$$

指数衰减： $$\alpha = 0.95^{epoch\\_num}\alpha_{0}$$

其他： $$\alpha = \dfrac{k}{epoch\\_num}\cdot\alpha_{0}$$

* * *

#### 5\. 训练模型

神经网络的训练大体可以分为下面几步：

  1. 首先用前面提到的初始化权重 weights 和 biases
  2. 然后进行前向传播：用 input X, weights W ，biases b, 计算每一层的线性组合 Z，经过激活函数得到 A，最后一层用 sigmoid, softmax 或 linear function 等作用 A 得到预测值﻿ Y
  3. 接着计算损失，来衡量预测值与实际值之间的差距
  4. 然后进行反向传播，来计算损失函数对 W, b 的梯度 dW ，db
  5. 最后通过随机梯度下降等优化算法来进行梯度更新，重复第二到第四步直到损失函数收敛到最小

* * *

#### 6.1 定义评估指标函数

训练完模型后，需要在测试集上对模型的表现进行评估。

评估函数和损失函数很像，它们的区别是评估函数的结果不会用在模型的训练过程中，任何损失函数都可用作评估函数。

**在回归问题中可以用：**

Mean Squared Error: 计算预测值与真值的均方差 Mean Absolute Error: 计算预测值与真值的平均绝对误差 Mean
Absolute Percentage Error: 计算预测值与真值的平均绝对误差率 Cosine Proximity: 计算预测值与真值的余弦相似性

**在分类问题中可以用：**

Binary Accuracy: 对二分类问题，计算在所有预测值上的平均正确率 Categorical Accuracy:
对多分类问题，计算再所有预测值上的平均正确率 Sparse Categorical Accuracy: 与 categorical_accuracy
相同，在对稀疏的目标值预测时有用 Top k Categorical Accuracy: 计算top-
k正确率，当预测值的前k个值中存在目标类别即认为预测正确

也可以自定义评估函数。

* * *

以上就是建立深度学习模型的一般流程，其中合适的权重初始化，激活函数，Batch Normalization
用于缓解梯度消失梯度爆炸的问题；选择合适的优化算法和学习率可以加速模型的训练；正则化和 Dropout 可以缓解过拟合问题。

一般情况下我们可以先选择下面这样的配置，然后再根据模型表现进行调优：

权重初始化：He initialization 激活函数：ELU 进行 Batch Normalization 应用 Dropout 选择优化算法：Adam

当然这只是一个基本的流程，还有很多技术会在后面的实战中进行详细解释。

实战中进行详细解释。

