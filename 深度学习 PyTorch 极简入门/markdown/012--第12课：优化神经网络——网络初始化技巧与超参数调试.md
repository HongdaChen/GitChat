上一篇，我们主要介绍了神经网络中几种常见的梯度下降优化算法，包括 Mini-Batch、Momentum、Nesterov
Momentum、AdaGrad、RMSprop、Adam、Learning Rate Decay
，并对各自特点进行了说明和对比。本文将重点讲解初始化神经网络的一些技巧以及如何高效进行超参数调试。

### 网络输入标准化

我们知道，神经网络的输入层是训练样本的各个特征值，而不同特征值的数值范围可能不同。例如训练样本数据中输入层特征是二维的：$[x_1,x_2]$。$x_1$
的数值范围是 [0, 0.01]，$x_2$ 的数值范围是 [0, 100]，彼此相差了 10000 倍。$x_1$ 与 $x_2$
之间分布极不平衡，会造成训练得到的权重 $W$ 数值差别很大，参数 $b$
也是一样。这样的后果会造成运行梯度下降算法时，振荡较大，轻则影响训练速度，重则导致模型无法正确优化，无法获得优质解。

怎么理解呢？下面用图解的方式来说明。

![enter image description
here](https://images.gitbook.cn/ef681940-ac53-11e8-afe5-6ba901a27e1b)

上图显示了损失函数 $J$ 与 $W$ 和 $b$ 的凸函数关系。左边两张图没有进行输入标准化，可见 $J$ 与 $W$ 和 $b$
呈类似椭圆的形状，这是因为彼此幅值范围不同。根据上文中的假设，$x_1$ 与 $x_2$ 之间分布极不平衡，造成 $W$
数值差别很大。这时，如果学习因子过大，就容易发生振荡，使得 $J$
下降不稳定。为了减小振荡，只能尽量减小学习因子，但是会大大增加训练时间，让训练变得非常缓慢和困难。

右边两张图进行了输入标准化，$J$ 与 $W$ 和 $b$ 呈类似圆碗的形状。显然，若 $x_1$ 与 $x_2$ 之间分布范围类似，$W$
数值差异就没那么大了，$b$ 也是一样。这时，就不太容易发生较大振荡，可以设置较大的、合适的学习因子，并能够保证 $J$
有稳定的下降趋势，训练速度也会大大加快。

既然输入标准化很有必要，那么如何对输入进行标准化呢？非常简单，直接减去各自特征的均值，再除以各自特征的标准差即可。具体做法是，例如有 m
个训练样本，特征维度是 n，那么对于 n 个特征，计算其均值向量 $\mu$ 和标准差向量 $\sigma$：

$$\mu=\frac1m\sum_{i=1}^mX^{(i)}$$

$$\sigma=\sqrt{\frac{1}{m-1}\sum_{i=1}^m(X^{(i)}-u)^2}$$

$$X'=\frac{X-u}{\sigma}$$

其中，$X$ 的维度为 (m, n) ，相应的 Python 代码为：

    
    
    import numpy as np
    n, m = X.shape
    mu = 1/m * np.sum(X, axis=1)    # 均值
    sigma = np.std(X, axis=1)       # 标准差
    X = (X - mu) / sigma
    

注意上述代码中，m 表示训练样本个数，n 为特征维度，即神经网络输入层的个数。axis=1 表示对所有 m 个样本计算均值 $\mu$ 和标准差
$\sigma$。

以二维特征 $[x_1,x_2]$ 为例，图示其标准化过程如下：

![enter image description
here](https://images.gitbook.cn/dba47fc0-ac67-11e8-8a14-814e96ebc1f4)

以上是训练的标准化过程，神经网络训练结束之后，测试集便成了新的样本。对测试集如何进行标准化操作呢？注意，此时不是计算测试集的特征均值 $\mu'$ 和标准差
$\sigma'$，而是直接将测试集减去训练集的特征均值 $\mu$ 再除以训练集的标准差 $\sigma$。这样保证了训练集和测试集的标准化操作一致。

### 权重 W 初始化

我们在第 06 课中讲过，神经网络模型在开始训练时需要对各层权重系数 W 和常数项 b 进行初始化赋值。b 全部初始化为 0 即可，但 W
却不能全部初始化为 0，一般对 W 进行随机初始化，相应的 Python 代码为：

    
    
    W = np.random.randn((n[l],n[l-1]))*0.01
    

在神经网络层数较少的时候，这种初始化方法没有问题。但如果是深层神经网络，这种简单的初始化就可能会带来一些问题。

举个例子来，假设一个深层神经网络模型如下图所示：

![enter image description
here](https://images.gitbook.cn/47831050-ac6b-11e8-8a14-814e96ebc1f4)

为了简化分析，我们令常数项 b 均为 0，激活函数 $g(Z)=Z$。这样，就可得到网络的输出 $\hat y$ 为：

$$\hat Y=W^{[L]}W^{[L-1]}\cdots W^{[2]}W^{[1]}X$$

假如每个 W = 1.1、L = 100，则最后 $\hat Y=W^LX\approx1.4e4X$。也就是说，$\hat Y$ 将随 L
增加呈指数型增长。即便是 W 略大于 1，但经过每层的级联相乘，最终 $\hat Y$ 将会变得很大，我们称之为数值爆炸。另外一种情况，假如每个 W =
0.9，则最后 $\hat Y=W^LX\approx2.6e-5X$。也就是说，$\hat Y$ 将随 L 增加呈指数型衰减。即便是 W 略小于
1，但是经过每层的级联相乘，最终 $\hat Y$ 将会变得很小，我们称之为数值消失。

这种现象会带来什么后果呢？在进行神经网络反向传播梯度计算的时候，同样会引起梯度呈现同样的指数型增大或减小。梯度过大会造成损失函数曲线振荡，无法准确进行训练；梯度过小会造成损失函数曲线近乎水平，训练缓慢或基本没有效果，这些都会严重影响神经网络训练。通常，我们把这两种情况分别称为梯度爆炸和梯度消失。

为了避免发生梯度爆炸和梯度消失，我们需要对权重 W 的初始化处理进行一些改进。首先看下原理，以单个神经元为例：

![enter image description
here](https://images.gitbook.cn/6f44d380-acc0-11e8-9a15-4584d17cbf11)

该神经元的输出 a 可由下式计算得到：

$$z=w_1x_1+w_2x_2+\cdots+w_nx_n$$

$$a=g(z)$$

此处，忽略了常数项 b。我们发现，输出 a 与该神经元的输入个数 n 有一定的关系。这时，我们可以这样思考，为了不让 a 过大或者过小，应该尝试让 w 与
n 也有一定的关系，即当 n 越大的时候，w 应该小一些；当 n 越小的时候，w 应该大一些。

基于此原理，一种初始化做法是让权重 W 的方差为 $\frac1n$，相应的 Python 代码为：

    
    
    W[l]=np.random.randn(n[l],n[l-1])*np.sqrt(1/n[l-1])
    

其中，n[l] 表示该层神经元的个数，n[l-1] 表示上一层神经元的个数，即该神经元的输入。以上这种初始化方法一般适用于该神经元激活函数是 tanh
的情况。

若激活函数是 ReLU，初始化做法是让权重 W 的方差为 $\frac2n$，相应的 Python 代码为：

    
    
    w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(2/n[l-1]) 
    

除此之外，Yoshua Bengio 提出了另外一种初始化 W 的方法，就是让 W 的方差为 $\frac{2}{n^{[l-1]}\cdot
n^{[l]}}$，相应的 Python 代码为：

    
    
    w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(2/(n[l-1]*n[l])) 
    

选择哪种初始化方法因人而异，可以根据不同的激活函数选择不同方法。另外，我们可以对这些初始化方法设置某些参数，将它们作为超参数，通过验证集进行验证，得到最优参数，来优化神经网络。

那针对常数项 b 要不要采用同样的初始化处理呢？一般做法是不需要，因为常数项 b 在每层神经网络中只有一个值，影响较小，一般初始化为 0 就可以了。

### 批归一化

批归一化（Batch Normalization）由 Sergey Ioffe 和 Christian Szegedy
两位学者提出。批归一化不仅可以让调试超参数更加简单，而且可以让神经网络模型更加“健壮”。也就是说较好模型可接受的超参数范围更大一些，包容性更强，更容易去训练一个深度神经网络。接下来，我们介绍下什么是
批归一化，以及它是如何工作的。

前面我们说过对输入进行标准化处理，可以让训练更加有效，且鲁棒性更强。那对于神经网络的隐藏层，我们知道第 $l$ 层隐藏层的输入就是第 $l-1$
层隐藏层的输出 $A^{[l-1]}$。对 $A^{[l-1]}$ 进行标准化处理，从原理上来说可以提高 $W^{[l]}$ 和 $b^{[l]}$
的训练速度和准确度。这种对各隐藏层的标准化处理就是批归一化。值得注意的是，实际应用中，一般是对 $Z^{[l-1]}$ 进行标准化处理而不是
$A^{[l-1]}$。

批归一化的具体做法是对 $l$ 层的输入 $Z^{[l-1]}$ 进行标准化处理：

$$\mu=\frac1m\sum_{i=1}^mZ^{[l-1](i)}$$

$$\sigma^2=\frac{1}{m-1}\sum_{i=1}^m(Z^{[l-1](i)}-u)^2$$

$$Z^{[l-1]}_{norm}=\frac{Z^{[l-1]}-\mu}{\sqrt{\sigma^2+\epsilon}}$$

其中，m 是训练样本个数，上标 `(i)` 表示第 i 个样本。$\epsilon$ 是为了防止分母为零的常数，可取值
$10^{-8}$。这样，可使该隐藏层的所有输入 $Z^{[l-1]}$ 均值为 0，标准差为 1。

考虑到输入应该有差异性和多样性，大部分情况下并不希望所有的 $Z^{[l-1](i)}$ 均值都为 0，方差都为 1。通常需要对
$Z^{[l-1](i)}$ 做进一步处理：

$$\tilde Z^{[l-1](i)}=\gamma\cdot Z^{[l-1](i)}_{norm}+\beta$$

上式中，$\gamma$ 和 $\beta$ 是可调参数，类似于 W 和 b 一样，可以通过梯度下降等算法迭代更新求得。这里，$\gamma$ 和
$\beta$ 的作用是让 $\tilde Z^{[l-1](i)}$ 的均值和方差为任意合理值，保证其多样性。

例如，当 $\gamma=\sqrt{\sigma^2+\epsilon}$，$\beta=\mu$ 时，$\tilde
Z^{[l-1](i)}=Z^{[l-1]}$，完全一致，称之为 Identity Function。

值得注意的是，输入的标准化和隐藏层的批归一化是有区别的。输入标准化是让所有输入的均值为 0，方差为
1。而批归一化可使各隐藏层输入的均值和方差为任意值，由模型训练情况决定。实际上，从激活函数的角度来说，如果各隐藏层的输入均值在靠近 0
的区域即处于激活函数的线性区域，这样不利于训练好的非线性神经网络，得到的模型效果也不会太好。这也解释了为什么需要用 $\gamma$ 和 $\beta$
来对 $\tilde Z^{[l-1](i)}$ 作进一步处理。

批归一化不仅能够提高神经网络训练速度，而且能让神经网络的权重 W
的更新更加“稳健”，尤其在深层神经网络中更加明显。究其原因在于批归一化能够有效避免神经网络模型中的 Covariate Shift 问题。

首先我要来解释一下什么是 Covariate
Shift。它指的是训练集的数据分布和预测集的数据分布不一致，如果在训练集上训练出一个分类器，肯定在预测集上不会取得比较好的效果。这种训练集和预测集样本分布不一致的问题就叫做
Covariate Shift。比方说，我想训练一个猫类识别网络，收集的训练样本都是黑猫，但是测试样本则存在各种颜色的猫。这就是典型的 Covariate
Shift 现象，会严重影响模型在测试集上的效果。

批归一化的作用是减少了各层 $W^{[l]}$、$B^{[l]}$ 之间的耦合性，让各层更加独立，实现自我训练学习的效果。也就是说，如果输入发生
Covariate Shift，那么批归一化会对个隐藏层输出 $Z^{[l]}$ 进行均值和方差的归一化处理，$W^{[l]}$ 和 $B^{[l]}$
更加稳定，使原来的模型也有不错的表现，从而让模型变得更加健壮，鲁棒性更强。

加入批归一化之后，整个模型结构如下图所示：

![enter image description
here](https://images.gitbook.cn/5aca4ea0-aceb-11e8-9c45-adc0fa12a28f)

值得注意的是，因为批归一化对各隐藏层 $Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$ 会减去均值，所以这里的常数项 $b^{[l]}$
可以消去，其数值效果完全可以由 $\tilde Z^{[l]}$ 中的 $\beta$ 来实现。因此，我们在使用批归一化的时候，可以忽略各隐藏层的常数项
$b^{[l]}$。在使用梯度下降算法时，分别对 $W^{[l]}$，$\beta^{[l]}$ 和 $\gamma^{[l]}$ 进行迭代更新就好了。

以上介绍的是训练过程中的批归一化操作。训练过程是对单个 Mini-Batch 进行的，但在测试过程中，如果是单个样本，该如何使用批归一化进行处理呢？

在测试过程中，如果只有一个样本，求其均值和方差是没有意义的，就需要对 $\mu$ 和 $\sigma^2$
进行估计。一种方法是将所有训练集放入最终的神经网络模型中，然后将每个隐藏层计算得到的 $\mu$ 和 $\sigma^2$ 直接作为测试过程对应层的
$\mu$ 和 $\sigma^2$。第二种更为常见的方法是使用指数加权平均（Exponentially Weighted
Average）的方法来预测各层的 $\mu$ 和 $\sigma^2$。指数加权平均的做法很简单，对于第 $l$ 层隐藏层，考虑训练时所有 Mini-
Batch 在该隐藏层下的 $\mu$ 和 $\sigma^2$，然后用指数加权平均的方式来预测该隐藏层的 $\mu$ 和
$\sigma^2$。这种指数加权的思想与我们在上一篇介绍梯度优化算法中所讲的加权是一致的，起到滑动平均的效果。

另外，值得一提的是，批归一化还起到了模型正则化的效果，因为它对每个 Mini-Batch 都进行均值为 0，方差为 1 的归一化操作，且 $\gamma$
和 $\beta$ 的引入类似于增加随机噪声，效果类似于 Dropout。但是，Batch Norm 的正则化效果还是比较微弱的。

### 超参数调试

神经网络超参数调试是最花费时间也是最重要的步骤之一，掌握良好的超参数调试方法对训练优秀的神经网络模型来说非常重要。这一节我们来看一看如何进行神经网络的超参数调试。

总结一下，深度神经网络需要调试的超参数较多，简单列举几个：

  * 学习因子 $\alpha$ 

  * 动量梯度下降因子 $\beta$

  * Adam 优化算法参数 $\beta_1、\beta_2、\varepsilon$

  * 神经网络层数

  * 各隐藏层神经元个数

  * 学习因子下降参数

  * 批量训练样本包含的样本个数

  * L1、L2 正则化系数 $\lambda$

如何选择和调试超参数呢？一般的做法是对每个超参数，在一段区间内等距离间隔采样取值，然后，分别使用不同点对应的参数组合进行训练，最后根据验证集上的表现好坏，来选定最佳的参数。例如有两个超参数，分别在每个参数上选取
5 个点，这样构成了 5x5=25 种组合，如下图所示：

![enter image description
here](https://images.gitbook.cn/d4e9c9e0-acf0-11e8-afe5-6ba901a27e1b)

这是一种最规矩的做法，在超参数个数不多的时候，这种做法的效果不错。但是当超参数较多的时候，这种等距离划分的方法在空间上比较离散，从概率上来说较难找到最佳的超参数组合。

另外一种方法是随机选择超参数，同样是两个超参数，直接在二维平面区域内随机选择 25 个点，作为超参数组合，如下图所示：

![enter image description
here](https://images.gitbook.cn/b638a9b0-acf2-11e8-9c45-adc0fa12a28f)

随机化选择超参数的目的是为了尽可能地得到更多种参数组合。如果使用均匀采样的话，每个参数只有 5 种情况；而使用随机采样的话，每个参数都有 25
种可能的情况，因此每个超参数都更有可能找到最优值。

在第一次随机采样之后，我们可能得到某些区域模型的表现较好。然后为了得到更精确的最佳参数，我们应该继续对选定的区域进行由粗到细的采样（Coarse to
Fine Sampling
Scheme）。也就是放大表现较好的区域，再对此区域做更密集的随机采样。例如，对下图中右下角的方形区域再做25点的随机采样，以此类推。

![enter image description
here](https://images.gitbook.cn/8bbe3910-acf3-11e8-afe5-6ba901a27e1b)

下面讲一下选择超参数时的尺度问题。对于网络层数、隐藏层神经元个数，本身是整数值，是可以直接在一个数值范围内进行随机采样，即该超参数每次变化的尺度都是一致的（每次变化为1，犹如一个刻度尺一样，刻度是均匀的）。但是，对于某些超参数，可能需要非均匀随机采样（即非均匀刻度尺）。例如超参数
$\alpha$，待调范围是 [0.0001, 1]。如果使用均匀随机采样，那么大约有 90% 的采样点分布在 [0.1, 1] 之间，只有 10% 分布在
[0.0001, 0.1] 之间。这在实际应用中是不太好的，因为最佳的 $\alpha$ 值可能分布在 [0.0001, 0.1]
之间。因此，我们更关注的是区间 [0.0001, 0.1]，希望在此区间内选择更多的超参数进行调试，所以在这个区间内应细分更多刻度，而在其它区间刻度大一些。

通常的做法是将均匀尺度转换为非均匀 log 尺度，然后在 log 尺度下再进行均匀采样。这样，[0.0001, 0.001]，[0.001,
0.01]，[0.01, 0.1]，[0.1, 1] 各个区间内随机采样的超参数个数基本一致，也就扩大了之前 [0.0001, 0.1] 区间内采样值个数。

![enter image description
here](https://images.gitbook.cn/bc445540-acf5-11e8-9c45-adc0fa12a28f)

一般解法是如果线性区间为 [a, b]，令 m=log(a)，n=log(b)，则对应的 log 区间为 [m,n]。然后，对 log
区间进行随机均匀采样，得到采样值 r 后反推到线性区间，即 $10^r$。$10^r$ 就是最终采样的超参数数值。相应的 Python 代码为：

    
    
    m = np.log10(a)
    n = np.log10(b)
    r = np.random.rand()
    r = m + (n-m)*r
    r = np.power(10,r)
    

值得一提的是，超参数调试完所得到的最佳值并不是一成不变的，一段时间之后，需要根据新的数据和实际情况，再次调试超参数，以获得实时的最佳模型。

### 总结

本文主要介绍了优化神经网络中的一些常用技巧，包括输入标准化、权重 W 初始化、批归一化（Batch
Normalization）、超参数调试等。掌握这些技巧对训练性能良好的神经网络非常有帮助。

