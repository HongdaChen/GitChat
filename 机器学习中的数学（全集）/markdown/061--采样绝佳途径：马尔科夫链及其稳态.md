这一讲，我们将马尔科夫链引入到采样的过程中来，让它成为辅助我们进行采样的工具。

### 马尔科夫链回顾

在概率统计基础的专栏中我们曾经花了大量篇幅介绍过随机过程中的马尔科夫链，这里我们不再从头介绍，我们重新回顾一下。

随机过程指的就是一个随机变量的序列 $\\{X_t\\}$，而马尔科夫链就是随机过程中的一种非常典型的类型，它的概率图如下：

![图
1：马尔科夫链的概率图](https://images.gitbook.cn/86bba460-8e7a-11ea-9ea4-63976c8b39c8)

马尔科夫链在不同的时间 $t$ 对应着不同的状态节点 $x_t$，实际上就是用时间串联起来的一个个随机变量，这一组随机变量共享一个状态空间，其中包含 $n$
个状态，每一个时间节点对应的随机变量都会取这个状态空间中的一个具体状态。

随着时间的不断向前移动，马尔科夫链当中的不同状态节点就在不同的状态之间进行着转移，这就派生了马尔科夫链中的另一个重要参数——状态转移矩阵
$P$，显然这个矩阵应该是一个 $n\times n$ 的方阵：

$$P=\begin{bmatrix} p_{11} & p_{12} & p_{13}& ...& p_{1n}\\\ p_{21} & p_{22} &
p_{23}& ...& p_{2n}\\\ p_{31} & p_{32} & p_{33}& ...& p_{3n}\\\ ... & ... &
...& ...& ...\\\ p_{n1} & p_{n2} & p_{n3}& ...& p_{nn}\\\ \end{bmatrix}$$

其中某个具体的元素 $P_{ij}$ 表示从状态 $i$ 转移到状态 $j$ 的概率。用条件概率描述就是
$P_{ij}=p(x_{t+1}=j|x_t=i)$。

这里我们只考虑一阶齐次马尔科夫链，简单点说，就是未来的状态只取决于现在，而与过去无关。用条件概率描述就是：

$$p(x_{t+1}=x|x_1,x_2,x_3,...,x_t)=p(x_{t+1}=x|x_t)$$

最后我们再来解释一下，马尔科夫链概率图中每个时间 $t$ 时刻节点对应的 $\pi_t$ 表示的是什么。

$\pi_t$ 表示 $t$ 时刻的概率分布，这是什么意思呢，因为节点之间的状态是依照概率进行转移的，也就是说任意时刻 $t$ 节点，对于 $n$
个状态中的任意一个状态，它都有可能取到，因此 $\pi_t$ 是一个向量，对应的是在 $t$ 时刻，$n$ 个不同状态中每一个状态出现的概率：

$$\pi_t=[\pi_t(1),\pi_t(2),\pi_t(3),...,\pi_t(n)]$$

并且满足：

$$\sum_{i=1}^n\pi_t(i)=1$$

那么依照状态转移的定义，将 $t$ 时刻和 $t+1$ 时刻的状态分布 $\pi_t$、$\pi_{t+1}$，以及状态转移矩阵 $P$ 结合起来就有：

$$\pi_{t+1}(x^{*})=\sum_x\pi_t(x)p(x^{*}|x)$$

这其中，$x$ 和 $x^*$ 是这个马尔科夫链状态空间中 $n$ 个状态里任意两个状态。

总体合成状态转移矩阵和状态分布向量之间相乘的形式就是：$\pi_tP=\pi_{t+1}$。

### 核心：马尔科夫链的平稳分布

接下来就要在这个状态分布 $\pi$ 上做足功夫，对于某一个具体的马尔科夫链而言，每一个时刻 $t$ 都有一个状态分布
$\pi_t$，但是如果对于任意不同的时刻 $t$ 和 $t+1$，它们的分布保持不变，都为 $\pi$ 的话，那么状态分布 $\pi$
就是这个马尔科夫链的平稳分布，按照定义它满足：

$$\pi(x^{*})=\sum_x\pi(x)p(x^{*}|x)$$

而此时，平稳分布 $\pi$ 和状态转移矩阵 $P$ 满足：$\pi P=\pi$。

换句话说，也就是意味着，当从某个时刻 $t$ 开始，它的各个状态服从平稳分布 $\pi$ 的话，那么后续的任意时刻，状态的分布都为平稳分布 $\pi$。

### 马尔科夫链进入稳态的转移过程

此时，结合我们上面介绍的内容，我们来细细回顾一下随着时间 $t$ 的变化，马尔科夫链上各个相邻时间节点之间的状态转移变化过程：

  * $t=1$ 时刻：从 $\pi_1$ 中，依概率采样状态 $x_1$，显然 $x_1\sim \pi_1$。
  * $t=2$ 时刻：从 $p(x|x_1)$ 中，依概率采样状态 $x_2$，显然 $x_2\sim \pi_2$，其中 $\pi_2=\pi_1P$，这里补充说明一点 $p(x|x_1)$ 也可以由一个分布向量表示，比如 $x_1$ 是状态 2，那么这个分布向量就是状态转移矩阵$P$中的整个第 2 行：$[p_{21},p_{22},p_{23},...,p_{2n}]$。
  * $t=3$ 时刻：从 $p(x|x_2)$ 中，依概率采样状态 $x_3$，显然 $x_3\sim \pi_3$，其中 $\pi_3=\pi_2P$。

就这样，经过了一段时间，当 $t=k$ 的时候，我们发现： $t=k$ 时刻，从 $p(x|x_{k-1})$ 中，依概率采样状态 $x_k$，我们发现
$x_k\sim \pi_k$。

$t=k+1$ 时刻，从 $p(x|x_k)$ 中，依概率采样状态 $x_{k+1}$，我们发现 $x_{k+1}\sim
\pi_{k+1}$，但是请注意，此时 $\pi_{k+1}=\pi_k$，后续一直延续这个情况，那么此时马尔科夫链进入到了稳态。

这就是一个直观的展示，它演示了从 $t=1$ 时刻开始，马尔科夫链上的状态不断依照状态转移概率进行转移，并最终进入到稳态的过程。

### 马尔科夫链稳态的价值和意义

那么这个稳态有什么意义呢？比如进入到马尔科夫链的稳态之后，每一个不同的时刻$t$都会对应状态集中的一个状态，当然它是随机的，但是由于进入了稳态，它们都服从同样一个分布，也就是该马尔科夫链的稳态分布
$\pi$，那么依照大数定律，将进入平稳状态之后的每个 $t$ 时刻的状态都作为一个样本，而形成一个样本集，那么这个样本集就可以作为这个平稳分布的近似。

这里有两个问题，实际在工程中，如何判断是否进入到平稳分布？进入平稳分布前的时间我们称之为是“燃烧期”，那么如果让燃烧期取一个相对较长的时间，一般而言就可以保证马尔科夫链进入到稳态。

第二，进入到稳态之后，采样的时间节点越多，那么样本集就越能够作为平稳分布的近似。

那么后续的思路就很直接了，如果要通过采样的方式去求取目标分布
$p(z)$，那我们就引入马尔科夫链的稳态分布，让我们的目标分布恰为某一个马尔科夫链的稳态分布，那么我们在该马尔科夫链上进行长时间的状态转移，燃烧期之后我们收集到进入稳态后各个时刻点的样本，该样本集就可以作为目标分布的一个近似了。

### 稳态判定：细致平稳条件

那么如何达到上述目标？如何判断一个分布 $\pi$ 是一个给定马尔科夫链的平稳分布？这里就必须要使用马尔科夫链中著名的细致平稳条件：

> 给定一个马尔科夫链的状态转移矩阵 $P$，以及一个分布 $\pi$，如果满足：
>
> $$\pi(x)p(x^*|x)=\pi(x^*)p(x|x^*)$$
>
> 其中，$x$ 和 $x^*$ 是该马尔科夫链状态空间中任意两个给定状态，那么分布 $\pi$ 就是该马尔科夫链的平稳分布。

这个定理证明起来也相当容易：

由于 $\pi(x)p(x^*|x)=\pi(x^*)p(x|x^*)$，那么对等式两侧同时关于状态 $x$ 所有的可取值进行求和：

$$\sum_x\pi(x)p(x^*|x)=\sum_x\pi(x^*)p(x|x^*)=\pi(x^*)\sum_xp(x|x^*)$$

显然，当 $x$ 取遍状态集中的所有状态时，有：

$$\sum_xp(x|x^*)=1$$

因此：

$$\sum_x\pi(x)p(x^*|x)=\pi(x^*)$$

这个不就是平稳分布的定义吗？于是我们就证明了细致平稳条件。

那么回到正题，我们如何利用这个细致平稳条件，为给定的目标分布 $p(z)$ 寻找到一个合适的马尔科夫链，使得 $p(z)$
恰为这个马尔科夫链的平稳分布呢？这个问题，我们下一讲彻底讲明。

