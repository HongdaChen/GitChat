### 从事件到随机变量

在前面两篇内容中，我们介绍了事件概率的一些基本概念，给大家找了找概率的感觉，对于“试验”、“试验结果”、“事件发生的概率”等等重要概念有了直观的认识，那么我们进一步来讨论一个新的概念。

我们可以把某一次具体试验中所有可能出现的结果构成一个样本空间，对于样本空间中的每一个可能的试验结果，我们去将他关联到一个特定的数。这种试验结果与数的对应关系就形成了
**随机变量** ，将试验结果所对应的数称为随机变量的取值。这里就是接下来要讨论的重要内容。

请注意这个概念中的一个关键点，随机变量如何取值？他可以直接就是试验的结果取值，比如“抛掷骰子的结果点数为 $5$”。

但是，随机变量更多的是这种情况，比如随机变量可以是“连续抛掷硬币 $10$
次，其中硬币正面出现的次数”，或者是“转了一道弯”的映射值：我们把骰子连续抛掷两次，随机变量对应连续两次试验中的最大值或者点数之和，这就是映射的情况。但是无论如何，对于随机变量，都必须要明确对应具体的取值。

![图1.随机变量表示试验结果与数的对应关系](https://images.gitbook.cn/5d01f2c0-b421-11e9-a960-5951e3207033)

### 离散型随机变量及其要素

读者们很容易联想到，随机变量作为一种映射后的取值，本质上和函数取值一样，可以有连续型和离散型两种，在这一篇里，我们主要讨论离散型的情况和应用场景，连续型的情况放在下一篇来讲解。

对于连续和离散的概念，大家脑海里的直观印象往往更加简单，但具体怎么用形式化的概念语言来描述他，反而要更繁琐一些。我们还是严格的对离散型随机变量做一个定义，即：随机变量的取值只能是
**有限多个** 或者是 **可数的无限多个值** 。

那么对于任意的我们获取的一组随机变量，最关注的是哪些要素呢？我来列举一下：

**第一：随机变量的取值。** 显然这个是我们首先需要关注的，由试验结果派生出的这一组随机变量到底能取到哪些值，这是我们首要关注的问题点。

**第二：试验中每个对应取值的概率。** 每个事件的结果肯定不是等概率的，这也恰恰就是我们研究的出发点。

**第三：随机变量的统计特征和度量方法。**
弄清楚随机变量每一个具体的取值，我们把握的是他的个体特征，那么如何从整个上来把握这一组随机变量的统计特征呢？这也是非常重要的。

结合三个问题，来讨论一下离散型随机变量的分布

### 离散型随机变量的分布列

分布列描述的就是离散型随机变量每一种取值及其对应的概率，随机变量一般用大写字母表示，其具体的取值一般用小写字母来表示。例如，随机变量 $X$
的分布列，我们一般用 $p_X$，而用 $x$ 来表示随机变量 $X$ 的某个具体取值，因此把上述信息合起来就有：

随机变量 $X$ 取值为 $x$ 的概率，本质上也是一个事件的概率，这个事件就是
$\\{X=x\\}$，我们将他记作：$P_X(x)=P(\\{X=x\\})$。

为了更清楚的解释这个式子，我们还是回到抛硬币这个最简单的情况中来。随机变量 $X$ 表示两次抛掷硬币正面向上的次数，随机变量 $X$ 的分布列如下表所示：

取值 | 0 | 1 | 2 | 其他  
---|---|---|---|---  
`$P$ | $\frac{1}{4}$ | $\frac{1}{2}$ | $\frac{1}{4}$` | 0  
  
从上面的随机变量分布列中我们可以清晰地看出随机变量 $X$ 的每一种取值以及所对应的取值概率。例如，正面向上的次数为 $1$ 时，对应的事件概率为
$\frac{1}{2}$。

这个分布列虽然非常简单，但是麻雀虽小五脏俱全，下面我们来重点关注里面最重要的两个要点。

第一，对于随机变量 $X$ 的所有可能取值，其概率之和为 $1$，表示成表达式就是：$\sum_{x}{P_X(x)}=1$

第二，对于随机变量 $X$ 的不同取值 $x$，对应的事件 $\\{X=x\\}$ 彼此之间是互不相容的。因此多个事件构成的事件集合 $S$
的发生概率，可以通过对应事件发生的概率直接相加得到。即：$P(X\in S)=\sum_{x\in S}{p_X(x)}$

举个例子，比如我们想计算一下连续两次抛掷硬币，出现正面向上的概率为多大，这个事件集合实际上包含了两个事件：事件 $1$ 是 $\\{X=1\\}$，事件
$2$ 是 $\\{X=2\\}$，二者彼此是互不相容的，我们按照上面的式子可以得出其概率：

$P(X>0)=\sum_{x=1}^{2}{p_X(x)}$
$=P_X(1)+P_X(2)=\frac{1}{2}+\frac{1}{4}=\frac{3}{4}$

### 分布列和概率质量函数 PMF

一般情况下，我们最好是结合图形来观察一个随机变量的分布，这样一来，他的特性就能够非常直观的展现出来。

这里，就不得不提一下概率质量函数（$PMF$），概率质量函数就是将随机变量的每个值映射到其概率上，看上去和分布列就是一回事儿。

以上，就讲清楚了离散型随机变量的基本概念。下面开始详细介绍几种常见且非常重要的随机变量，并且借助 Python 工具来进行随机变量的生成和概率的展示。

### 二项分布及二项随机变量

#### 分布列及 PMF

我们还是举抛硬币的例子：将一个硬币抛掷 $n$ 次，每次抛掷出现正面的概率为 $p$，每次抛掷彼此之间都是相互独立的，随机变量 $X$ 对应 $n$
次抛掷得到的是正面的次数。

这里，随机变量 $X$ 服从二项分布，二项分布中的核心参数就是上面提到的 $n$ 和 $p$，随机变量的分布列可以通过下面这个熟悉的公式计算得到：

$p_X(k)=P(X=k)=\begin{pmatrix} n\\\ k \end{pmatrix}p^k(1-p)^{n-k}$

下面通过依次指定不同的 $(n,p)$ 参数：$(10,0.25)$,$(10,0.5)$,$(10,0.8)$，来绘制 $PMF$
图，来观察一下二项随机变量的分布情况。

**代码片段：**

    
    
    from scipy.stats import binom
    import matplotlib.pyplot as plt
    import seaborn
    seaborn.set()
    
    fig, ax = plt.subplots(3, 1)
    params = [(10, 0.25), (10, 0.5), (10, 0.8)]
    x = range(0, 11)
    
    for i in range(len(params)):
        binom_rv = binom(n=params[i][0], p=params[i][1])
        ax[i].set_title('n={},p={}'.format(params[i][0], params[i][1]))
        ax[i].plot(x, binom_rv.pmf(x), 'bo', ms=8)
        ax[i].vlines(x, 0, binom_rv.pmf(x), colors='b', lw=3)
        ax[i].set_xlim(0, 10)
        ax[i].set_ylim(0, 0.35)
        ax[i].set_xticks(x)
        ax[i].set_yticks([0, 0.1, 0.2, 0.3])
    
    plt.show()
    

**运行结果：**

![图2.二项分布PMF示意图](https://images.gitbook.cn/e84c5890-c176-11e9-8621-c1fbe3716b21)

挺好看的一张图，我们来简要解释一下代码：

  * **第 11 行：** 生成服从指定参数 $n$, $p$ 的二项分布随机变量。
  * **第 12 行~第 18 行：** 分别对其进行 **PMF** 图绘制，因为是离散型随机变量，因此不建议画成折线图，这种形态更为合适一些。

在这个例子中，我们直接通过 $scipy$ 中的 $stats$ 模块得到的二项分布的概率质量函数，也就是反映了不同参数条件下，随机变量 $X$
各取值点所对应的取值概率。

#### 随机变量的采样

我们可以使用 $binom$ 模块中的 $rvs$ 方法进行二项随机变量的采样模拟，我们可以指定所要采样的随机变量个数，这里指定重复采样 $10$
万次。我们使用三组参数 $(n,p)$，分别是$(10,0.25)$，$(10,0.5)$ 和 $(10,0.8)$。

通过上述模拟采样试验可以得到每种实验结果所对应的次数，然后我们通过归一化，可以计算出随机变量每一种取值所对应的频数，并将其作为概率的近似进行绘图观察。

**代码片段：**

    
    
    from scipy.stats import binom
    import matplotlib.pyplot as plt
    import seaborn
    seaborn.set()
    
    fig, ax = plt.subplots(3, 1)
    params = [(10, 0.25), (10, 0.5), (10, 0.8)]
    x = range(0, 11)
    for i in range(len(params)):
        binom_rv = binom(n=params[i][0], p=params[i][1])
        rvs = binom_rv.rvs(size=100000)
        ax[i].hist(rvs, bins=11, normed=True)
        ax[i].set_title('n={},p={}'.format(params[i][0], params[i][1]))
        ax[i].set_xlim(0, 10)
        ax[i].set_ylim(0, 0.4)
        ax[i].set_xticks(x)
        print('rvs{}:{}'.format(i, rvs))
    
    plt.show()
    

**运行结果：**

    
    
    rvs0:[0 4 2 ... 3 2 3]
    rvs1:[6 6 5 ... 5 7 8]
    rvs2:[7 8 9 ... 9 7 8]
    

![图3.基于二项分布的采样](https://images.gitbook.cn/f8bb44a0-c169-11e9-97a8-35dcf136a505)

程序打印的结果是三个数组，这就是我们在不同参数下分别做 $10$ 万次采样试验的结果数组。

#### 随机变量的数字特征

服从二项分布的随机变量，他的期望和方差的表示很简单，服从参数为 $(n,p)$ 的二项分布的随机变量 $X$，他的期望和方差的公式我们直接给出来：

期望：$E[X]=np$

方差：$V[X]=np(1-p)$

我们可以结合上面的试验，用几种方法来验证一下上述结论：

**代码片段：**

    
    
    import numpy as np
    from scipy.stats import binom
    
    binom_rv = binom(n=10, p=0.25)
    mean, var, skew, kurt = binom_rv.stats(moments='mvsk')
    
    binom_rvs = binom_rv.rvs(size=100000)
    E_sim = np.mean(binom_rvs)
    S_sim = np.std(binom_rvs)
    V_sim = S_sim * S_sim
    
    print('mean={},var={}'.format(mean,var))
    print('E_sim={},V_sim={}'.format(E_sim,V_sim))
    print('E=np={},V=np(1-p)={}'.format(10 * 0.25,10 * 0.25 * 0.75))
    

**运行结果：**

    
    
    mean=2.5,var=1.875
    E_sim=2.50569,V_sim=1.8735076238999997
    E=np=2.5,V=np(1-p)=1.875
    

我们用三种方法计算了服从参数为 $(n=10,p=0.25)$ 的二项分布随机变量的均值和方差，其中：

  * **第 4 行~第 5 行：** 是用函数包中的方法计算的分布的各个理论统计值；
  * **第 7 行~第 10 行：** 从采样试验中得到的样本数据计算出来的均值和方差；
  * **第 14 行：** 通过公式直接计算出来的理论值。

看的出，利用采样样本数据计算出来的值和理论值基本上是相等的。

### 几何分布与几何随机变量

#### 几何分布的应用场景

我们在二项分布的基础上再来介绍几何分布，在连续抛掷硬币的试验中，每次抛掷出现正面的概率为 $p$，出现反面的概率为 $1-p$，在这种背景下，几何随机变量
$X$ 就用来表示连续抛掷硬币直到第一次出现正面所需要的抛掷次数。

或者我们再举一个直白点的例子，学校里有 $10$
个白富美女生（假定她们互相不认识，保证独立性），你依次去找她们表白，只要有一个成功了，你就结束了单身狗的日子。但是表白成功的概率为
$p$，当然，成功的概率肯定不大，但是你秉持着死皮赖脸、死缠烂打，不成功誓不罢休的精神，只要女神拒绝你的表白，就换一个女神继续表白，直到某一个女神答应你为止，那么你一共表白过的总的次数，就是几何型的随机变量。

#### 几何分布的 PMF 图

我们还是先绘制几何分布的 PMF 图，方法和二项分布并无二致。

**代码片段：**

    
    
    from scipy.stats import geom
    import matplotlib.pyplot as plt
    import seaborn
    seaborn.set()
    
    fig, ax = plt.subplots(2, 1)
    params = [0.5, 0.25]
    x = range(1, 11)
    
    for i in range(len(params)):
        geom_rv = geom(p=params[i])
        ax[i].set_title('p={}'.format(params[i]))
        ax[i].plot(x, geom_rv.pmf(x), 'bo', ms=8)
        ax[i].vlines(x, 0, geom_rv.pmf(x), colors='b', lw=5)
        ax[i].set_xlim(0, 10)
        ax[i].set_ylim(0, 0.6)
        ax[i].set_xticks(x)
        ax[i].set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])
    
    plt.show()
    

**运行结果：**

![图4.几何分布的pmf图](https://images.gitbook.cn/f1e94790-c181-11e9-8621-c1fbe3716b21)

#### 采样试验和数字特征

同样的，我们进行 $10$ 万次采样试验，来观察验证一下，同时观察他的统计特征。

**代码片段：**

    
    
    from scipy.stats import geom
    import matplotlib.pyplot as plt
    import seaborn
    seaborn.set()
    
    x = range(1, 21)
    geom_rv = geom(p=0.5)
    geom_rvs = geom_rv.rvs(size=100000)
    plt.hist(geom_rvs, bins=20, normed=True)
    plt.gca().axes.set_xticks(range(1,21))
    
    mean, var, skew, kurt = geom_rv.stats(moments='mvsk')
    print('mean={},var={}'.format(mean,var))
    plt.show()
    

**运行结果：**

    
    
    mean=2.0,var=2.0
    

![图5.几何分布的采样试验](https://images.gitbook.cn/2bd9ac00-c179-11e9-9166-bdb140d6509f)

总结一下，几何分布的期望和方差分别为：

$E[X]=\frac{1}{p}$

$V[X]=\frac{1-p}{p^2}$

### 泊松分布及泊松随机变量

#### 泊松分布的应用场景

我们刚刚讲了，$n$ 次独立的伯努利试验成功的次数是一个服从二项分布的随机变量，其中参数为 $n$ 和 $p$，期望为
$np$。我们这里看一种非常特殊的情况就是：$n$ 非常大，$p$ 非常小，但是期望 $np$ 结果适中。

现实生活中有没有这类情况？有，比如我们考虑任何一天内发生飞机事故的总数，记作随机变量 $X$，总共飞机飞行的次数 $n$
非常大，但是单架次飞机出现事故的概率 $p$ 非常小。或者用随机变量 $X$ 表示一本书中字印刷错误的次数，$n$ 表示一本书中的总字数，非常大，而 $p$
表示每个字印刷出错的概率，非常小。

这种情况下，$n$ 很大 $p$ 很小，二项分布的分布列可以简化为我们这里谈到的泊松分布的分布列：

$p_X(k)=e^{-\lambda}\frac{\lambda^k}{k!}$

其中，

$\lambda=np$，$k=0,1,2,...$

期望和方差满足：

$E[X]=\lambda$

$V[X]=\lambda$

特别的，当我们的 $n\rightarrow \infty$，且 $p=\lambda / n \rightarrow 0$ 时，对应的二项分布列：

$p_X(k)=P(X=k)=\begin{pmatrix} n\\\ k \end{pmatrix}p^k(1-p)^{n-k}$
就收敛于上面的泊松分布列了。

通俗点说把，就是只要当 $\lambda=np$，且 $n$ 非常大，$p$
非常小，泊松分布就是二项分布的一个非常好的近似。计算简便就是他的一个很大的优势。

#### 泊松分布的 PMF 图

同样的，我们也用 Python 代码来画一下他的 PMF 函数图，对应的观察一下指定参数下泊松分布的分布列。

正如我们所说，泊松分布的参数就是一个 $\lambda$，我们分别绘制一个 $\lambda=10$ 和 $\lambda=2$ 的泊松分布 PMF
图，并获取他们的均值和方差。

**代码片段：**

    
    
    from scipy.stats import poisson
    import matplotlib.pyplot as plt
    import seaborn
    seaborn.set()
    
    fig, ax = plt.subplots(2, 1)
    x = range(0, 20)
    params = [10, 2]
    
    for i in range(len(params)):
        poisson_rv = poisson(mu=params[i])
        mean, var, skew, kurt = poisson_rv.stats(moments='mvsk')
        ax[i].plot(x, poisson_rv.pmf(x), 'bo', ms=8)
        ax[i].vlines(x, 0, poisson_rv.pmf(x), colors='b', lw=5)
        ax[i].set_title('`$\\lambda$`={}'.format(params[i]))
        ax[i].set_xticks(x)
        print('lambda={},E[X]={},V[X]={}'.format(params[i], mean, var))
    
    plt.show()
    

**运行结果：**

    
    
    lambda=10,E[X]=10.0,V[X]=10.0
    lambda=2,E[X]=2.0,V[X]=2.0
    

![图6.泊松分布的 PMF
图](https://images.gitbook.cn/9a686ba0-c180-11e9-9969-976e2ac29eb2)

同样的，我们对 $\lambda=2$ 的泊松分布进行采样。

**代码片段：**

    
    
    import numpy as np
    from scipy.stats import poisson
    import matplotlib.pyplot as plt
    import seaborn
    seaborn.set()
    
    lambda_ = 2
    data = poisson.rvs(mu=lambda_, size=100000)
    plt.figure()
    plt.hist(data, normed=True)
    plt.gca().axes.set_xticks(range(0, 11))
    print('mean=', np.mean(data))
    print('var=', np.square(np.std(data)))
    plt.show()
    

**运行结果：**

    
    
    mean= 2.00542
    var= 2.0082906236
    

![图7.泊松分布采样模拟](https://images.gitbook.cn/a2f09ad0-c181-11e9-9969-976e2ac29eb2)

这也是我们通过 10 万次采样试验得出的统计结果，我们通过这个结果集计算了均值和方差，和模型的理论推导值是一致的。

离散型随机变量的内容就暂时到这，在下一篇，我们将介绍连续型随机变量的有关内容。

### 分享交流

为了方便与作者交流与学习，GitChat 编辑团队组织了一个专栏读者交流群，用微信扫码添加小助手，回复关键字【2052】给小助手伽利略获取入群资格。

![R2Y8ju](https://images.gitbook.cn/R2Y8ju.jpg)

