### 统计推断的根源和场景

在讲具体的统计推断原理和方法之前，让我们追根溯源，先来看看这个问题的萌发根源和应用场景在哪，它的需求背景从何而来。

我们还是来看那个熟悉的贝叶斯公式：

$$p(\theta|x)=\frac{p(x|\theta)p(\theta)}{p(x)}$$

其中，$\theta$ 是模型的参数，$p(\theta)$ 是事先给定的参数的先验分布 $p(\theta)$，$p(x|\theta)$
是似然。$p(x)$ 是观测变量的概率，在某个给定的试验背景下，它是一个常数，可以通过积分运算
$p(x)=\int_{\theta}p(x|\theta)p(\theta)d\theta$ 求得。

这都是老生常谈的内容了，相信大家都很熟悉。

### 后验分布：推断过程的关注重点

那么基于上述贝叶斯框架，实际上我们有下面两个新的概念：

  * 第一个是贝叶斯推断，实际上就是利用这个贝叶斯框架，把后验概率 $p(\theta|x)$ 计算出来。
  * 第二个是贝叶斯决策，指的是在已有的 $N$ 个样本 $X$ 的基础上，求出现一个新增样本 $\hat{x}$ 的概率：$p(\hat{x}|X)$，那么这个概率如何求解？我们简单地通过下面的转换关系就可以求得，我们把模型的参数 $\theta$ 引入进来当做一个变换的桥梁：

$$p(\hat{x}|X)=\int_{\theta}p(\hat{x},\theta|X)d\theta=\int_{\theta}p(\hat{x}|\theta)p(\theta|X)d\theta$$

发现了没，贝叶斯决策的关键环节，也是要先获得后验分布$p(\theta|X)$。而贝叶斯推断的式子
$\int_{\theta}p(\hat{x}|\theta)p(\theta|X)d\theta$ 实际上就是 $p(\hat{x}|\theta)$
这个式子关于后验概率 $p(\theta|X)$ 的期望。

因此，求得后验分布或者是后验分布的期望，就是许多工作的重要环节，这就是推断（inference）的过程，因此就成为了我们从这一节开始，接下来几讲内容的讨论重点。

### 精确推断和近似推断

首先在一些非常简单的情况下，后验分布是可以直接求出精确的解析解的，我们称之为精确推断方法，但是这种方法对参与贝叶斯框架中的分布的要求很严格，要求其具备共轭特性，比如，高斯分布具备非常好的特性，高斯分布的联合分布、条件分布、边缘分布等都是高斯分布，因此如果参与推断的分布都是高斯分布的话，我们是可以通过公式直接计算出结果高斯分布的均值、方差参数的。

比如先验和似然都是高斯分布的情况下，后验分布也是高斯分布。

先验分布是 beta 分布，似然服从二项分布，得到的后验仍然是beta 分布。

当满足这种情况的时候，结局是非常完美的，因为我们在已知后验分布类型的情况下，是可以直接计算出后验分布的参数。

但是毕竟这种情况还是少数，同时常常因为参数空间的维度和复杂度高，没有办法让我们通过直接计算求得后验的解析解，因此我们常常是只能通过近似的方法，来得到后验分布或者分布期望的近似结果，这是另外一种分类，即：近似推断。

近似推断这个大类中，还分为两类具体方法，一种是确定性近似，也就是我们下面要提到的变分推断，另一种是随机近似，是我们后面两讲内容中要着重介绍的 MCMC
方法。

### 确定性近似：变分推断概述

这里我们重点介绍一下变分推断的核心思想，我们的目的是去找一个分布 $Q(\theta)$ 去逼近一个没办法找到解析解的后验分布
$p(\theta|X)$，变分推断之所以称之为确定性近似，是因为虽然结果不是精确的，是近似结果，但是它能拿出一个解析解的形式。

具体的思路过程是这样的。

我们令 $X$ 是观测数据，$\theta$ 是参数。

$$p(X,\theta)=p(X)p(\theta|X)\Rightarrow
p(X)=\frac{p(X,\theta)}{p(\theta|X)}$$$$\Rightarrow
log~p(X)=log~p(X,\theta)-log~p(\theta|X)$$

这里我们引入用来近似目标后验分布 $p(\theta|X)$ 的近似分布 $q(\theta)$：

$$log~p(X)=(log~p(X,\theta)-log~q(\theta))-(log~p(\theta|X)-log~q(\theta))$$$$=log~\frac{p(X,\theta)}{q(\theta)}-log~\frac{p(\theta|X)}{q(\theta)}$$

最终，我们拿到了这样一个等式：

$$log~p(X)=log~\frac{p(X,\theta)}{q(\theta)}-log~\frac{p(\theta|X)}{q(\theta)}$$

这个等式并不会让我们感到陌生，在前面 EM 的内容中我们也曾经见到过，这里的处理手法也是类似的，即对左右两边同时乘以 $q(\theta)$ 并求积分：

$$左边=\int_{\theta}log~p(X)q(\theta)d\theta=log~P(X)\int_{\theta}q(\theta)d\theta=log~p(X)$$

$$右边=\int_{\theta}q(\theta)log~\frac{p(X,\theta)}{q(\theta)}d\theta-\int_{\theta}q(\theta)log~\frac{p(\theta|X)}{q(\theta)}d\theta$$$$=\int_{\theta}q(\theta)log~\frac{p(X,\theta)}{q(\theta)}d\theta+\int_{\theta}q(\theta)log~\frac{q(\theta)}{p(\theta|X)}d\theta$$

这两部分都很有讲究，其中：

$$\int_{\theta}q(\theta)log\frac{p(X,\theta)}{q(\theta)}d\theta$$

我们记作是 $L(q)$。

$$\int_{\theta}q(\theta)log~\frac{q(\theta)}{p(\theta|X)}d\theta$$

很明显，是 KL 散度的定义式，它用来描述 $q(\theta)$ 和 $p(\theta|X)$ 两个分布之间的距离，记作 $KL(q||p)$，从
$KL$ 散度的基本性质可知：$KL(q||p) \ge 0$。

因此我们联立左右两边的式子：

$$log~p(X)=L(q)+KL(q||p)$$

那么 $log~p(X)$ 可以视作是与参数 $\theta$ 无关的量，当 $X$ 固定时，$log~p(X)$ 的值就固定了，由于 $KL(q||p)
\ge 0$，因此 $L(q)$ 取值的上限就是左侧的 $log~p(X)$，于是我们的思考方向就很简单了，让 $L(q)$ 取得最大，变相地使得
$KL(q||p)\Rightarrow 0$。

KL 散度描述的是两个分布之间的距离，当 $KL(q||p)\Rightarrow 0$ 时，就代表着 $q(\theta)$ 可以作为目标后验分布
$p(\theta|X)$ 的一个近似了。

后续具体的计算过程我们不再展开，这里只是做一个思路上的介绍，在实际过程中，我们更多地是使用随机近似的方法，下一讲我们着重进行讲解。

