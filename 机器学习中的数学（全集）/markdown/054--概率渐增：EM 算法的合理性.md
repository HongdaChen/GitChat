### EM 算法的背景介绍

在上一讲中，我们用一个例子介绍了含有隐变量的情形下，如何用迭代法去估计模型的参数，这是 EM 算法的概念基础。那么，从这一讲开始，我们将深入到 EM
算法的理论中去，带领读者们一探究竟。

在极大似然估计中，我们就是用求最值的方法，将使得 $p(x|\theta)$ 取得最大值的参数 $\theta$
作为我们的估计值，有一类概率模型比较简单，它只有观测变量
$x$，就像是我们在第一讲里介绍的单中心的高斯分布，我们可以直接利用模型分布的观测变量，基于极大似然估计法，估计出这个模型的参数。

而在另一些模型中，还含有一类隐变量 $z$，这一类变量是观测不到的，这使得在这一类模型中 $p(x|\theta)$ 就无法仅仅利用观测变量 $x$
直接通过求导等解析方法一步求得估计值 $\theta$，那么就必须换一种思路，采用一轮一轮迭代的方法，不断地逼近真实解。

如何迭代？又为何能保证一定能逼近真实的参数 $\theta$？相信大家到这里肯定还是一头雾水，心里肯定藏着这两个问题。

### 先抛出 EM 算法的迭代公式

首先，我们来看看如何迭代。这里我们首先拿出 EM 算法中的参数迭代公式：

$$\theta^{(t+1)}=argmax_{\theta}\int_{z}log~p(x,z|\theta)~p(z|x,\theta^{(t)})dz$$

这样在第 $t$ 轮迭代的过程中，我们就能利用第 $t$ 轮的参数估计值 $\theta^{(t)}$，去迭代地估计出第 $t+1$ 轮的参数
$\theta^{(t+1)}$。

那么，如果我们在假定出一个初值 $\theta^{(0)}$
的情况下，就能不断地通过这个迭代公式，一轮一轮地迭代下去。至于说这个公式怎么来的，我们这里先不展开，我们放在下一讲当中介绍。

第二，这种迭代的方法为何有效？换句话说，我们如何能保证从 $\theta^{(0)}$
开始，$\theta^{(1)}$，$\theta^{(2)}$，$\theta^{(3)}$，$\theta^{(4)}$……，一直到
$\theta^{(t)}$ 的迭代过程中，使得每一次迭代都能使似然函数 $p(x|\theta)$
的值不断增大，实现最终的收敛性。只要保证每次迭代，$p(x|\theta)$ 的值都在增大，那么这个方法就是有效的，可行的。

### EM 方法为什么是有效的

我们这一讲就来说明每一轮迭代都能使似然函数 $p(x|\theta)$ 的值不断增大，让你安心地使用这个迭代方法。

下面我们开始形式化的描述和证明这个问题，即：

我们对于任意轮数 $t$，通过

$$\theta^{(t+1)}=argmax_{\theta}\int_{z}log~p(x,z|\theta)~p(z|x,\theta^{(t)})dz$$

的方法实现 $\theta^{(t)}\rightarrow \theta^{(t+1)}$ 的迭代之后，一定能够使得：

$$log~p(x|\theta^{(t)})\le log~p(x|\theta^{(t+1)})$$

下面我们开始证明。

首先，我们利用贝叶斯公式得到观测变量 $x$ 和隐变量 $z$ 的概率关系式：

$$p(x|\theta)p(z|x,\theta)=p(x,z|\theta)\\\\\Rightarrow
log~p(x|\theta)+log~p(z|x,\theta)=log~(x,z|\theta)$$

因此，我们将隐变量引入到 log 似然函数当中：

$$log~p(x|\theta)=log~p(x,z|\theta)-log~p(z|x,\theta)$$

对等式两边同时求关于 $p(z|x,\theta^{(t)})$ 的期望，也就是求积分：

$$\int_{z}p(z|x,\theta^{(t)})log~p(x|\theta)dz\\\=\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta)dz-\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta)dz$$

我们对左边进行化简：

$$\int_{z}p(z|x,\theta^{(t)})log~p(x|\theta)dz\\\=log~p(x|\theta)\int_{z}p(z|x,\theta^{(t)})dz=log~p(x|\theta)
\cdot 1=log~p(x|\theta)$$

这里简单解释一下：$log~p(x|\theta)$ 与变量 $z$
无关，因此可以拿到积分号外面，同时，$\int_{z}p(z|x,\theta^{(t)})dz$ 相当于所有概率的加和，其值必然为 1。

因此最终等式变为了：

$$p(x|\theta)=\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta)dz\\\\-\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta)dz$$

那么 $p(x|\theta^{(t+1)})\ge p(x|\theta^{(t)})$，就转化成了去验证下面这个不等式了：

$$\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta^{(t+1)})dz-\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta^{(t+1)})dz
\\\\\ge
\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta^{(t)})dz-\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta^{(t)})dz$$

拆解成两部分，如果能验证下面两部分的不等式都成立，那么自然 $p(x|\theta^{(t+1)})\ge p(x|\theta^{(t)})$ 就能成立。

不等式 1：

$$\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta^{(t+1)})dz\ge
\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta^{(t)})dz$$

不等式 2：

$$\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta^{(t+1)})dz \le
\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta^{(t)})dz$$

先看不等式 1。让我们回忆一下，$\theta^{(t+1)}$ 是如何迭代出来的？

$$\theta^{(t+1)}=argmax_{\theta}\int_{z}log~p(x,z|\theta)~p(z|x,\theta^{(t)})dz$$

也就是说，依据迭代算法的定义，$\theta=\theta^{(t+1)}$ 是使得
$\int_{z}log~p(x,z|\theta)~p(z|x,\theta^{(t)})dz$ 取值达到最大的取值，换言之就是比 $\theta$
取其他值都要大，自然这个其他值里也包含了 $\theta=\theta^{(t)}$。

所以说

$$\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta^{(t+1)})dz\ge
\int_{z}p(z|x,\theta^{(t)})log~p(x,z|\theta^{(t)})dz$$

这个不等式是迭代算法本身的定义就能够保证成立。

那么不等式 2 呢？我们稍作变形：

$$\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta^{(t)})dz-\int_{z}p(z|x,\theta^{(t)})log~p(z|x,\theta^{(t+1)})dz\\\=\int_{z}p(z|x,\theta^{(t)})log\frac{p(z|x,\theta^{(t)})}{p(z|x,\theta^{(t+1)})}dz$$

后面再如何处理？我们引入一个概念叫作 KL 散度，也就是相对熵：

设 $P(x)$ 和 $Q(x)$ 是随机变量 $x$ 上的两个概率分布，则在离散和连续随机变量的情形下，相对熵的定义分别为：

$$KL(P||Q)=\sum P(x)log\frac{P(x)}{Q(x)}$$$$KL(P||Q)=\int
P(x)log\frac{P(x)}{Q(x)}dx$$

KL 散度用来衡量两个分布 $P(x)$ 和 $Q(x)$ 之间的距离，因此它具有一个非常重要的性质，那就是非负性，即：

$$KL(P||Q)\ge 0$$

当 $P$ 和 $Q$ 两个分布相同的时候，取等号。

那此时就十分清楚了：

$$\int_{z}p(z|x,\theta^{(t)})log\frac{p(z|x,\theta^{(t)})}{p(z|x,\theta^{(t+1)})}dz=KL(p(z|x,\theta^{(t)})||p(z|x,\theta^{(t+1)}))\ge
0 $$

因此，不等式 1 和不等式 2 都已得证。

那么经过 $\theta^{(t)}\rightarrow \theta^{(t+1)}$ 的迭代之后，$log~p(x|\theta^{(t)})\le
log~p(x|\theta^{(t+1)})$ 的关系就得到了证明，也就是说通过一轮一轮的迭代，log 似然函数的取值也在不断增大，最终 log
似然函数收敛到最大值，我们的待估计的参数 $\theta$ 也就不断地趋近于参数的真实值。

这个迭代法就请大家放心使用，至于说这个迭代公式是如何得到，我们下一讲再来说。

