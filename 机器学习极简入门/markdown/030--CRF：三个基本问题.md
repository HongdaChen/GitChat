### 线性链 CRF 的形式化表示

#### 一般形式

设 $P(Y|X)$ 为线性链 CRF，在随机变量 $X$ 取值为 $x$ 的条件下，随机变量 $Y$ 取值为 $y$ 的条件概率具有如下形式：

$P(y|x) =\frac{1}{Z(x)} \exp(\sum_{i,k} \lambda_k t_k (y_{i-1}, y_i, x, i) +
\sum_{i,l}\mu_l s_l (y_i, x, i))$

其中，求和是在所有可能的输出序列上进行的。$t_k$ 和 $s_l$ 是特征函数，$\lambda_k$ 和 $\mu_l$
是对应的权值——这四组参数确定了 CRF。

$t_k$ 是定义在（图模型的）边上的特征函数，称为转移特征，依赖当前和前一个位置。

$s_l$ 是定义在（图模型的）节点上的特征函数，称为状态特征，依赖于当前位置。

$t_k$ 和 $s_l$ 都是局部特征函数，因为它们都依赖于位置。通常的取值为$1$或者$0$。取值为$1$表示满足特征条件，否则为$0$。

$Z(x)$ 为规范化因子：

$Z(x) = \sum_{y} \exp(\sum_{i,k} \lambda_k t_k (y_{i-1}, y_i, x, i) +
\sum_{i,l}\mu_l s_l (y_i, x, i))$

在实际使用中，当样本既定后，$Z(x)$ 也是既定的。

在这种情况下，$Z(x)$ 就可以被看作一个常数。因此：

$P(y|x) \propto \exp(\sum_{i,k} \lambda_k t_k (y_{i-1}, y_i, x, i) +
\sum_{i,l}\mu_l s_l (y_i, x, i))$

用更清晰的表示，可写作：

$P(y|x) \propto \exp(\sum_{k=1}^{K} \lambda_k \sum_{i=1}^{n}t_k (y_{i-1}, y_i,
x, i) + \sum_{l=1}^{L}\mu_l \sum_{i=1}^{n}s_l (y_i, x, i))$

上式表达的是，线性链 CRF 一共有 $K$ 个转移特征和 $L$ 个状态特征，它的观测序列和状态序列的长度为 $n$。它在 $X=x$ 条件下，$Y=y$
的条件概率分布正比于经历如下步骤得出的内容：

  * 步骤1：将同一个特征（转移特征及状态特征）在各个位置求和，将局部特征转化为全局特征；
  * 步骤2：分别计算全局转移特征向量和全局状态特征向量与对应的权值向量的内积；
  * 步骤3：对步骤2的结果求 $exp(·)$。

#### 简化形式

如果我们将转移特征和状态特征及其权值用统一的符号表示，线性链 CRF 形式化的表示就会简单许多。

设有 $K_1$ 个转移特征和 $K_2$ 个状态特征，且 $K=K_1 + K_2$。

我们用 $f_k(·)$ 来表示转移/状态特征函数：

![](https://images.gitbook.cn/080b0e50-9b63-11e8-9a75-4558ac89d9d8)

这样一来，在所有位置对转移/状态特征求和，就变成了：

$f_k(y,x) = \sum_{i=1}^{n}f_k(y_{i-1},y_i,x,i), \;\; k=1,2,..., K$

用 $w_k$ 表示特征 $f_k(y,x)$ 的权值，即

![](https://images.gitbook.cn/4fb2b6e0-9b63-11e8-9a44-4972dd48e97e)

于是，线性链 CRF 的表示可以写作：

$P(y|x) = \frac{1}{Z(x)}\exp{\sum_{k=1}^{K}w_kf_k(y,x)}$

其中，$Z(x) = \sum_y\exp{\sum_{k=1}^{K}w_kf_k(y,x)}$。

设：

$w=(w_1, w_2, …, w_K)^T$ $F(y,x) =(f_1(y,x), f_2(y,x), …, f_K(y,x))^T$

则有：

$P_w(y|x) = \frac{\exp{(w·F(y,x))}}{Z_w(x)}$

其中，$Z_w(x) = \sum_y\exp{(w·F(y,x))}$。

> 注意：CRF 和马尔可夫随机场都是用团上的势函数来定义概率的。在表现形式上，二者非常接近。
>
> 但 CRF 处理的是条件概率，而马尔可夫随机场处理的是联合概率！

### CRF 的三个基本问题

#### 三个基本问题

类比于之前的 HMM，线性链 CRF 同样有三个基本问题。

##### **1\. 概率计算问题。**

问题名称：概率计算问题。

已知信息：给定 CRF——

  * $P(Y|X)$
  * 观测序列 $x$ 
  * 状态序列 $y$

求解目标：求条件概率 $P(Y_i = y_i|x)$, $P(Y_{i-1} = y_{i-1}, Y_i = y_i | x)$ 以及相应的数学期望。

##### **2\. 预测问题。**

问题名称：预测问题。

已知信息：给定 CRF——

  * $P(Y|X)$
  * 观测序列 $x$ 

求解目标：求条件概率最大的状态序列 $y^*$，也就是对观测序列进行标注。

##### **3\. 学习问题**

问题名称：学习问题。

已知信息：训练数据集。

求解目标：求 CRF 模型的参数。

#### 对比 HMM 的三个基本问题

如果我们根据已知条件和求解目标来对比 CRF 和 HMM 的三个基本问题，则不难发现：它们在预测问题和学习问题上很类似。

对于预测问题，无论 HMM 还是 CRF 都是在模型已经存在（各个参数都已知）的情况下，给定观测序列，求最有可能与之对应的状态序列。

学习问题则都是在模型参数未知的时候，根据训练数据（观测序列）将模型的参数学习出来。

两者 **区别较大** 的是 **概率计算问题** 。

虽然在解决概率计算问题时，两者都已经有了既定的模型，但对于 HMM
而言，概率计算只需要观测序列即可，无须确定的状态序列，而最终计算出的结果，则是当前观测序列出现的可能性。

CRF 则需要既有已知观测序列，又有已知状态序列，这才能够去计算概率。

CRF 计算的是当前观测序列条件下，$i$ 节点对应的状态为 $y_i$ 的概率，或是当前观测序列条件下 $i$ 节点及其前面一个节点 $i-1$
的状态分别为 $y_i$ 和 $y_{i-1}$ 的概率，或者是它们的数学期望。

#### 三个基本问题的解法

鉴于 CRF 模型的具体算法较 HMM 难度更大，我们在此仅作简要说明。大家如果有兴趣，可以自行进一步研修。

##### **概率计算问题**

概率计算问题本身与 HMM 差别较大，但计算方法，却是借鉴了 HMM 的前向-后向算法，引入前向-后向向量，递归地计算每一步的概率。

我们将上面的 CRF 的简易形式化表达稍微该写一下：

$P(y|x) =\frac{1}{Z(x)} \exp(\sum_{k=1}^{K}\sum_{i=1}^{n} w_k f_k (y_{i-1},
y_i, x, i))$

其中：

$Z(x) = \sum_{y} \exp(\sum_{k=1}^{K}\sum_{i=1}^{n} w_k f_k (y_{i-1}, y_i, x,
i))$

设：

$W_i(y_{i-1},y_i|x) = \sum_{k=1}^{K}w_k f_k(y_{i-1}, y_i, x, i)$

$M_i(y_{i-1},y_i|x) = \exp(W_i(y_{i-1},y_i|x)) $

令 $M_i(y_{i-1},y_i|x)$ 构成矩阵：$M_i(x) = [M_i(y_{i-1}, y_i|x)]$，$M_i(x)$ 是一个 $m$
阶的矩阵（$m$ 是状态 $y_i$ 取值的个数）。

状态序列原本有 $n$ 个节点，对应状态为 $(y_1, y_2, …, y_n)$。

这里，为了下面的计算，我们要引入一个起点，位置为 $0$，其状态为 $y_0$, 和一个终点，位置为 $n+1$，其状态是 $y_{n+1}$。

于是有：

$P(y|x) = \frac{1}{Z(x)}\prod_{i=1}^{n+1} M_i(y_{i-1}, y_i, x, i)$

其中 $Z(x)$ 是 $n+1$ 个 $m \times m$ 矩阵的相乘之后的 $m \times m$ 矩阵中的一个元素的值，这个元素的行号对应的是
$y_0$ 所对应的状态序号，列号则是 $y_{n+1}$ 所对应的状态序号：

$Z(x) = (M_1(x)M_2(x)…M_{n+1}(x))_{y_0, y_{n+1}}$

有了以上这种表达方式之后，我们用前向-后向算法来解决 CRF 的概率计算问题，就容易多了。对每一个位置（包括起点和终点）$i=0,1,2,…, n,
n+1$，定义前向向量：

![](https://images.gitbook.cn/aec67770-9b63-11e8-9c43-3956c7ef0d7c)

$\alpha_i^T(y_i|x) = \alpha_{i-1}^T(y_{i-1}|x)M_i(y_{i-1},y_i|x), \;\; i
=1,2,..., n+1$

并定义后向向量：

![](https://images.gitbook.cn/e82cae30-9b63-11e8-9a44-4972dd48e97e)

$\beta_i(y_i|x) = M_i(y_i, y_{i+1} | x)\beta_{i-1}(y_{i+1}|x)$

根据前向向量和后向向量，推算出：

$P(Y_i=y_i|x) = \frac{\alpha_i^T(y_i|x)\beta_i(y_i|x)}{Z(x)}$

$P(Y_{i-1} = y_{i-1}, Y_i=y_i|x) =
\frac{\alpha_{i-1}^T(y_{i-1}|x)M_i(y_{i-1},y_i|x)\beta_i(y_i|x)}{Z(x)}$

其中，$Z(x) = \alpha_n^T(x)\cdot \mathbf{1}$，$\mathbf{1}$ 是元素均为 $1$ 的 $m$ 维列向量。

##### **预测问题**

预测问题实际上是对观测序列进行标注。在给定的 CRF 之下，求给定观测序列最有可能对应的状态序列。

我们用 $x$ 表示观测序列，用 $y^*$ 表示最有可能的状态序列，则：

$y^* = max P(y|x) = max (\frac{1}{Z(x)}\exp{\sum_{k=1}^{K}w_kf_k(y,x)} ) $

因为 $Z(x)$ 是规范化因子，因此，实际上：

$ y^* \propto max (\exp{\sum_{k=1}^{K}w_kf_k(y,x)}) \propto max
(\sum_{k=1}^{K}w_kf_k(y,x))$

最后问题变成了：$ max (\sum_{k=1}^{K}w_kf_k(y,x))$，也就是我们要找到使输出序列权值向量和特征向量内积最大的最优路径。

针对这一问题，可以和应对 HMM 的预测问题一样，采用 **维特比算法** 。

##### **学习问题**

线性链 CRF 模型实际上是定义在序列数据上的对数线形模型，可以通过极大化训练数据的对数似然函数来求模型参数。

训练数据的对数似然函数为：

$ L(w) = \sum_{i=1}^{n}\sum_{k=1}^{K}w_k f_k(y_i, x_i) -
\sum_{i=1}^{n}\log{Z(x_i)}$

学习方法则有极大似然估计和正则化的极大似然估计。

具体的优化实现算法有：改进的迭代尺度法 IIS、梯度下降法以及拟牛顿法。目前应用较广的 BFGS 算法，属于拟牛顿法。

> **实例代码**
>
> CRF 的代码较多，就不直接贴在这里了，请参见下面链接：
>
>   * [GitHub](https://github.com/juliali/CRFExample)
>

