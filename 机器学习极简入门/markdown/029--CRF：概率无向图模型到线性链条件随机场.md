### 概率无向图

#### 定义

**概率无向图模型** （Probabilistic Undirected Graphical Model）是一个可以用无向图表示的联合概率分布。

它的整体结构是一张图（Graph），图中每一个节点表示一个或者一组变量，节点之间的边表示这两个/组变量之间的依赖关系。

概率无向图模型还有一个名字—— **马尔可夫随机场** 。

下图就是一个简单的马尔可夫随机场：

![enter image description
here](https://images.gitbook.cn/04e8bb20-8eeb-11e8-b4db-8317426c96d5)

#### 势函数和团

关于马尔可夫随机场，有几个非常重要的概念。

**势函数** （Potential Function，又称为因子 Factor）：是定义在变量子集上的非负实函数，用于定义概率分布函数。

**团** （Clique）：图中节点的子集，其中任意两个节点之间都有边连接。

**极大团** ：一个团，其中加入任何一个其他的节点都不能再形成团。

马尔可夫随机场中， **多个变量之间的联合概率分布可以基于团分解为多个势函数的乘积，每个势函数仅与一个团相关** 。

#### Hammersley-Clifford 定理

对于 $N$ 个变量的马尔可夫随机场，其变量为 $X=(X_1,X_2, …X_N) $（上图例子中 $N=6$）。

设所有团构成的集合为 $C$，与团 $Q \in C$ 对应的变量集合记作 $X_Q$，则联合概率为：

$P(X) = \frac{1}{Z}\prod_{Q \in C} \Psi_Q(X_Q)$

其中 $\Psi_Q$ 为与团 $Q$ 对应的势函数，用于对团 $Q$ 中的变量关系进行建模。

$Z$ 为规范化因子，很多时候要计算它很困难，不过好在大多数情况下，我们无须计算出 $Z$ 的精确值。

当团 $Q$ 不是极大团的时候，它必然属于某个极大团——实际上每一个非极大团都是如此，此时我们完全可以只用极大团来计算 $P(X)$：$P(X) =
\frac{1}{Z^*} \prod_{Q \in C^*} \Psi_Q(X_Q)$，其中 $C^*$ 为所有极大团的集合。

这叫做 Hammersley-Clifford 定理，是随机场（Random Fields）的基础定理，它给出了一个马尔可夫随机场被表达为
**正概率分布** 的 **充分必要条件** 。

#### 性质

在讨论马尔可夫随机场的性质之前，我们要学习两个概念。

##### **两个概念**

(1)分离（Separating）

设 $A、B、C$ 都是马尔可夫随机场中的节点集合，若从 $A$ 中的节点到 $B$ 中的节点都必须经过 $C$ 中的节点，则称 $A$ 和 $B$ 被
$C$ 分离，$C$ 称为 **分离集** （Separating Set）。参加下图：

![enter image description
here](https://images.gitbook.cn/54ae2fb0-80f3-11e8-a935-d59fe50595b6)

(2)马尔可夫性（Markov Property）

马尔可夫性的 **原始定义**
为：当一个随机过程在给定当前状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态；换句话说，在给定当前状态时，它与过去状态（即该过程的历史路径）是条件独立的，那么此随机过程即具有
**马尔可夫性** 。

我们把马尔可夫性引入到马尔可夫随机场中，把当前状态看作无向图中的一个节点，过去状态看作与当前状态节点有历史路径（边）连接的其他节点。

可以这样理解：在马尔可夫随机场的无向图中，任何一个节点的概率分布都仅和与它相连的节点有关。

形式化的表达为：设 $v$ 为无向图中任意一个节点，$W$ 是所有与 $v$ 相连的节点的集合，则 $v$ 的概率分布仅和 $W$ 有关，和 $v$ 与
$W$ 之外的其他节点无关 。

参看下图，给定灰色节点，则黑色节点独立于其他所有节点：

![enter image description
here](https://images.gitbook.cn/c38936a0-8f08-11e8-90c0-476a2623d2fb)

##### **马尔可夫随机场的马尔可夫性**

马尔可夫随机场具备 **全局马尔可夫性** （Global Markov Property）：给定两个变量子集的分离集，则这两个变量子集条件独立。

令 $A、B$ 和 $C$ 对应的变量集合分别为 $X_A、X_B、X_C$，则 $X_A$ 和 $X_B$ 在给定 $X_C$
的条件下独立，记作：$X_A \perp X_B | X_C$。

即：$P(X_A, X_B|X_C) = P(X_A|X_C)P(X_B|X_C)$

由全局马尔可夫性，又可以推导出两种性质：

  * **局部马尔可夫性** （Local Markov Property）：给定某变量的邻接变量，则该变量条件独立于其他变量。

用公式描述是：$P(X_v, X_O | X_W) = P(X_v|X_W)P(X_O|X_W)$，其中 $v$ 为无向图中任意节点，$W$ 是与 $v$
有边连接的所有节点的集合，$O$ 是 $v$ 和 $W$ 之外的所有其他节点。

  * **成对马尔可夫性** （Pairwise Markov Property）：给定所有其他变量，两个非连接变量条件独立。

公式描述为：$P(X_u, X_v | X_O) = P(X_u|X_O)P(X_v|X_O)$， 其中 $u$ 和 $v$
为无向图中任意两个没有边连接的点，$O$ 为其他所有点的集合。

### 条件随机场（Conditional Random Field，CRF）

#### 无向图模型

CRF 也是一种无向图模型。

它 **和马尔可夫随机场的不同点在于：马尔可夫随机场是生成式模型** ，直接对联合分布进行建模；而 **条件随机场是判别式模型** ，对条件分布进行建模。

但两者又是相关的，CRF 是“有条件的”马尔可夫随机场。也就是说，CRF 是 **给定随机变量 $X$ 条件下，随机变量 $Y$ 的马尔可夫随机场** 。

#### 定义

这里我们给出 CRF 的 **定义** ：设 $X$ 和 $Y$ 是随机变量，$P(Y|X)$ 是给定 $X$ 条件下 $Y$ 的条件概率分布。如果随机变量
$Y$ 构成一个由无向图 $G=<V, E>$ 表示的马尔可夫随机场，则称条件概率分布 $P(Y|X)$ 为 CRF。

换言之，设 $X$ 和 $Y$ 是随机变量，$P(Y|X)$ 是给定 $X$ 条件下 $Y$ 的条件概率分布。如果随机变量 $Y$ 构成一个无向图
$G=<V，E>$，且图 $G$ 中每一个变量 $Y_v$ 都满足马尔可夫性——$P(Y_v|X, Y_Z) = P(Y_v|X, Y_W) $，其中
$Z$ 表示无向图中节点 $v$ 以外所有点的集合，$W$ 表示无向图中与节点 $v$ 有边连接的所有节点集合——则 $P(Y|X)$ 为 CRF。

在 $P(Y|X)$ 中，$X$ 是输入变量，表示需要标注的观测序列；$Y$ 是输出变量，表示状态（或称标记）序列。

从定义层面，没有要求 $X$ 和 $Y$ 具有相同结构，不过在实际运行中，一般假设 $X$ 和 $Y$ 具备相同图结构。

### 线性链 CRF

在现实应用中，最常被用到的 CRF 是线性链（Linear Chain）CRF，其结构如下：

![enter image description
here](https://images.gitbook.cn/67a4c520-80f3-11e8-876c-25ed94be3d09)

当 $X$ 和 $Y$ 具备相同结构时，其形如下：

![](https://images.gitbook.cn/7b5eaa90-80f3-11e8-a935-d59fe50595b6)

上图中，$X$ 为观测序列，$Y$ 为状态序列。

设 $X=(X_1,X_2, …, X_n)$，$Y = (Y_1, Y_2, …, Y_n)$，它们都是线性链表示的随机变量序列。

如果在给定随机变量序列 $X$ 的条件下，随机变量序列 $Y$ 的条件概率分布 $P(Y|X)$ 构成 CRF，也就是说它满足马尔可夫性：

$P(Y_i|X, Y_1, …, Y_{i-1}, Y_{i+1}, …, Y_n) = P(Y_i|X, Y_{i-1}, Y_{i+1})$

其中 $i=1,2,…, n$ （当 $i=1$ 和 $n$ 时只考虑单边），则称 $P(Y|X)$ 为线性链条件随机场。$X$
为输入序列/观测序列，$Y$ 为输出序列/标记序列/状态序列。

### HMM VS 线性链 CRF

看到此处是不是很眼熟，是不是又想到了 HMM？

确实，HMM 和 CRF 看起来蛮像的。

![enter image description
here](https://images.gitbook.cn/8bff1b00-80f3-11e8-9614-476580d74a06)

但是要注意：

  1. HMM 是有向图，CRF 是无向图；
  2. HMM 计算的是状态和观测的联合概率，而 CRF 计算的是状态基于观测的条件概率。

从使用的角度，HMM 多用于那种状态“原生”，而观测是状态“生成”出来的场景。

比如，用 HMM 来生成一段语音，则状态对应的是音节（声韵母）或文字，而观测则是这个音节所对应的声学特征。

这时，状态是相对客观的，观测是状态的一种“表征”，是状态“产生”出来的——我们想象一下自己说话时的场景，也是头脑中先想好说什么话，有了语言文字音节，然后再由大脑指挥喉舌发声。发出来的声音，就是最终的观测。

CRF 则多用于那种观测“原生”。状态“后天”产生，用来标记观测的情况。

比如，用 CRF 来做文本实体标记。输入一句话“我有一个苹果”，CRF
处理后将“苹果”标记成了“水果”。这个时候，“苹果”是观测，而“水果”则是对应的状态（或称标签）。

同一个观测值“苹果”，它的标签可以是“水果”，也可以是“手机”，具体是什么与训练数据有关，也与之前状态值有关。

但无论怎么样，观测才是客观存在的。而状态（标签）是人为“打”上去的，是以观测为条件进行“判别”的结果。

