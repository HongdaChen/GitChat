### ETL 基本概念

ETL 是将数据从来源端经过抽取（extract）、交互转换（transform）、加载（load）至目的端的过程。

ETL 过程是构建数据仓库的重要一环，用户从数据源抽取出所需的数据，经过数据清洗，最终按照预先定义好的数据仓库模型，将数据加载到数据仓库中去。ETL
规则的设计和实施约占整个数据仓库搭建工作量的 60%~80%。

![](https://images.gitbook.cn/6b556680-ef81-11ea-b27a-6f83744fa302)

### 数据抽取（Extraction）

#### **对不同数据源的抽取**

抽取的数据，根据类型的不同，可以分为结构化数据、非结构化数据、半结构化数据。

结构化数据的抽取可以采用 JDBC 连接到数据库直接进行抽取，这也是最常用的一种方法，但这种方式因为是对数据库进行直连，所以会消耗数据库的
IO，影响正常的业务进行，所以抽取时间会选择在凌晨业务量较少的时间；而且有一些企业不允许对数据库进行直接抽取，首先是出于安全的考虑，防止数据库异常、影响业务运行；其次对数据库进行直抽会因为
IO 的问题，导致抽取速度非常慢，无法在规定时间内完成数据导出。

除了使用 JDBC 进行数据抽取外，还可以抽取数据库日志的方式进行抽取，这种方式不会直连数据库，而是直接采集数据库的
WAL（预写日志文件）。数据库为了保证数据的安全性，所有对数据库的操作，都会顺序追加到 WAL 日志文件中，然后再对数据库执行操作。所以对 WAL
日志的采集对数据库的影响是极小的，但采集到的 WAL 日志需要经过解析后才能获取到数据，一般整个过程会使用工具来完成。

而对于非结构化、半结构化数据的抽取就比较简单了，只需要监控这些数据是否发生了变动，然后将变动后的数据进行抽取就行。

#### **数据抽取方式**

数据抽取方式有全量同步、增量同步两种。

![](https://images.gitbook.cn/7ef2c340-ef81-11ea-9bd3-c1ce0cf88d43)

全量同步会将全部数据进行抽取，一般用于初始化数据装载。增量同步方式会检测数据的变动，抽取发生变动的数据，一般用于数据更新。

一般企业在第一次数据抽取时，采用全量同步，之后每天使用增量同步方式即可。但企业在数据量较小的时候，也会使用每天全量同步的方法同步数据。

### 数据转换（Transformation）

对抽取来的数据，一般要经过数据转换的阶段，然后才可以被运送到数据仓库中。这个过程主要包含数据清洗、转换两个阶段。

数据清洗主要是对出现的重复、二义性、不完整、违反业务或逻辑规则等问题的数据进行统一的处理。

数据转换主要是对数据进行标准化处理，进行字段、数据类型、数据定义的转换。

对于结构化数据而言，在转换过程中的逻辑较为简单，因为结构化数据本身存储在数据库中，数据比较干净。而对于非|半结构化数据，转换的过程会较为复杂，因为这些数据本身就比较混乱，需要花费大量的工作在转换上。

### 数据加载（Loading）

数据加载将处理完的数据，导入到对应的目标源中。完成数据的整个 ETL 阶段。此时数据就已经存储到数据仓库的 ODS 层中了。

### 常见 ETL 产品

#### **结构化数据 ETL 工具**

![](https://images.gitbook.cn/91ebc9b0-ef81-11ea-a374-77fb7954ed83)

最常见的对结构化数据抽取的开源免费的 ETL 工具有 Sqoop、Kettle，其中 Sqoop
主要面向由传统数据库的数据抽取到大数据集群的场景，使用命令行操作；而 Kettle 是可视化窗口操作，主要面向传统数据库、数据仓库。

当然也有商业版如 Datastage、Informatica。

![](https://images.gitbook.cn/a33439f0-ef81-11ea-b27a-6f83744fa302)

而且对于像 Kafka 这样的消息中间件，也提供了对数据抽取的功能。

#### **非/半结构化数据 ETL 工具**

![](https://images.gitbook.cn/be652220-ef81-11ea-bc58-d7943dd51ce7)

![](https://images.gitbook.cn/cb4bbee0-ef81-11ea-9212-f1aa28746d87)

对于非/半结构化数据的 ETL 开源工具，Flume、Logstash
是比较主流的。而且它俩也提供对结构化数据的抽取，但非/半结构化数据场景是它们被使用最多的功能。

### 小结

这节主要介绍了 ETL 的整体流程、常见 ETL 工具；在企业数仓设计中，这个阶段花费的时间最长，因为涉及到 ETL
工具选型、架构的搭建、数据的导入、数据稽查等。而且如果企业拥有海量数据，整个过程就更花费时间，可能需要几个月、或者半年的时间进行迁移。

