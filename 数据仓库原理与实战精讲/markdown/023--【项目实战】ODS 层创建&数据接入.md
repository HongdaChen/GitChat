### 操作说明

此时已经将数据从 MySQL 中导入到 HDFS 中了，接下来就需要将数据导入到数据仓库的 ODS 层中，完成原始数据的存储。

这个部分分为两个阶段，首先在 Hive 中创建 ODS 层的所有表结构，表结构与源系统（MySQL）一致。之后，使用脚本将 HDFS 中存储的数据导入到
Hive 数据仓库的 ODS 层中。

### ODS 层创建

1\. 进入 Hive 安装节点（Node03），启动 Hive 元数据服务：

    
    
    hive --service hiveserver2 &
    hive --service metastore &
    

2\. 在 Node03 节点，/home/warehouse/sql 目录下编写 ods_ddl.sql，创建与业务数据库一致的数据表：

    
    
    mkdir /home/warehouse/sql/
    vim /home/warehouse/sql/ods_ddl.sql
    

文件内容如下：

    
    
    -- 创建数据库
    create database if not exists mall;
    use mall;
    
    -- 创建订单表
    drop table if exists ods_order_info;
    create table ods_order_info ( 
        `id` string COMMENT '订单编号',
        `total_amount` decimal(10,2) COMMENT '订单金额', 
        `order_status` string COMMENT '订单状态', 
        `user_id` string COMMENT '用户 id' ,
        `payment_way` string COMMENT '支付方式',  
        `out_trade_no` string COMMENT '支付流水号',  
        `create_time` string COMMENT '创建时间',  
        `operate_time` string COMMENT '操作时间' 
    ) COMMENT '订单表'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_order_info/'
    tblproperties ("parquet.compression"="snappy")
    ;
    
    -- 创建订单详情表
    drop table if exists ods_order_detail;
    create table ods_order_detail( 
        `id` string COMMENT '订单编号',
        `order_id` string  COMMENT '订单号', 
        `user_id` string COMMENT '用户 id' ,
        `sku_id` string COMMENT '商品 id',  
        `sku_name` string COMMENT '商品名称',  
        `order_price` string COMMENT '下单价格',  
        `sku_num` string COMMENT '商品数量',  
        `create_time` string COMMENT '创建时间'
    ) COMMENT '订单明细表'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_order_detail/'
    tblproperties ("parquet.compression"="snappy")
    ;
    
    -- 创建商品表
    drop table if exists ods_sku_info;
    create table ods_sku_info( 
        `id` string COMMENT 'skuId',
        `spu_id` string   COMMENT 'spuid', 
        `price` decimal(10,2) COMMENT '价格' ,
        `sku_name` string COMMENT '商品名称',  
        `sku_desc` string COMMENT '商品描述',  
        `weight` string COMMENT '重量',  
        `tm_id` string COMMENT '品牌 id',  
        `category3_id` string COMMENT '品类 id',  
        `create_time` string COMMENT '创建时间'
    ) COMMENT '商品表'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_sku_info/'
    tblproperties ("parquet.compression"="snappy")
    ;
    
    -- 创建用户表
    drop table if exists ods_user_info;
    create table ods_user_info( 
        `id` string COMMENT '用户 id',
        `name`  string COMMENT '姓名', 
        `birthday` string COMMENT '生日' ,
        `gender` string COMMENT '性别',  
        `email` string COMMENT '邮箱',  
        `user_level` string COMMENT '用户等级',  
        `create_time` string COMMENT '创建时间'
    ) COMMENT '用户信息'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_user_info/'
    tblproperties ("parquet.compression"="snappy")
    ;
    
    -- 创建商品一级分类表
    drop table if exists ods_base_category1;
    create table ods_base_category1( 
        `id` string COMMENT 'id',
        `name`  string COMMENT '名称'
    ) COMMENT '商品一级分类'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_base_category1/'
    tblproperties ("parquet.compression"="snappy")
    ;
    
    -- 创建商品二级分类表
    drop table if exists ods_base_category2;
    create external table ods_base_category2( 
        `id` string COMMENT ' id',
        `name`  string COMMENT '名称',
        category1_id string COMMENT '一级品类 id'
    ) COMMENT '商品二级分类'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_base_category2/'
    tblproperties ("parquet.compression"="snappy")
    ;
    
    -- 创建商品三级分类表
    drop table if exists ods_base_category3;
    create table ods_base_category3( 
        `id` string COMMENT ' id',
        `name`  string COMMENT '名称',
        category2_id string COMMENT '二级品类 id'
    ) COMMENT '商品三级分类'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_base_category3/'
    tblproperties ("parquet.compression"="snappy")
    ;
    
    -- 创建支付流水表
    drop table if exists `ods_payment_info`;
    create table  `ods_payment_info`(
        `id`   bigint COMMENT '编号',
        `out_trade_no`    string COMMENT '对外业务编号',
        `order_id`        string COMMENT '订单编号',
        `user_id`         string COMMENT '用户编号',
        `alipay_trade_no` string COMMENT '支付宝交易流水编号',
        `total_amount`    decimal(16,2) COMMENT '支付金额',
        `subject`         string COMMENT '交易内容',
        `payment_type` string COMMENT '支付类型',
        `payment_time`   string COMMENT '支付时间'
       )  COMMENT '支付流水表'
    PARTITIONED BY ( `dt` string)
    row format delimited  fields terminated by '\t' 
    location '/warehouse/mall/ods/ods_payment_info/'
    tblproperties ("parquet.compression"="snappy")
    ;
    

3\. 将 ods_ddl.sql 导入到 Hive 中，创建 ODS 层：

    
    
    hive -f /home/warehouse/sql/ods_ddl.sql
    

![](https://gitee.com/QiaoLuManMan/ImageUpload/raw/master/img/20200824070851.png)

### 数据导入

1\. 在 Node03 节点中，/home/warehouse/shell/目录下编写 ods_db.sh 脚本，完成数据导入操作：

    
    
    vim /home/warehouse/shell/ods_db.sh
    

脚本内容如下：

    
    
    #!/bin/bash
    
       do_date=$1
       APP=mall
       hive=hive
    
    sql=" 
    load data inpath '/origin_data/$APP/db/order_info/$do_date'  OVERWRITE into table $APP"".ods_order_info partition(dt='$do_date');
    
    load data inpath '/origin_data/$APP/db/order_detail/$do_date'  OVERWRITE into table $APP"".ods_order_detail partition(dt='$do_date');
    
    load data inpath '/origin_data/$APP/db/sku_info/$do_date'  OVERWRITE into table $APP"".ods_sku_info partition(dt='$do_date');
    
    load data inpath '/origin_data/$APP/db/user_info/$do_date' OVERWRITE into table $APP"".ods_user_info partition(dt='$do_date');
    
    load data inpath '/origin_data/$APP/db/payment_info/$do_date' OVERWRITE into table $APP"".ods_payment_info partition(dt='$do_date');
    
    load data inpath '/origin_data/$APP/db/base_category1/$do_date' OVERWRITE into table $APP"".ods_base_category1 partition(dt='$do_date');
    
    load data inpath '/origin_data/$APP/db/base_category2/$do_date' OVERWRITE into table $APP"".ods_base_category2 partition(dt='$do_date');
    
    load data inpath '/origin_data/$APP/db/base_category3/$do_date' OVERWRITE into table $APP"".ods_base_category3 partition(dt='$do_date'); 
    "
    $hive -e "$sql"
    

2\. 为脚本赋权限，并执行：

    
    
    chmod +x /home/warehouse/shell/ods_db.sh
    cd /home/warehouse/shell/
    ./ods_db.sh 2020-06-10
    

![](https://gitee.com/QiaoLuManMan/ImageUpload/raw/master/img/20200824074109.png)

3\. 在 Node03 节点，进入 Hive，查看数据是否导入成功：

    
    
    hive
    use mall;
    show tables;
    select count(1) from ods_user_info;
    

![](https://images.gitbook.cn/1e58f120-f040-11ea-813e-7720407984bb)

![](https://images.gitbook.cn/2e727e50-f040-11ea-affc-a54214209ff7)

