### 虚拟机准备

#### **安装说明 & 文件下载**

下载并安装 [Virtual Box](https://www.virtualbox.org/wiki/Downloads)，准备并安装 3 台
CentOS 7.2 的虚拟机，主机名命名为 Node01、Node02、Node03。

虚拟机的安装可以使用纯系统镜像，安装后配置主机名。但过程会比较繁琐，学习环境讲求开箱即用，尽量少地在环境上花费时间，否则会打击学习的热情。所以，也可以直接导入已经配置好的虚拟机镜像文件，方便使用。

使用纯镜像安装，下附 CentOS 镜像下载地址：

  * 链接：<https://pan.baidu.com/s/1CV0C7bZ0-7tKziNf6RmdVg>
  * 提取码：h931

推荐直接导入虚拟机镜像文件，下附虚拟机镜像下载地址：

  * 链接：<https://pan.baidu.com/s/1T1VhTv6EwGAr2odlAUPBtA>
  * 提取码：pljf

#### **虚拟机镜像文件导入流程**

1\. 下载虚拟机镜像文件：

![](https://images.gitbook.cn/b5cc4db0-f01b-11ea-bc58-d7943dd51ce7)

2\. 打开 Virtual Box，选择导入虚拟电脑：

![](https://images.gitbook.cn/c64ab730-f01b-11ea-813e-7720407984bb)

3\. 选择文件位置，进行导入：

![](https://images.gitbook.cn/d6bc0150-f01b-11ea-b91c-6d7fbdb6f8f7)

![](https://images.gitbook.cn/e445bbe0-f01b-11ea-b2cc-b183c5e37897)

4\. 配置虚拟机，自定义将虚拟机文件存放到指定目录，然后点击确定，完成导入：

![image-20200819094401086](https://images.gitbook.cn/8c1040b0-f040-11ea-889f-9de3f88b5342)

5\. 依次导入 Node01、Node02、Node03：

![](https://images.gitbook.cn/4980cdb0-f01c-11ea-813e-7720407984bb)

6\. 开启虚拟机，使用 root/123456 进行登录：

![image-20200819095050483](https://images.gitbook.cn/a8335110-f040-11ea-b27a-6f83744fa302)

![](https://images.gitbook.cn/5c538770-f01c-11ea-b2cc-b183c5e37897)

7\. 修改虚拟机 IP 地址：

![](https://images.gitbook.cn/696d1b10-f01c-11ea-a374-77fb7954ed83)

    
    
    vim /etc/sysconfig/network-scripts/ifcfg-enp0s3
    

![](https://images.gitbook.cn/7742abb0-f01c-11ea-8755-9ff4c3d0bc34)

8\. 使用 XShell，或者其它远程 SSH Linux 登录工具进行远程连接虚拟机：

![](https://images.gitbook.cn/88db37c0-f01c-11ea-b2cc-b183c5e37897)

![](https://images.gitbook.cn/96349380-f01c-11ea-bc58-d7943dd51ce7)

### 自动化安装脚本准备

1\. 下载并上传自动化安装脚本
[automaticDeploy.zip](https://github.com/MTlpc/automaticDeploy/archive/master.zip)
到虚拟机 Node01 中。

    
    
    wget https://github.com/MTlpc/automaticDeploy/archive/master.zip
    

2\. 解压 automaticDeploy.zip 到 /home/hadoop/ 目录下：

    
    
    mkdir /home/hadoop/
    unzip master.zip -d /home/hadoop/
    mv /home/hadoop/automaticDeploy-master /home/hadoop/automaticDeploy
    

3\. 更改自动化安装脚本的 frames.txt 文件，配置组件的安装节点信息（如无特殊要求，默认即可）。

![](https://images.gitbook.cn/e1f63120-f01c-11ea-bc58-d7943dd51ce7)

4\. 编辑自动化安装脚本的 configs.txt 文件，配置 MySQL、Keystore 密码信息（如无特殊要求，默认即可，末尾加 END
表示结束）。

![](https://images.gitbook.cn/f3c92e20-f01c-11ea-8755-9ff4c3d0bc34)

5\. 编辑 host_ip.txt 文件，将 3 台虚拟机节点信息添加进去（需自定义进行修改）：

![](https://images.gitbook.cn/0366d490-f01d-11ea-813e-7720407984bb)

6\. 对 /home/hadoop/automaticDeploy/ 下的 hadoop、systems 所有脚本添加执行权限：

    
    
    chmod +x /home/hadoop/automaticDeploy/hadoop/* /home/hadoop/automaticDeploy/systems/*
    

### 大数据环境一键安装

1\. 下载 frames.zip 包，里面包含大数据组件的安装包，并上传到 Node01 中：

  * 链接：<https://pan.baidu.com/s/17T3zIbedTaQgk1knxvchPA>
  * 提取码：cvtq

![](https://images.gitbook.cn/2134fce0-f01d-11ea-bc58-d7943dd51ce7)

2\. 将 frames.zip 压缩包，解压到/home/hadoop/automaticDeploy 目录下：

    
    
    unzip frames.zip -d /home/hadoop/automaticDeploy/
    

3\. 将自动化脚本分发到其它两个节点：

    
    
    # 需提前在另外两个节点创建 /home/hadoop 目录(此时还未配置 hosts，需将 node02\node03 替换为对应 IP)
    ssh root@node02 "mkdir /home/hadoop"
    ssh root@node03 "mkdir /home/hadoop"
    scp -r /home/hadoop/automaticDeploy root@node02:/home/hadoop/
    scp -r /home/hadoop/automaticDeploy root@node03:/home/hadoop/
    

![](https://images.gitbook.cn/34fb8c80-f01d-11ea-80b6-61caae27bd5a)

![](https://images.gitbook.cn/41544120-f01d-11ea-b2cc-b183c5e37897)

4\. 依次在各个节点执行 systems/batchOperate.sh 脚本，完成环境初始化。

    
    
    /home/hadoop/automaticDeploy/systems/batchOperate.sh
    

为了避免脚本中与各个节点的 SSH 因为环境问题，执行失败，需要手动测试下与其它节点的 SSH 情况，如果失败，则手动添加。

![](https://images.gitbook.cn/5cca48a0-f01d-11ea-9bd3-c1ce0cf88d43)

失败后重新添加 SSH：

    
    
    ssh-copy-id node02
    

![](https://images.gitbook.cn/6d6ded60-f01d-11ea-affc-a54214209ff7)

5\. 在各个节点执行脚本，安装 Hadoop 集群：

    
    
    /home/hadoop/automaticDeploy/hadoop/installHadoop.sh
    source /etc/profile
    # 在 Node01 节点执行，初始化 NameNode
    hadoop namenode -format
    # 在 Node01 节点执行，启动 Hadoop 集群
    start-all.sh
    

6\. 使用本地浏览器访问 node01:50070，成功则搭建成功。

![](https://images.gitbook.cn/8855e5b0-f01d-11ea-b91c-6d7fbdb6f8f7)

7\. 安装其它组件，在所有节点运行以下命令，未规划安装节点会自动跳过安装。

    
    
    /home/hadoop/automaticDeploy/hadoop/installMysql.sh
    /home/hadoop/automaticDeploy/hadoop/installHive.sh
    /home/hadoop/automaticDeploy/hadoop/installSqoop.sh
    /home/hadoop/automaticDeploy/hadoop/installPresto.sh
    /home/hadoop/automaticDeploy/hadoop/installAzkaban.sh
    /home/hadoop/automaticDeploy/hadoop/installYanagishima.sh
    

8\. 在所有虚拟机节点 source 环境变量文件：

    
    
    source /etc/profile
    

