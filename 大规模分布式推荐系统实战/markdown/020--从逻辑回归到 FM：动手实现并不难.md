地鼠商城的排序系统经历了从简入繁的过程，与召回模型不同，排序模型通常更为复杂，参数也更多。商城的排序模型迭代了很多个版本，从早期的线性模型到现在的深度模型，这期间踩了无数的坑，也挖了无数的坑。深度学习的”炼丹性“很容易让算法工程师忽略一些理论基础，封装的越来越好的框架让算法工程师的“编码”工作量大大降低，这究竟是好事还是坏事呢？在深入到深度模型之前，我们还是来温习一遍久远的可能早已遗忘的理论知识，接着再回顾如何手写一个机器学习模型，这并不是那么让人畏惧。

### 数据和模型

数据，就是算法工程师收集到的数据，比如用户的点击/加车/收藏/下单数据等等，因为这些数据一般都是在一段时间内采集到的，可以理解为是从总体 $X$
中抽样出的有限样本，以 $\bold x$ 来表示，它是已知的。

任何模型都有参数，比如线性模型 $y = \omega x + b$ 中的 $\omega$ 和 $b$，我们将这些参数统称为
$\theta$，它是未知的，正是我们想要通过训练“学到”的，一旦 $\theta$
学习到了，模型就生成了（模型和参数根据上下文可能会被交替使用，但是两者本质上是一个概念）。

那么如何能通过已知的 **数据** 来“学到”未知的 **参数** 呢？首先来看看 **最大似然估计** 和 **最大后验概率估计** 。

#### **最大似然估计**

最大似然估计的前提条件是“分布已知，参数未知”。也就是假定数据服从某种分布，但是该分布的参数是未知的，比如如果已知数据服从伯努利分布，但是 $p$
未知。又或者已知数据服从高斯分布，但是 $\mu$ 和 $\sigma$ 未知。我们要做的就是把这些未知的参数估算出来。

假定总体 $X$ 服从的分布为 $P\\{X=x\\} = p(x;\theta), \theta \in \Theta$，其中 $\theta$
就是待估计的参数，$\Theta$ 是 $\theta$ 可能的取值范围，设 $x_1$，$x_2$，...，$x_n$ 是来自 $X$
的样本值，则总体参数为 $\theta$ 时，事件 $\\{X_1=x_1，X_2=x_2，...，X_N=x_n\\}$
发生的概率为（这里假设样本独立同分布）：

$$p(x|\theta) = \prod_{i=1}^{n}p(x_i|\theta), \theta \in \Theta \tag{1}$$

概率 $p(x|\theta)$ 是 $\theta$ 的函数，$\theta$ 取值不同，得到的 $p(x|\theta)$ 也不同，注意到式中的 $x$
是已知的样本值，均可认为是常数。

关于最大似然估计（Maximum Likelihood Estimation, MLE），我们最直观的想法是：对于给定的样本数据
$x_1$，$x_2$，...，$x_n$，希望有这么一个 $\hat{\theta}$ 使得 $p(X|\theta)$
取值最大，因为我们认为之所以能得到这些样本数据，是因为它们出现的概率比较大，我们当然不会选择使 $ p(x|\theta)$ 取值很小的
$\theta$。也即，取 $\hat{\theta}$ 使得

$$\hat{\theta} = \arg\max\limits_{\theta}p(x|\theta)=>p(x|\hat{\theta}) =
\max\limits_{\theta \in \Theta}p(x|\theta) \tag{2}$$

使用 $\hat{\theta}$ 作为总体参数 $\theta$ 的估计，称为最大似然估计。

#### **最大后验概率估计**

根据上文的描述，最大似然估计完全根据当前的样本数据来对总体参数进行估计，而没有考虑任何先验信息。举个例子，假设抛了 10 次硬币，正面出现 3
次，那么根据最大似然估计可以算出正面出现的概率 $p$ 为 0.3，但是从经验上来说 $p$ 为 0.5
的概率是最大的。当既要考虑先验信息，又要考虑最大似然时，总体参数 $\theta$ 又该如何估计呢？这就是最大后验概率估计（Maximum A
Posteriori estimation, MAP）需要解决的问题。

MAP 的思想是找到一个参数 $\hat{\theta}$ 使得

$$\begin {aligned}\hat{\theta} &= \arg \max \limits_{\theta \in \Theta}
p(\theta|x) \\\&= \arg \max \limits_{\theta \in \Theta}
\frac{p(x|\theta)p(\theta)}{p(x)} \\\&= \arg \max \limits_{\theta \in \Theta}
p(x|\theta)p(\theta) \ \ \ \ \end{aligned} \tag{3}$$

因为 x 已知的样本，所以 p(x)是定值，不影响求最大值。

上式中的第一项是 **最大似然估计** ，第二项是 **参数的先验分布** 信息。

可见根据 MAP 估计得到的 $\hat{\theta}$ 不仅使得最大似然估计要大，先验概率也要大。根据 $log$ 函数单调递增的特性，上式等价于

$$\begin {aligned}\hat{\theta} &= \arg \max \limits_{\theta \in \Theta}
p(x|\theta)p(\theta) \\\&= \arg \max \limits_{\theta \in \Theta}
log(p(x|\theta)p(\theta)) \\\&= \arg \max \limits_{\theta \in \Theta}
log\prod_{i=1}^{n}p(x_i|\theta) + log(p(\theta)) \\\&=\arg \max
\limits_{\theta \in \Theta} \sum\limits_{i=1}^{n}log(p(x_i|\theta)) +
log(p(\theta))\end{aligned} \tag{4}$$

这个公式很重要，一定要掌握，它对于我们理解 **损失函数** 和 **正则项** 是大有裨益的。

### 模型训练流程

> 本文只针对有 Label 的监督学习且只考虑基于梯度更新的模型。
>
> 关于梯度更新理论，不熟悉的同学可以自行谷歌，一定要掌握它。本文就不再赘述了。

基本上所有基于梯度更新的模型的训练流程如下图所示：

![](https://images.gitbook.cn/7ce5d670-58e3-11eb-8ca0-ad2e0df56a32)

  1. 程序读入预先处理好的训练数据，作为输入；
  2. 根据输入中的特征，获取对应的参数；
  3. 输入与参数根据不同的模型进行不同的数学运算，无论如何最终都会得到 **预测值** ；
  4. 利用真实值和预测值，根据具体的损失函数，得到损失值；
  5. 得到损失后，即可对参数进行求导，得到导数后，根据具体的优化器（Optimizer）对参数进行更新；
  6. 进入第 1 步，开始下一轮训练。

从上图可知，想让模型具有“学习”的能力：

  1. 需要预测函数，这样才能根据输入和参数得到预测值
  2. 需要损失函数，这样才能根据损失来对参数求导从而实现参数的更新，达到“学习”的目的

下面我们以逻辑回归为例，不依赖任何第三方库，自己动手写一个模型训练代码。

#### **逻辑回归**

逻辑回归是一个二分类模型，其 label 只有 0 和 1 两种，这种二分类任务在推荐系统中是最常见的任务，比如点击率预估，转化率预估等等。

逻辑回归的 **预测函数** 为

$$\hat{y} = \frac{1}{1+e^{-(w_0 + \sum \limits_{i=1}^{n}w_ix_i) }} \tag{5}$$

其中，$w_i,i \in [1,2...,n]$ 是模型的参数，$w_0$ 是模型 bias 对应的参数，$x_i$ 是具体的输入数据，$\hat{y}$
是模型的预测输出，如果是点击率预估任务的话，$\hat{y}$ 可以理解为本次输入 $\bold x$ 对应的预测点击概率。

逻辑回归的 **损失函数** 为：

$$LL(w) = -y \ log(\hat{y}) - (1-y) \ log(1-\hat{y}) \tag{6}$$

可以看出它是关于 $w$ 的函数，$y$ 是真实值，$\hat{y}$ 是预测值。

但是一般情况下，我们都会对损失函数稍加修改，加入 **L1 或/和 L2 正则项** ，$(6)$ 式改为：

$$L(w) = LL(w) + \lambda_1\sum|w| + \frac{1}{2}\lambda_2\sum w^2 \tag{7}$$

利用式 $(5)(7)$，可以计算出 $L$ 对 $w$ 的导数为

$$g = \frac{dL}{dw} = (\hat{y} - y) \ x + \lambda_1 \ sign(w) + \lambda_2 \ w
\tag{4} \\\$$

$$\begin{equation}sign(w)=\left\\{\begin{aligned}1 & , & w \gt 0, \\\0 & , & w
= 0, \\\\-1 &, & w \lt 0.\end{aligned}\right.\end{equation} \tag{8}$$

这里给读者们提几个问题：

  1. 式 $(7)$ 和 式 $(4)$ 能对应起来吗？为什么说 $L1$ 正则假设参数的先验服从拉普拉斯分布，$L2$ 正则假设参数的先验服从高斯分布？
  2. 面试常见问题：$L1$ 正则通常会让参数更稀疏（参数有很多值为 0），你能从式 $(7)(8)$ 中找到原因吗？
  3. 逻辑回归的预测函数为什么要用 sigmoid？

到此为止，有了式 $(5)(8)$，就可以开始写模型代码了，我们来实现一个基于随机梯度下降（Stochastic Gradient Descent,
SGD）的逻辑回归。

软件环境：Python 3.x。

**1\. 数据**

输入数据如下所示：

    
    
    data = [
        # 格式 "label feature1:value1 featue2:value2"
        "0 item_id2:1 user_id2:1",
        "1 item_id1:1 user_id1:1",
        "0 item_id2:1 user_id1:1",
        "0 item_id1:1 user_id2:1",
        "1 item_id1:1 user_id1:1"
    ]
    

该数据集有两个特征，分别为 物品 ID 和 用户 ID。因为这些特征都是离散型特征，所以特征的值都是 1。

**2\. 输入函数**

将原始输入数据转化为模型能够识别的形式：

    
    
    import re
    def input_fn(data, epochs=1):
        for line in data * epochs:
            label_features = re.split('\\s+', line)
            if label_features is None or len(label_features) < 2:
                continue
            label = float(label_features[0])
            feature_values = label_features[1:]
            features = {}
            for feature_value in feature_values:
                feature, value = feature_value.split(':')
                features[feature] = float(value)
            features['bias'] = 1.0 # 每条数据都加上一个模型 bias
    
            yield label, features   
    

**3\. 工具函数**

为了后面的计算方便，需要定义一些辅助的工具函数：

    
    
    import math
    def sigmoid(wx_plus_b):
        return 1 / (1 + math.exp(-wx_plus_b))
    
    def sign(x):
        if x > 1e-6:
            return 1
        elif x > -1e-6:
            return 0
        else:
            return -1
    
    def predict(features, model):
        wx_plus_b = 0
        for feature, value in features.items():
            weight = model.get(feature, 0.0)
            wx_plus_b += weight * value
        # 预测值
        y_pred = sigmoid(wx_plus_b)
    
        return y_pred 
    

**4\. 训练函数**

我们按照上图中的 **模型训练流程** 来组织代码：

    
    
    def train(data, learning_rate=0.01, lambda1=0.0, lambda2=0.0, epochs=1):
        # 1.输入
        data_set = input_fn(data, epochs)
        model = {} # 模型参数，保存每个特征对应的权重
        for label, features in data_set:
            # 2.读取参数 和 3.数学运算
            y_pred = predict(features, model)
            # 4.计算损失 和 5.求导更新参数，运用式(8)
            for feature, value in features.items():
                weight = model.get(feature, 0.0)
                g = (y_pred - label) * value + lambda1 * sign(weight) + lambda2 * weight
                # 更新参数, SGD
                model[feature] = weight - learning_rate * g
        # 这就是逻辑回归的模型参数
        return model   
    

**5\. 训练**

    
    
    if __name__ == '__main__':
        lr = train(data, 0.01, epochs=100)
        print(lr) 
    

瞧，一个逻辑回归模型我们就写出来了。

从输出的日志中可以看到 item_id1 和 user_id1 的权重都比较大，但是在原始数据集中，只有当 item_id1 和 user_id1
共同出现时，label 才有很大可能是 1，显然逻辑回归无法捕获这种 **特征组合**
带来的影响，这就出现了早期带有特征向量化思想的模型——Factorization machine，FM.

#### FM$^1$

FM 为每个特征 $x_i$ 又新增了一个向量参数（称为 factor, f），以 $v_i$ 来表示，即现在每个特征 $x_i$ 除了有标量参数
$w_i$ 之外，还多了一个长度为 $k$ 的向量参数 $v_i$。

别看 FM 弄的这么玄乎，其实只要有它的 **预测函数** 和 **损失函数** ，我们一样可以手写 FM 代码。

FM 具体的推导过程就不在这里展开了，感兴趣的同学可以仔细研读原始 paper。

**预测函数**

$$\begin{aligned}\hat{y} &= w_0 + \sum \limits_{i=1}^{n}w_ix_i +
\frac{1}{2}\sum \limits_{f=1}^{k}((\sum \limits_{i=1}^nv_{i,f}x_i)^2 - \sum
\limits_{i=1}^nv_{i,f}^2x_i^2)\end{aligned} \tag{9}$$

其中，$w_i$ 是 $x_i$ 对应的标量/一次项参数，$v_i$ 是 $x_i$ 对应的向量参数，$k$ 是 $v_i$ 的长度，$v_{i,f}$
是向量 $v_i$ 中的第 $f$ 个元素值。

**损失函数**

对于二分类任务来说，FM 的损失函数与逻辑回归很相似：

$$\begin{aligned}L(w, v) = -y \ log(sigmoid(\hat{y})) - (1-y) \
log(1-sigmoid(\hat{y})) \end{aligned} \tag{10}$$

有了 $L(w, v)$ 就可以对参数 $w$ 和 $v$ 求导（具体的推导参考原始的
paper$^1$），然后进行参数的更新，与上述逻辑回归参数更新没有任何差别。

那么，现在你可以不依赖任何第三方库，自己实现一个 FM 模型了呢，请试一试吧。

### 小结

本篇首先介绍了数据和模型的关系，从最大似然和最大后验的角度阐述了模型是如何从数据中“学习”参数的。

然后讲述了基于梯度更新的模型是如何更新参数的，并且引入了两个传统的排序模型：逻辑回归和 FM。

逻辑回归简单易用，一般在项目的初期使用，缺点就是线性模型不太能捕获更复杂的特征组合带来的影响，模型表达能力有限。

FM 是早期引入特征向量化的模型之一，实现起来也不难，而且可以捕获特征的两两交叉，但是也仅限于此，没有办法对特征组合进行更深层次的挖掘。

可以看到，我们目前介绍的模型在训练过程中都是一条一条的对数据进行训练，但是我们知道在推荐系统中， **一组数据**
通常是有优先级顺序的，比如我们在同一页看到的 N 个商品，如果用户点了第 3 个，那么我们有理由相信第 3
个物品在该用户看来是优于其他物品的。这种数据与数据之间的关联，Pointwise（单点，一次只考虑单条数据） 的模型是难以发现的。

下一篇，咱们来看看如何能让模型在一次训练时，同时参考多条有关联的数据，学习到它们之间的优先级（顺序），从而在推荐系统这类需要排序的任务中发挥重要的作用！

注释 1：paper 地址：Factorization Machines. Steffen Rendle. ICDM 2010

