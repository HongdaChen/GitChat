经过前面几篇的历练，本上已经可以使用 TensorFlow 去搭建复杂的深度模型，搭配上一篇对于超参调节的 **最佳实践**
，相信模型搭建这一环节已经不再是整个模型开发流程中的瓶颈了。但是（总有一个但是）目前我们编写的模型，所使用的输入数据都还是人造的，而现实世界中的数据，“多姿多彩”、“奇形怪状”……总是会有令人意想不到的情况发生。本篇的重点，是几乎每个推荐系统算法从业者都会在不断地填坑踩坑过程中遇到的一些问题。

实际应用中遇到的问题远不止这些，希望各位同学都能在踩坑的过程中注意总结经验教训。

以下均以点击率预估任务为例。

### 类别失衡

点击率预估任务中，训练数据来自于 **曝光** 和 **点击** ，曝光未点击的数据是负样本，label 为 0，曝光点击的数据是正样本，label 为
1. 通常 1 和 0 的比例会达到 1 比 100，甚至更多，造成严重的类别失衡。

显然正样本对于模型来说最为珍贵，因为模型需要正样本来识别出哪些特征能够区分出正负样本，如果负样本太多，会造成正样本对于模型的贡献不够，导致模型学习不充分，因此常用的做法就是：

  * 数据处理时进行采样
  * 建模时设置类别权重

#### **采样**

一般有两种采样方式：

  * 下采样：对负样本下采样，随机选择一定比例的负样本，比如原本 1 比 100 的正负样本比，通过 0.1 的下采样率，变成了 1 比 10。
  * 上采样：对正样本上采样，将每个正样本复制 N 份，比如原来 1 比 100 的正负样本比，对正样本上采样 10 倍，同样让正负样本比例达成 1 比 10。

在实际应用中一般会采用 **下采样**
的方式去对数据进行采样，因为曝光数据动辄十亿百亿条，通过下采样，不仅可以平衡正负样本比，还会大幅降低训练时间。下面介绍几种下采样的方式可以在实际应用中作为参考。

**随机采样**

最朴素的一种处理手法，随机选择一定比例的负样本。优点在于简单、可以快速实现，作为基线版本，而且说不定这种简单的处理方法会带来很好的效果。

**按请求采样** [^1]

这种处理方式稍微复杂一点。

假设用户某次请求，看到如下 6 个物品，如下图所示。

![1、req.png](https://images.gitbook.cn/89e659c0-79d2-11eb-8fac-fb2a5d3bb731)

图 1：一次请求结果

这在会产生 6 条训练数据，现在有两种情况：

  * 6 个物品中，用户没有点击任何 1 个物品，则对这 6 条数据进行采样。
  * 6 个物品中，至少有 1 个物品被用户点击了，则对这 6 条数据不做采样，也就是保留所有的负样本，或者

**情况一**

即该请求下没有任何正样本时，也有做法是 **直接丢弃这 6 条数据**
。这里建议不要直接丢弃，丢弃后线下训练数据的分布与真实数据的分布差异会比较大，从实践中来看按照上述采样方式训练出来的模型，效果一般会好于直接丢弃。当然，如果时间允许，直接丢弃和随机采样都可以尝试。

**情况二**

即该请求下至少有 1 条正样本，还有一种做法叫 skip-above[^2]，顾名思义，就是丢弃该请求内
**最后一次点击（或者是最后一次点击之后的少数几条样本）**
之后的样本，这种做法认为最后一次点击之后的样本，可能用户尚未看见，因此不能把它们放入训练数据中。比如上图中，用户点击了物品 D，那么训练数据里可以只保留
ABCD，或者 ABCDE。究竟这两种策略哪种更好，都需要实验去验证。

#### **类别和样本权重**

设置类别/样本权重是另外一种解决类别失衡的好方法。

**类别权重 class weight**

一般对类别设置权重遵循的原则是：越稀少的类别，权重越高。比如在点击率预估任务中，label 为 1 的权重应该比 label 为 0
的权重高。那这个权重怎么设置呢？

TensorFlow 官方教程[^3] 给出了一个经验公式：

$$weight_{positive} = \frac{total\\_count}{positive\\_count} \times
\frac{1}{2} \\\weight_{negative} = \frac{total\\_count}{negative\\_count}
\times \frac{1}{2} \tag{1}$$

这里的目标是把正负样本比变为 1 比 1，实际应用中我们可能会设置会 1 比 5 或者 1 比 10 等其他比例，所以公式 (1) 仅可作为参考。

**样本权重 sample weight**

不仅类别可以权重，样本同样也可以设置权重，很多同学会混淆样本权重和类别权重的区别。

类别权重，只跟该样本的 label 有关系，比如 label 为 1 的权重为 10，label 为 0 的权重为 1
等等，但是有时候并不想这样处理，有可能 label 为 0 的样本权重也为 10. 那么什么时候才会有这样的处理逻辑呢？

按请求采样 **第二种情况** 时，就有可能发生这种情况。比如某次请求贡献了 6 条训练样本，其中 1 次发生了点击行为，则该请求下的样本不会被采样，这 6
条样本的样本权重均为 1，也就是说此请求下 label 为 0 的样本权重也是 1. 假设另一次请求也贡献了 6 条训练样本，但是均为 label 为 0
的样本，如果采样率设置为 0.2，则该 6 条训练样本会被采样成 1 条（$0.2 \times 6$ 向下取整），这 1 条样本的权重为
5（样本权重等于采样率的倒数[^1]），此时 label 为 0 的样本权重变为了 5。

**权重的作用**

类别/样本权重究竟有什么用、为什么要设置它们？设置它们影响的是什么？

**首先来看为什么需要设置它们**

当人为地对训练数据进行采样时，破坏了数据原来的分布，比如未采样数据的平均点击率为 0.02，使用采样率为 0.1 的下采样后平均点击率变成了
0.2，带来的后果就是模型的平均预测概率也变成了 0.2 了。

如果只关心预测概率的相对大小，而不关心其准确值，那么设置类别/样本权重的意义并不大，但是大部分情况下，预测概率是需要再与其他因子做运算操作的，比如电商中一般的排序公式是
$P_{点击}\times P_{转化} \times
Price$，此时不管是点击率（曝光后点击的概率）还是转化率（点击后支付的概率）都要求尽可能地准确，设置类别/样本权重正是为了解决这个问题，使得即使对采样后的训练数据进行建模，输出模型的预测概率依然在真实概率附近，不太受采样的影响。

**再来看看它们影响的是什么？**

既然数据被采样了，那么就要对被采样的数据进行“补偿”，在哪里进行“补偿”呢？

是的，LOSS. 通过将权重施加到损失函数中，使得采样后数据的整体 LOSS 期望值与原始数据的整体 LOSS
期望值相同，纠正了数据采样带来的选择偏差（selection bias）。

具体的证明可以参考引文[^1] 4.6 小节。

以交叉熵 LOSS 为例：

$$LOSS=\left\\{\begin{aligned}& -y \ log(p), & y = 1.0 \\\& -(1-y) \ log(1-p),
& y = 0.0\end{aligned}\right. \tag{2}$$

式中，y 是真实 label，p 为预测概率。

如果施加类别权重，则 LOSS 变为：

$$LOSS=\left\\{\begin{aligned}& class\\_weight_1 \times -y \ log(p), & y = 1.0
\\\& class\\_weight_0 \times -(1-y) \ log(1-p), & y = 0.0\end{aligned}\right.
\tag{3}$$

计算每条样本的 LOSS 时要乘以对应的类别权重，与 label 有关。

如果施加样本权重，则 LOSS 变为：

$$LOSS=\left\\{\begin{aligned}& sample\\_weight \times -y \ log(p), & y = 1.0
\\\& sample\\_weight \times -(1-y) \ log(1-p), & y = 0.0\end{aligned}\right.
\tag{4}$$

计算每条样本的 LOSS 时要乘以对应的样本权重。

如果同时施加类别和样本权重，则 LOSS 变为：

$$LOSS=\left\\{\begin{aligned}& class\\_weight_1 \times sample\\_weight \times
-y \ log(p), & y = 1.0 \\\& class\\_weight_0 \times sample\\_weight \times
-(1-y) \ log(1-p), & y = 0.0\end{aligned}\right. \tag{5}$$

一般同时设置的比较少见，较为常见的情况是类别/样本权重二选一，主要取决于数据的采样方式。

上文提到过，数据采样后不做任何处理直接训练，模型的预测概率与真实概率的偏差是比较大的。如果确实不想设置任何权重（毕竟修改了
LOSS，对梯度造成了影响），但是又想让预测概率在真实概率附近波动，怎么办呢？这时候就需要对预测概率进行校准（calibration）。

#### **概率校准**

假设数据集中正样本个数为 p，负样本个数为 n，则整体平均点击率：

$$ctr = \frac{p}{p+n} \tag{6}$$

设采样率为 $r \in (0,1]$，则负样本个数变为 $rn$，那么模型看到的整体平均点击率为：

$$\hat{ctr} = \frac{p}{p+rn} \tag{7}$$

显然模型拟合的是采样后的数据分布，其预测概率 $\hat{pctr}$ 也是一个有偏的概率分布，需要将其修正到真实预测概率 $pctr$。

由公式 6 和 7，可以得到：

$$\begin{aligned}\hat{ctr} &= \frac{p}{p+rn} \\\&= \frac{1}{1+r\frac{n}{p}} =>
\frac{n}{p}=\frac{1-\hat{ctr}}{r\ \hat{ctr}} \\\ctr &= \frac{p}{p+n} \\\&=
\frac{1}{1+\frac{n}{p}} \\\&= \frac{1}{1+\frac{1-\hat{ctr}}{r\ \hat{ctr}}}
\\\&= \frac{r \ \hat{ctr}}{1-(1-r)\hat{ctr}}\end{aligned} \tag{8}$$

因此对于 $\hat{pctr}$ 和 $pctr$，也有同样的关系：

$$pctr = \frac{r \ \hat{pctr}}{1-(1-r)\hat{pctr}}$$

在训练时，可以基于有偏的 $\hat{pctr}$ 去计算 LOSS 进行梯度更新，然后在预测时使用 $pctr$ 进行对外服务。

### 位置偏差

图 1 中的 6 个物品，其位置分别为 1-1、1-2、2-1、2-2、3-1、3-2​，一般称之为 **坑位** 。

1-1、1-2 表示第一行第一个，第一行第二个。

坑位是排序系统中扮演者绝对核心的角色，一件物品排在第一位和排在第一百位，直接决定了这件物品的生死，这也是为什么商家愿意花重金买坑位的原因。越靠前的坑位流量越大，自然也就更加的重要。

位置偏差或者坑位偏差，名称为 Position Bias，指的是用户对物品的行为，不仅受物品本身质量的影响，还受物品所在位置的影响。

因此，在实际建模时，尽量去消除这种偏差（Position DeBias），因为在预测时，根本不知道坑位信息，希望模型完全只关注用户对物品本身的兴趣。

既然训练数据已经收到了坑位的影响，那么建模时就要想办法让模型学到这种影响，从而在预测时剔除它，在这里介绍一种容易实现，简单直接的方法。

  * 训练时：将位置信息作为特征输入模型，比如把 3-1、3-2 等位置信息，hash 后做 embedding 处理，当作普通的特征参与模型训练
  * 预测时：此时并没有位置信息（因为还在预测嘛），所以比较好的做法是 **把位置特征固定为第一个坑位（在这里为 1-1）** ，进行预测，因此得到的点击率可以理解为：如果所有的物品都展示在第一个坑位，用户对物品的点击率。可以看到，已经达到了消除位置信息对模型的影响了。

关于 position bias，有兴趣地同学可以细读引文[^4]。

### 离线实验成本高

离线实验主要是为了进行调参，为的是得到让模型表现最佳的一组超参。

因此就有了本章节最后一个问题——离线实验试错成本可能过高。这里的成本主要指时间成本。

假设训练环境为单机 TensorFlow，训练数据跨度为 30 天，每天 1 亿条数据，共 30 亿条。

训练时设置 Batch Size 为 1024，每秒训练 50 个 Batch，那么训练一个 epoch 大概需要 16 个小时。当然可以选择 early
stopping 技术可能会让训练时间有所缩短，但是总的来说按照这样的时间估算，离线训练一次成本太高了，如果多调几组参数，多加几个
epoch，离线实验的时间成本可以以 **周** 为单位了。

为了降低时间成本，快速进行离线实验，可以这样去做： **在不破坏数据分布的情况下，对数据进行采样** 。

具体步骤为：

  1. 对每天的全量训练数据进行随机采样，不区分 label.
  2. 在采样后的数据上进行调参实验。
  3. 得到的最佳超参可以用于线上模型。

注意，这里只对训练集进行采样。

为了不破坏数据的分布，最好不要整体采样，而是在某个时间单位（比如天）内采样，最后将多个时间单位内的数据放在一起。

以上述假设为例，每天 1 亿条数据，施加 0.05 的采样率进行采样，则采样后每天的数据量为 500 万条，30 天的总数据量为 1 亿 5
千万。再按照上述的训练速度，训练一个 epoch 的时间缩短到 0.8 小时左右，原本可能需要 1 天的时间，现在只需要 1
个小时了，大大降低了时间成本，提高了建模的效率。

实践证明通过训练采样数据得到的超参与通过训练全量数据得到的超参是几乎没有差别的，如果在平时的建模过程中，确实数据量很大或者训练资源不足时，建议使用这种方式进行离线实验。

减少离线成本最直接的方式就是增加计算资源，比如由单机训练变为分布式训练。但是不管哪种方式，都可以通过训练采样数据来进行调参实验。

### 小结

现实世界中的数据总是纷繁多样的，在实际的建模过程中会遇到这样那样的问题，但是如果没有亲身经历过大型的系统或者在数据量不大的情况下，很多问题其实并不会遇见，而且这些问题在机器学习的理论领域是不会涉及的，只有涉足其中才能体会到“坑”是何其多，不过在不断填“坑”涨姿势的同时也能获得巨大的成就感和满足感。

类别失衡问题是推荐系统中最常见的问题，所以本文花了最多的篇幅来讲解如何解决此类问题——主要通过采样和类别/样本权重。

同样地，位置偏差问题在实际应用中也经常被忽略，这个问题主要是由于物品所在的位置也影响到了用户的行为，究竟需不需要去除它，还需要通过线上 AB 实验去判断。

最后谈到了离线实验时间成本高的问题，这在海量数据时显得尤为明显，除了增加训练资源外，还可以在不破坏数据分布的情况下对数据进行采样，然后利用采样后的数据进行离线实验，可以大大提高建模的效率，此可作为调参时的最佳实践之一。

到此为止，关于模型搭建到训练再到建模时需要注意的问题，已经探讨了很多了，似乎一直没有介绍一个很重要的主题——排序系统如何做离线评估？不可能所有的模型都去线上校验其质量，不仅流量不允许，BOSS
也不可能允许啊。下一篇就来看看离线评估这个问题。

咱们，下篇见。

注释 1：[Ad Click Prediction: a View from the
Trenches](https://research.google.com/pubs/archive/41159.pdf) 注释 2：《美团机器学习实战》
注释 3：[Tensorflow
官方类别失衡指南](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)
注释 4：[Leveraging Position Bias to Improve Peer
Recommendation](https://www.researchgate.net/publication/263015500_Leveraging_Position_Bias_to_Improve_Peer_Recommendation)

