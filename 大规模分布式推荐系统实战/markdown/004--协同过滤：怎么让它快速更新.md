目前为止，对于协同过滤算法，一般设定为一天更新一次，对于大部分推荐系统来说已经可以很好的完成任务了。不过，如果特别关注新物品能够快速地被推荐系统发现，就需要设计一套准实时的协同过滤算法。

本篇会详细介绍准实时协同过滤算法的实现逻辑，但是并不会真正去实现，因为涉及到多种技术框架。不过相信掌握了思路之后，工程中的实现相信难不倒聪明的你。

准实时指的是秒级或者分钟级。实际工程中一般采用的技术栈：HBase/Redis、Kafka、Spark Streaming/Flink。

### 温故知新

离线协同过滤的计算逻辑大体上如下。

1\. 生成一张用户物品打分表：

user | item | rating  
---|---|---  
用户 ID | 物品 ID | 用户对物品的打分  
  
2\. 根据用户聚合，得到每个用户的物品打分集合：

user | item_ratings  
---|---  
用户 ID | 用户对物品的打分集合: [ ( item1 : rating1 ), ( item2 : rating2 ), ... ]  
  
3\. 计算局部相似度、全局相似度、生成结果表：

item1 | item2 | similarity  
---|---|---  
物品 ID | 相似物品 ID | 相似度  
  
准实时的计算逻辑与之一样，只不过为了能够做到及时更新，数据的存储需要有所变化。

### 数据流

在真正介绍准实时更新的思路之前，先要搞清楚线上的数据流是什么样子的。如下图所示：

![准实时协同过滤](https://images.gitbook.cn/dfb33b20-2734-11eb-be76-5555cd71111f)

流程如下：

1\. 用户的行为通过手机或者 PC 等终端上报到服务端，Kafka 不断接收。

2\. 流处理程序（Spark Streaming/Flink）将流数据通过窗口操作转换成批数据（一般是以分钟粒度为一个窗口）。

3\. 开始获取更新物品相似度所需要的一切数据：

  * 批数据中用户的历史行为（图中 3.1）：从存储和计算性能考虑，一般历史行为可以最多存储 M 条或者最多 N 天的数据。
  * 批数据中用户的实时行为和历史行为中的物品对应的被消费次数（图中 3.2）。
  * 批数据中物品的两两相似度（图中 3.3）。

4\. 更新新的相似度、更新用户历史行为、更新物品被消费次数。

下面就来举个例子来说明整个流程。

### 准实时如何更新

#### **离线数据准备**

假设图中的三张 HBase 表含有如下数据：简单起见，表格中第一列均为 HBase 的 rowkey、第二列均为 column family
的名字及其对应的 value，这里用的 rowkey 是明文，一般工程中使用的是 MD5 等分布比较均匀的值，降低数据倾斜的概率。

**用户行为 HBase：**

rowkey | history actions  
---|---  
小明 | [(P40PRO,浏览,20200610)、(iPhone11,浏览,20200615)、(iPad,浏览,20200530)]  
  
这个 HBase 的数据我们很熟悉，可以认为是离线表同步到 HBase 中供线上使用。

**物品被消费次数 HBase：**

rowkey | item counts  
---|---  
P40PRO | 1000  
iPhone11 | 800  
iPad | 500  
  
**相似度 HBase：**

rowkey | sim  
---|---  
(P40PRO, iPhone11) | 0.05  
(iPhone11, iPad) | 0.04  
(P40PRO, iPad) | 0.03  
  
#### **实时数据处理**

**历史行为处理**

假设以 5 分钟为一个窗口，生成了一份批数据：

    
    
    [小明 P40PRO   购买 20200620]
    [小明  三体     浏览 20200620]
    

那么，流处理程序的逻辑是，根据 **历史行为 HBase** 获取到小明的历史行为，与实时行为合并，则小明的行为数据变为：

    
    
    [(P40PRO，购买，20200620)、(iPhone11，浏览，20200615)、(iPad，浏览，20200530)、(三体, 浏览, 20200620)]
    

注意到 P40PRO 同时存在历史行为和实时行为中，这里我们采用最大合并而不是求和合并。

**物品次数处理**

根据 **物品次数 HBase** 获取到批数据里所有物品的消费次数，得到：

    
    
    COUNT_p40pro = 1000
    
    COUNT_iphone11 = 800
    
    COUNT_三体 = 0
    

**相似度处理**

根据 **相似度 HBase** 获取到所有物品原来的相似度：

    
    
    SIM_(p40pro, iphone11) = 0.05
    
    SIM_(iphone11, ipad) = 0.04
    
    SIM_(p40pro, ipad) = 0.03
    

#### **相似度更新**

如果读者还记得上一篇关于相似度的计算方法的话，相似你已经知道如何更新了。

**计算局部相似度（单个用户下的物品相似度）SIM_小明**

根据上一篇的逻辑，使用小明合并后的行为集合即可计算出来。

**计算全局相似度**

同样，在上一篇中我们知道：

    
    
    SIM(ITEM1, ITEM2) = SUM(SIM_USER) / SQRT(COUNT_ITEM1 * COUNT_ITEM2)
    

这里我们有了一个新的 PART_SIM_小明，所以相似度更新公式应该是：

    
    
    NEW_SIM(ITEM1, ITEM2) = (OLD_SUM(SIM_USER) + SIM_小明) / SQRT(NEW_COUNT_ITEM1 * NEW_COUNT_ITEM2)
    

以 P40PRO 和 iPhone11 为例：

    
    
      /* 1 / (1 + |rating1 - rating2|) / log2(用户消费的物品次数) */
      SIM_小明(P40PRO, iPhone11) = 1 / (1 + (5 - 1)) / log2(4) = 0.1 
    
      OLD_COUNT_P40PRO = 1000
      OLD_COUNT_IPHONE11 = 800
      OLD_SIM(P40PRO, IPHONE11) = 0.05
      OLD_SUM(SIM_USER) = OLD_SIM(P40PRO, IPHONE11) * SQRT(OLD_COUNT_ITEM1 * OLD_COUNT_ITEM2) // WHY ? 
                        = 0.05 * SQRT(1000 * 800)
                        = 44.721
    
      NEW_COUNT_P40PRO = OLD_COUNT_P40PRO + 1
                       = 1001
      NEW_COUNT_IPHONE11 = OLD_COUNT_IPHONE11 + 0
                         = 800
    
      NEW_SIM(P40PRO, iPhone11) = (OLD_SUM(SIM_USER) + SIM_小明) / SQRT(NEW_COUNT_ITEM1 * NEW_COUNT_ITEM2)
                                = (44.721 + 0.1) / SQRT(1001 * 800)
                                = 0.0501
    
      // 保存新的用户行为集合到 HBase 中 
      // 保存新的物品消费次数到 HBase 中
      // 保存新的物品相似度到 HBase 中
    

至此，一个窗口更新完成，继续处理下一个窗口的数据。

这里只用到了一个用户，其实多个用户的逻辑是一样的，与上一篇离线计算相似度的逻辑并无差异。主要的区别点就在于将离线的全量计算改成了线上的增量计算，要不断地读取和更新相关数据。

### 地鼠商城召回算法之协同过滤实战总结

经过几周的不断优化和完善，地鼠商城的第一个召回算法——协同过滤，终于能做到准确度和更新速度都能满足了。

在此对实战中踩到的坑加以总结。

**数据！数据！数据！……**

这个强调多少遍都不为过，在实际的工作过程中，一旦算法表现不尽如人意，第一反应就是去 **优化公式**
！！！尤其是相似度计算公式，这是很多同学都会做出的选择，毕竟 **优化和分析数据**
是一种没有技术含量的“脏活累活”。但是，通过不断地踩坑和碰壁，不断地被毒打和冲击， **数据才是王道**
，而好的数据是要深入理解业务，了解数据中每个字段的含义、埋点的逻辑等等，它带来的回报也是很客观的。

协同过滤最重要的就是打分数据，隐式反馈数据作为一种最容易获取的数据，并没有直接反映出用户的喜好，我们只是凭借数据去“猜测”用户的打分，所以这份打分数据一定要能最大可能地反映用户的真实喜好，这份数据的质量决定了算法最终的表现。

要记得一个真理：

> GARBAGE IN, GARBAGE OUT!

**影响结果的因素**

除了上述的数据之外，还有以下可能会影响到算法表现的几点：

  * 行为时间衰减：这个策略听上去很合理，因为它可能会让很久之前的用户行为无法发挥作用而只关注近期的行为，请谨慎使用，最好同时尝试不加任何衰减的策略。
  * 热门惩罚：类似爬虫等异常用户，其数据价值不大；热门物品，其对相似度的贡献度也不是那么的大。
  * 相似度公式：最起码要做到打分接近，相似度就接近，还要做到有一定的区分度。
  * 更新速度：有些场景对实时性的要求并不高，但是有的就很高，比如新闻、短视频，还是要根据业务的情况再决定。

好啦，说得够多了，就到这里了。刚才 BOSS 问我，地鼠商城购物车推荐 （下图中的为你推荐） 怎么优化？

![](https://images.gitbook.cn/00b2b0c0-2736-11eb-be76-5555cd71111f)

GOD，需求无止尽啊~~~

我先休息先，咱们下篇再问答他这个问题。

