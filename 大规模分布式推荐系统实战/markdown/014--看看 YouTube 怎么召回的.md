到目前为止，地鼠商城推荐系统已经上线了协同过滤、关联规则和词向量三种召回算法，效果确实比对照组有不小的提升。而且这些都属于 I2I（item to
item）算法，也就是根据商品去找关联/相似商品。

所谓对照组，就是 AB 实验时没有变量发生变化的一组事物，用来判断变量发生变化的实验究竟有没有带来收益。

相信读者们对这一套推荐逻辑都比较清楚了：

  * 获取用户的行为序列
  * 根据行为序列中的商品，查找每个商品对应的关联/相似商品
  * 返回推荐列表

在很多数据量不大的场景，这样的推荐逻辑不仅简单而且效果也很不错，更难能可贵的是这些算法的可解释性都很好（可能词向量除外）。在需要强解释性的场景，这些算法都可以很好地发挥作用。

可是，终究还是有个“可是”，它们虽然有很多优点，缺点也很明显，有的缺点甚至是致命的：

  * 首当其冲的就是商品冷启动问题：对于刚刚上线的新品，上述三种算法直接缴械投降，因为这些新品甚至都不会出现在训练数据里。
  * 再次就是用户冷启动问题：对于没有任何行为的新用户而言，也就没有下行为序列，那还谈何关联/相似商品呢。
  * 同质化问题：相似商品推荐的结果会造成越推越窄，满屏的同类商品、难以跳出，从而很可能让用户感到厌烦失去兴趣。
  * 不够个性化：只考虑了用户行为，很难将其他影响因素纳入到算法中来，比如用户的年龄性别、使用的手机型号、购买力等等……

可以看到，当数据量开始变大，用户行为逐渐丰富起来时，上述几种算法难以挖掘到更深层次的用户和商品之间的关系。为了利用上丰富的用户信息、商品信息，各种算法模型层出不穷，本篇主要介绍
YouTube 的召回系统时如何设计的。

### paper 说明

Google（YouTube 是 Google 的产品）曾于 2016 年发表过一篇很出名的 paper，叫做 [_Deep neural networks
for YouTube recommendations_](https://research.google/pubs/pub45530/)，从 paper
的名字中已经可以知道主要内容是详细介绍了深度学习在 YouTube 视频推荐系统中的应用，着重介绍了 **召回** 和排序系统。

后来在 2019 年，Google 又发表了一篇也很出名的 paper，叫做 [_Sampling-Bias-Corrected Neural
Modeling for Large Corpus Item
Recommendations_](https://research.google/pubs/pub48840/)，这篇 paper
的主题思想还是在于召回系统的设计和优化。

一般 Google 和 Facebook 的论文质量都特别高，不仅在于理论基础很扎实，更难得的是都比较容易落地。请读者们一定要仔细研读这两篇质量很高的
paper。

本篇不打算对这两篇 paper 做类似翻译性的解读，而是从地鼠商城首页推荐场景中对于这两篇 paper 的理论落地出发，好好聊聊实际工作中应该如何将
Deep Learning 运用在召回系统中。

本篇没有具体的代码，GitHub 上关于 YouTube recommendation 的代码实现已经多如牛毛了。重心放在如何将 paper
与实际工作结合起来。

### U2I

既然有 I2I，那么就有 U2I。

I2I 是根据商品去找商品，那么相应地，U2I
就是根据用户（user）去找商品。那么，怎么根据用户去找商品呢？一般地思路就是将用户转化为一个向量，用向量来表征用户与用向量来表征商品一样，并没有太大地差异。这里简单介绍一下几个常见的早期很多基于
MF（矩阵分解）的思想将用户向量化的算法：

  * ALS：交替最小二乘，根据用户对商品的打分矩阵构造出用户矩阵 P 和商品矩阵 Q，通过固定 P 来更新 Q，然后再固定 Q 来更新 P，此为交替的由来，最终 P 和 Q 会趋于稳定。这个算法在 Spark 中有实现，优点在于简单，缺点在于这是一个离线算法，并且对于新用户/新商品束手无策，仅仅用到了打分数据，算法精度不高。
  * SVD/SVD++：这类算法与 ALS 很相似，都是基于打分矩阵最终得到用户/商品向量，差别在于打分公式会有所差别。
  * FM：FM$^1$ 有了特征的概念，所以相对上面几种算法会稍微复杂一点。引入了特征的一阶组合和二阶组合，增强了模型的表达能力和泛化能力，而且算法的时间复杂度并不高。不足点在于特征交叉过于简单，没法挖掘特征更深层次的关联。至于后来的 FFM，也只是在一定程度上缓解了这个问题。

以上这些算法虽然在现在这个时代很少有人会去直接使用，但是其中的思想还是希望大家一定要好好掌握的，很多比较出名的深度学习模型的思想可能就是从这些“上古”算法中演变而来（比如
DeepFM）。

一般来说，相比于商品向量来说，用户向量应该是更容易产生变化的，因为用户的兴趣在不断的改变，而商品属于比较稳定的事物。所以我们需要这样的算法：

  * 既能快速响应用户兴趣的变化（比如用户在应用内只要发生行为，算法模型就能感知到并及时更新用户向量）
  * 又能够挖掘出用户对商品更深层次的联系（比如我正在浏览 Xbox 游戏，突然推荐页里出现了便携式显示屏）

也就是响应又快结果又准，怎么去做才好呢？

对的，Deep Learning、即深度学习或者神经网络。

首先我们来看看 YouTube 是如何通过深度学习模型来得到用户/商品向量。

### 双塔

什么是“塔”？如下图是神经网络常见的结构：

![](https://images.gitbook.cn/1d7f90a0-2831-11eb-be76-5555cd71111f)

输入 $x$ 经过三层网络，每一层的输出都是一个向量，来自于输入与该层参数矩阵的相乘，最终得到输出 $y$，这个结构看上去非常像一座塔。

上一节说道在召回阶段我们可以得到 用户向量 和
商品向量，如果通过某一种网络结构的搭建，同时让神经网络模型学习到这两个向量，岂不是很美？这就是“双塔”的由来。如下图所示：

![](https://images.gitbook.cn/26678880-2831-11eb-9e6e-492b4066adc9)

我们以一个具体的场景来举例说明。

> 目标：提升视频网站的点击率。

那么应该如何根据这个具体的目标，通过建模，将双塔模型与实际应用场景结合起来，解决业务问题呢？

一般的步骤如下。

#### **数据**

最重要的一步，这一步直接决定了算法的性能表现。

**1\. Label**

既然目标是点击率提升，那么就需要将曝光数据与点击数据关联起来，曝光未点击的作为 $y = 0$ 的负样本，曝光点击的作为 $y = 1$ 的正样本。

> 曝光：用户实际看到了某件商品，那么就称为一次曝光。点击：用户看到之后点击了，就称为一次点击。

**2\. 特征**

一般的推荐系统会从以下四个方面去挖掘特征：

  * 用户信息：用户 ID、年龄、性别……
  * 商品信息：商品 ID、商品类别 ID、品牌 ID、店铺 ID、价格……
  * 上下文特征：事件发生时，用户使用的手机品牌、操作系统、城市，是不是周末、上午还是下午还是晚上、当前的页面 ID……
  * 行为特征：用户过去浏览/加车/收藏/购买过的商品/店铺/类别/品牌……

以上数据要经过仔细的清洗和过滤，确保数据的质量。谨记 GARBAGE IN GARBAGE OUT。

#### **训练**

如下图所示，这是一个特别直观的双塔结构的模型。

![](https://images.gitbook.cn/82d6ae90-2834-11eb-b804-ef8651c2512a)

  * 原始的特征经过 embedding 层之后拼接起来
  * 然后左右两个塔各自经过 [512,256,128] 三层网络
  * 将最后一层输出作为用户向量和商品向量，维度均为 128
  * 最终将用户向量与商品向量做内积之后，经过一个 sigmoid 函数，得到预测概率 p
  * p 与真实 Label 计算 Loss
  * 参数梯度更新
  * 下一批数据

这便是整个训练过程。

#### **Serving**

经过上一步之后，模型已经训练完毕，那么怎么让这个模型用起来呢？别着急，接着往下看。

一般双塔模型在召回系统中的使用如下图所示：

![](https://images.gitbook.cn/97a3d8c0-2834-11eb-b0e7-2bcf5f61297e)

生成模型后，却要将双塔分开使用：

  * 用户侧的塔推送到线上用作实时预测，也就是说：当用户请求来临时，根据用户特征预测得到 user vector
  * 商品侧的塔的处理方式又有点差别
    * 离线将所有商品及其特征输入模型，得到所有商品的 item vector
    * 再将这些 item vector 加入到 **某种可以快速检索的数据结构** 中
  * 有了实时推理出当前用户的 user vector，又有离线计算好的全量商品的 item vector，就可以计算两者内积，取 topN 作为召回结果
  * 完毕

### 小结

在这篇文章之前，我们接触到的都是 I2I 算法，此类算法的优点和缺点都很明显。我们又简单介绍了一些 U2I
算法，可不要小看这些简单的算法，在很多时候崇尚复杂而又难以训练的算法模型往往会导致不好的结果，一个优秀的推荐算法设计人员应该能够根据不同的业务场景设计不同的适配算法，这也是最难的地方。

将神经网络运用在召回系统中，其最大的优点就是泛化性很好，能够用上丰富的用户和商品特征，而作为世界技术领导者，Google 每年都会有经典地 paper
问世，值得我们这些从业人员好好研究。

双塔结构已经被广泛的运用在推荐系统中，能够训练出高质量的用户向量和商品向量，虽然数据处理、模型训练的复杂度明显上升，但是在地鼠商城一上线，便处于“独孤求败”的位置，线上表现及其优异，虽然牺牲了部分可解释性（embedding
很难解释），但是带来的收益却是特别可观。我想我又可以躺在功劳簿上摸鱼一段时间了。

然而，可以吗？

### 不足

相信眼尖的读者们已经发现了这个问题：

> 有了实时推理出当前用户的 user vector，又有离线计算好的全量商品的 item vector，就可以计算两者内积……

如果有百万级千万级的商品，用 user vector 去与每个 item vector
做内积，岂不是要慢的连蚂蚁都嫌弃？这怎么可能满足线上毫秒级响应的要求？

是的，这确实是一个很大的问题，所以我们需要 **某种可以快速检索的数据结构** ，也就是说——根据 user vector 去检索百万/千万级别的 item
vector 时，可以实现极低的时间复杂度，在毫秒级的时间内完成 topN 的检索结果。

真的有这种技术吗？

当然，大家还记得 LSH 吗？只不过它因为自身性能原因，不能用于要求快速返回结果的线上服务，但是至少能提供了一个解决问题的思路。

下一篇，咱们来仔细研究一个从“海量商品向量中取 topN 如探囊取物”的近似近邻搜索（ANN）技术——HNSW。

咱们，下篇见。

* * *

注释 1：[FM 的原始
paper](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)，值得一读

