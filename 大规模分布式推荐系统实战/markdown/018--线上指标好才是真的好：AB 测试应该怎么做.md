有道是“台上十分钟，台下十年功”，咱们这些算法工程师们经过了——数据获取、数据清洗、特征筛选、特征工程、建模、调参、特征工程、建模……这一系列步骤之后，终于完成了一个“有模有样”的离线指标还不是太难堪的模型，在喜极而泣之余感概良多，但是随之而来又有一个最为重要的一步需要完成——上线。

当一个算法模型上线后，通常关注的不再是上一篇所提到的 **精准率** 、 **召回率**
等离线指标，而是与具体业务强相关的商业指标——点击率、转化率、GMV（一定时间内的成交总额）、ARPU（一定时间内的平均每用户收入，GMV/用户数）
等。这些指标需要一个平台直观地展示出来，这不仅可以对比线上模型孰优孰劣，更重要的是能够表示出我们的迭代效果，指引下一步的优化方向——这正是 AB
测试平台大显身手的机会。

### 什么是 AB 测试

[维基百科](https://en.wikipedia.org/wiki/A/B_testing) 上关于 AB 测试的描述如下：

> A/B testing is a way to compare two versions of a single variable, typically
> by testing a subject's response to variant A against variant B, and
> determining which of the two variants is more effective.

简单翻译过来就是：AB 测试是用来比较 **单个变量** 的 **两个版本 A 和 B** ，通过测试用户对 A 和 B 的不同反应，来决定会采用 A 还是
B 作为该变量的最终版本。当然在现实生产中，单个变量通常不止两个版本，而是多个版本（如下图所示），然后通过观察用户反应，效果最佳的那个胜出。

![](https://images.gitbook.cn/fbaa0280-483d-11eb-8e68-bb4362622133)

在推荐系统中，不管是召回算法还是排序算法，都在整个的个性化推荐流程中发挥重要的作用，对点击率、转化率等业务指标会产生很大的影响。而算法模型是一个不断优化迭代的过程，每天都会有新的模型上线，线上表现不好的模型下线，这其中正是依靠
AB 测试去展示每个模型的效果好坏。

一个好的 AB 测试平台可以提高算法模型的迭代效率，大大增加试错的机会，这在机器学习应用中显得尤为珍贵，“调参侠”的美名相信各位同学都不陌生了，如果 AB
测试平台可以快速验证各种参数组合带来的效果，对业务指标的提升是大有裨益的。

地鼠商城的 AB 测试平台方案经历了从简单到完善的过程，接下来咱们就来一起瞧瞧这其中的迭代过程。

### 最朴素的 AB 测试方案

最初的 AB 测试方案如下所示：

![](https://images.gitbook.cn/067fc0a0-483e-11eb-a007-1b095f083930)

我相信这也是目前很多公司采用的方案——大杂烩，意思是所有服务的实验均放在一起。

以上图为例，总流量为 100%，共有 5 个实验正在进行中，其中有 2 个是召回实验，3 个是排序实验，流量互不干扰，很容易就计算出来每个实验都占用 20%
的流量，很好，一般情况下单个实验 20% 的流量持续运行一段时间足以得到一个置信的实验结论。在这个阶段，还是没有什么问题的。

现在，APP 登录界面（UI）需要开一个实验来验证到底 **某一个按钮究竟是圆形好还是方形好** ，于是 AB 测试平台上又多了一个实验，如下图所示：

![](https://images.gitbook.cn/82e59bb0-483e-11eb-bda4-87a3a0ca87cf)

为了让新加入的实验 F 获得一定的流量，另外 5 个实验只好“委屈”一下将各自的 20% 流量都做相应的缩减，保证最后 6 个实验的流量都能够达到
16.7%。

按照这种态势发展下去，很快实验数量便会超过 20 个、30 个、50 个……此时每个实验的流量居然只有可怜的
2%，实验效果波动极大，每个实验都因为流量过小都难以得到确切结论，AB 平台形同虚设。为了让 AB
平台还能发挥它的作用，便开始控制实验数量，同时上线的实验不能超过 10 个等等，迭代效率大打折扣。

我们希望 AB 平台能够完善实验设计方案，解决上述 **扩展性差** 、 **流量不够用** 等问题，满足以下几个诉求：

  * 不同类型的实验调配对其他类型的实验毫无影响，比如召回实验增加 3 个实验，对排序实验毫无影响。
  * 同种类型的实验能得到 100% 的流量，比如召回实验能得到 100% 的流量，排序实验也能得到 100% 的流量。这样每种类型的实验数量就可以大大提升了。
  * 同种类型的时间流量互不干扰，比如召回实验 1 的流量和召回实验 2 的流量之间没有重叠、互不干扰。

于是，分层实验方案出现了。

### 分层 AB 测试方案

> 分层 AB 方案来自 Google 2010 年的一篇 paper$^1$，目前已经成为了 AB 平台方案设计的“行业标准”了，这篇 paper
> 中的内容并不是本文的重点，有兴趣的同学可以一探究竟。

何谓 **分层实验？** 顾名思义就是把实验分成多层（说了跟没说一样）。如下图所示，便是分层实验的概览。

![](https://images.gitbook.cn/e8a51fc0-483e-11eb-9bc5-d1a5ef48d082)

上图中的 AB 测试平台将实验分成了 3 层，可以看到每一层都可以使用 100% 的流量，同一份流量同时穿越 3 层。

各层按照相应的业务类型进行划分，比如实验层 1 是 UI 界面实验，实验层 2 是召回实验，实验层 3 是排序实验。

那么这种分层的设计有什么规则需要遵循呢？最重要的就是流量的 **正交** 和 **互斥** 。

#### **正交**

所谓流量的正交是针对 **不同实验层**
而言的，指的是层与层之间的流量是正交的，每个层出来的流量会再次经过随机打散后进入下一层，保证下一层接收到的流量均匀的来自上一层。文字描述可能会有点干巴巴的不好理解，下图展示出了正交的含义。

![](https://images.gitbook.cn/f6db1fe0-483e-11eb-a9f9-7f16db2bf39e)

当实验层 1 内第 1 个实验（记为实验 1-1）的 20%流量进入第 2 层时会被再次随机均匀打散，这样实验层 2 内每个实验得到的实验 1-1 的流量为
5%，当实验层 2 的流量进入实验层 3 时，实验 2-1 中来自实验 1-1 的 5% 流量再次被打散，这样实验层 3 内每个实验得到的实验 2-1
中实验 1-1 的流量为 0.8%。这样带来的好处就是不仅实验流量被均匀打散，而且实验效果也被均匀打散了，比如实验 1-1
在线上的效果特别好，但是其流量进入实验层 2、实验层 3 时都是被均匀打散的，所以这两层内的实验受到的实验 1-1 的影响都是一样的，也就是说
**上一层实验效果** 并不会对 **下一层实验效果的比对** 产生任何影响。

#### **互斥**

所谓流量的互斥是针对 **同一实验层** 而言的，指的是同一层内实验之间的流量是不会重叠的，这个很好理解，就不再赘述啦。

关于分层 AB 测试方案，我们就介绍到这里，要实现一个配置灵活、方便易用的 AB 测试平台也并不是 1、2
个人就能够完成的事情，这其中需要很多的工作要做，在此就不做过多介绍了，感兴趣的同学强烈推荐看一下 Google 的 paper$^1$。

接下来，我们将着重介绍 **怎么估算 AB 测试结果的置信度** ，从而判断实验效果到底可不可信。

### AB 测试结果可靠性估计

在说明如何估计可靠性之前，有几个概率论和随机过程中的概念需要再回顾一下。

#### **假设检验**

通常我们能获取到的数据均可以认为是从 **总体** 中抽样出来的 **样本**
，因此假设检验的作用就是我们先对总体中的参数提出假设，然后判断样本是否提供了足够的信息让我们可以得出 **这个假设成立**
的结论，也就是通过样本来验证总体假设。

一般实验者会提出两个假设：

  * 零假设（Null Hypothesis）：记为 $H_0$，即假设两份样本来自同一个总体，所有异常事件均是随机误差造成的。
  * 备择假设（Alternative Hypothesis）：记为 $H_1$，即假设两份样本不是来自同一总体。

可见零假设和备择假设互斥，只可能有一个是真，一般零假设是实验者想要否定的假设，相应地，备择假设是实验者希望接受的假设。

假设检验的思想也很简单——反证法和小概率原理， 其步骤为：

假设检验的步骤为：

  1. 根据实际问题，提出零假设和备择假设

  2. 先假定原假设是正确的，开始构造一个小概率事件

  3. 通过样本来检验该小概率事件是否发生，如果

    * 小概率事件发生了，我们有理由怀疑零假设的正确性，从而拒绝零假设，否则
    * 我们认为零假设确实是正确的，接受零假设

#### **显著性水平**

显著性水平一般用 $\alpha$ 来表示，其定义为：

$$P\\{当 H_0 为真时拒绝 H_0\\} \leq \alpha$$

也即，零假设 $H_0$ 为真时却拒绝 $H_0$ 的最大概率，记住：这是 **人为** 定的。

#### **置信区间**

设总体 $X$ 的分布函数中含有一个变量 $\theta$，对于给定值 $\alpha$，来自 $X$ 的样本确定的两个统计量
$\underline{\theta}$ 和 $\bar{\theta}$（$\underline{\theta} <
\bar{\theta}$），对于任意的 $\theta$ 均满足：

$$P(\underline{\theta} < \theta < \bar{\theta}) \geq 1-\alpha$$

则称随机区间（$\underline{\theta}$, $\bar{\theta}$）是 $\theta$ 在置信水平为 $1-\alpha$
下的置信区间。 $1-\alpha$ 称为置信水平。

这个公式的含义是：反复进行 N 次抽样，每份样本会确定一个区间（$\underline{\theta}$,
$\bar{\theta}$），每个这样的区间要么包含 $\theta$ 的真值，要么不包含 $\theta$ 的真值。在这 N 个区间中，包含
$\theta$ 真值的区间占 $100(1-\alpha)\%$，不包含 $\theta$ 真值的区间占 $100\alpha\%$。比如，假设
$\alpha=0.05$，进行 100 次抽样，得到的 100 个区间内不包含 $\theta$ 真值的为 5 个。

#### **p 值**

p 值的定义： **由样本得出的** 零假设 $H_0$ 为真时却拒绝 $H_0$ 的最小显著性水平，记住：这是 **根据样本算出来的** 。

可见 p 值本质上也是显著性水平，只不过通常意义上的显著性水平是人为指定的，而 p 值是根据样本算出来的。

按照 p 值的定义，对于任意给定的显著性水平 $\alpha$：

  * 如果 p 值 $\leq \alpha$，则在显著性水平 $\alpha$ 下拒绝 $H_0$
  * 如果 p 值 $\gt \alpha$，则在显著性水平 $\alpha$ 下接受 $H_0$

比如，p 值为 0.02，如果显著性水平 $\alpha$ 为 0.01，那么接受 $H_0$，但是如果 $\alpha$ 为 0.05，则拒绝
$H_0$。

掌握了以上几个概念之后，我们来看看在 AB 实验中如何判断“B 实验与 A 实验的指标差异”具不具有统计显著性，也就是说这种差异并非由于随机误差导致。

#### **AB 测试的统计显著性**

场景：A 实验和 B 实验是同一个变量的两个版本（比如 A 实验使用召回算法 1，B 实验使用召回算法 2）。

现象：线上指标显示实验 B 的点击率（CTR，click through rate）要比实验 A 的点击率高。

目标：验证上述指标差异是否具有统计显著性，显著性水平假定为 $\alpha$。

为了达成上述目标，需要的实验数据如下所示：

| 实验 A | 实验 B  
---|---|---  
命中用户数 | $n_A$ | $n_B$ |  
样本（实验观测到的）点击率 | $\hat{p_A}$ | $\hat{p_B}$ |  
  
**第一步：提出假设**

$H_0$：总体 $p_B$ $==$ 总体 $p_A$

$H_1$：总体 $p_B$ $\gt$ 总体 $p_A$

**第二步：计算 Z-score**

点击率服从伯努利分布 $\mathcal B(n,p)$，对于总体 A，其点击率分布为 $\mathcal B(n_A,p_A)$，总体 B 的点击率分布为
$\mathcal B(n_B,p_B)$。各自的均值方差为：

$$\begin{aligned}E(p_A) &= \hat{p_A} \\\D(p_A) &= \hat{p_A} (1-\hat{p_A})
\\\E(p_B) &= \hat{p_B} \\\D(p_B) &= \hat{p_B} (1-\hat{p_B})\end{aligned}$$

根据中心极限定理，可以得到如下两个正态分布：

$$\begin{aligned}\overline{p_A} &\sim \mathcal
N(\hat{p_A},\frac{\hat{p_A}(1-\hat{p_A})}{n_A}) \\\\\overline{p_B} &\sim
\mathcal N(\hat{p_B},\frac{\hat{p_B}(1\hat{p_B})}{n_B})\end{aligned}$$

中心极限定理指出如果有一个独立同分布的随机变量 $X$ 的序列 $X_1, X_2, …, X_n$，它们的期望为 $\mu$，方差为
$\sigma^2$，则 $X$ 的均值 $\bar X \sim \mathcal N(\mu,\frac{\sigma^2}{n}) $。

而两个独立的服从正态分布的随机变量相减，得到的差依然服从正态分布，即：

$$\begin{aligned}\overline{p_A} - \overline{p_B} &\sim \mathcal
N(\hat{p_A}-\hat{p_B},\frac{\hat{p_A}(1-\hat{p_A})}{n_A} +
\frac{\hat{p_B}(1-\hat{p_B})}{n_B})\end{aligned}$$

于是可以计算出此分布对应的 Z-score：

$$\begin{aligned}Z &= \frac{x-\mu}{\sigma} \\\&= \frac{\overline{p_A} -
\overline{p_B} - (p_A - p_B)}{\sqrt{\frac{\hat{p_A}(1-\hat{p_A})}{n_A} +
\frac{\hat{p_B}(1-\hat{p_B})}{n_B}}} \\\& = \frac{\overline{p_A} -
\overline{p_B}}{\sqrt{\frac{\hat{p_A}(1-\hat{p_A})}{n_A} +
\frac{\hat{p_B}(1-\hat{p_B})}{n_B}}} // 因为 H_0 假设 p_A==p_B\end{aligned}
\tag{1}$$

关于公式 (1) 中 Z-score 的计算还有另外一种计算方法，因为 $H_0$ 假设 $p_A==p_B$，所以我们可以认为 $\mathcal
B(n_A,p_A)$ 和 $\mathcal B(n_B,p_B)$ 均来自于伯努利分布 $\mathcal B(n_A+n_B,
\frac{n_Ap_A+n_Bp_B}{n_A+n_B})$，这个分布的均值和方差为：

$$\begin{aligned}E(p_{AB})&=\frac{n_A\hat{p_A}+n_B\hat{p_B}}{n_A+n_B}
\\\D(p_{AB})&=E(p_{AB})(1-E(p_{AB}))
\\\&=\frac{n_A\hat{p_A}+n_B\hat{p_B}}{n_A+n_B}(1-\frac{n_A\hat{p_A}+n_B\hat{p_B}}{n_A+n_B})\end{aligned}$$

于是，可以得到如下计算公式

$$\begin{aligned}\overline{p_A} &\sim \mathcal
N(\hat{p_A},\frac{D(p_{AB})}{n_A}) \\\\\overline{p_B} &\sim \mathcal
N(\hat{p_B},\frac{D(p_{AB})}{n_B}) \\\\\overline{p_A} - \overline{p_B} &\sim
\mathcal N(\hat{p_A}-\hat{p_B},D(p_{AB})(\frac{1}{n_A} + \frac{1}{n_B})) \\\Z
&= \frac{\overline{p_A} - \overline{p_B}}{\sqrt{D(p_{AB})(\frac{1}{n_A} +
\frac{1}{n_B})}} \\\&= \frac{\overline{p_A} -
\overline{p_B}}{\sqrt{\frac{n_A\hat{p_A}+n_B\hat{p_B}}{n_A+n_B}(1-\frac{n_A\hat{p_A}+n_B\hat{p_B}}{n_A+n_B})(\frac{1}{n_A}
+ \frac{1}{n_B}})}\end{aligned}$$

这种计算方法是在 $H_0$ 假设成立的前提下，认为 A 和 B 的样本来自同一个分布，此分布的参数 $p$ 是 A 样本和 B
样本的加权平均，因为是同一分布，因此方差一样，为上式中的 $D(p_{AB})$。

**第三步：计算 p 值**

p 值等于标准正态分布中横坐标大于 Z score 的曲线下的面积，如下图所示：

![](https://images.gitbook.cn/1cc34c40-4840-11eb-a5aa-e9f4ccbc8f49)

注意一下单边/双边假设检验问题，因为我们的备择假设是总体 $p_B$ $\gt$ 总体 $p_A$，因此是一个单边假设，如果是双边假设的话，p
值等于标准正态分布中横坐标大于 +Z score 和 小于 -Z score 的曲线下的面积和。

假设计算出的 p 值小于事先设定好的显著性水平 $\alpha$，则认为零假设 $H_0$ 不成立，备择假设 $H_1$ 成立，即实验 B 的表现确实比实验
A 好。

### 一些常见的问题

在这里推荐几个小工具：

  * [AB 测试持续时间计算器](https://vwo.com/tools/ab-test-duration-calculator/)：可以计算在给定当前流量和指标的情况下 AB 测试需要持续多久得到的结论才可信。
  * [AB 测试显著性计算器](https://vwo.com/tools/ab-test-siginficance-calculator/)：可以计算在给定实验组和对照组的流量和转化的情况下，计算出两组实验的指标差异是否具有统计显著性。

于是，一些工作中常见的问题可以得到解答：

  * 实验需要跑多久？[AB 测试持续时间计算器](https://vwo.com/tools/ab-test-duration-calculator/)帮您解答。
  * 实验结论可信了吗？[AB 测试显著性计算器](https://vwo.com/tools/ab-test-siginficance-calculator/)帮您解答。
  * 实验 B 比实验 A 好，怎么证明不是分流带来的差异？万一分给实验 B 的用户都是喜欢消费的，分给实验 A 的都是只看不买的呢？

好办！有两种办法。

  * 可以进行 AABB 实验，即把原来的 AB 两个实验扩展成 AABB 实验，4 份流量，2 份给实验 A， 2 份给实验 B，如果还能得到实验 B 比实验 A 好的结论，这总不会还是分流带来的差异了吧。AABB 这种实验策略会让实验结论更加置信，代价就是对于流量的要求更大了。如果流量很珍贵，也可以采用下面的方法
  * 得到实验 B 比实验 A 好的初步结论后，反转 AB 实验流量，把原先给实验 A 的流量给实验 B，原先给实验 B 的流量给实验 A，观察一段时间后，发现实验 B 还是比实验 A 好，那么我们也可以更确信的说：实验 B 确实比实验 A 好，与分流无关。这种反转实验的代价就是实验周期拉长了。

### 小结

好了，本文终于要结束了。看了这么多公式，一时间可能有点难以消化，没事，这些都是大学期间最基本的概率论和统计知识，相信稍加温习对同学们来说不是问题。

涉及到 AB 测试的知识，统计学难以避免，虽然作为算法工程师，我们不要求能设计一个 AB
测试平台，但是对于其背后的分层分流原理的理解和关于假设检验等统计学基本知识的掌握也是一项特别重要的技能。

很多时候我们都是在 AB 测试平台上开实验，关实验，但是对于其背后如何通过指标得出哪个实验更优的过程一无所知，希望本文能够帮助到你。

到此，推荐系统中的 **召回部分** 就完结了，在召回部分，主要讲解了以下内容：

  * 协同过滤
  * 关联规则
  * 词向量
  * 深度召回
  * 离线评估
  * 近似最近邻搜索：LSH 算法和 HNSW 算法
  * AB 测试的相关知识

对于各种算法和离线指标的实现上，我们留白了 **深度召回的代码实现** 和 **AUC 的原理和实现** ，对于 AB 测试，我们留白了
**线上线下不一致** 的问题。

这些内容将会出现在 **排序部分** ，我们将使用 TensorFlow
这个深度学习的框架来实现绝大多数排序算法模型，希望同学们或多或少有该框架的使用经验。

咱们排序部分见！

注释 1：[Overlapping Experiment Infrastructure: More, Better, Faster
Experimentation](https://static.googleusercontent.com/media/research.google.com/zh-
CN//pubs/archive/36500.pdf)

