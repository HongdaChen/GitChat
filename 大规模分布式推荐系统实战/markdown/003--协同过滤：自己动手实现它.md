上一篇文章花了很大的篇幅详细地说明了协同过滤数据源的处理，以及此算法的实现思路，为了唤醒各位读者的记忆，首先简要回顾一下协同过滤算法的逻辑，即伪代码。

UID 为用户 ID，IID 为物品 ID，R 为打分，SIM 为相似度。

根据用户行为得到用户物品打分表：

    
    
    [1] UID, IID, R
    

根据 UID 聚合，得到如下数据：

    
    
    [2] UID, [IID:R,IID:R ......]
    

根据相似度计算公式，计算单个用户下物品相似度，称为局部相似度，得到如下数据：

    
    
    [3] IID1, IID2, SIM1
    

根据 IID1 和 IID2 作 Key，聚合得到如下数据：

    
    
    [4] IID1, IID2, [SIM1、SIM2、.......、SIMN]
    

每一对 (IID1, IID2) 的局部相似度集合求平均，得到全局相似度：

    
    
    [5] IID1，IID2，SIM
    

对每个 IID，取与其最相似的 N 个物品，得到 topN 相似度表。

上一篇文章已经完成了第 1 步的工作，这篇文章来完成剩下的工作。

这也可以看出，算法工程师在实现一种算法时，90% 的时间都在数据处理中，真正实现算法代码的部分反而很少。

当用户数在千万级别、物品数在百万级别时，数据很容易就达到 TB 级，想要实现协同过滤，单机环境显然力不从心，必须借助于分布式框架。

即使没接触过 Spark/Scala
也没关系，它只是实现协同过滤逻辑的一种方式，读者只要通过上一篇以及本文理解了协同过滤的逻辑，那么可以采用自己熟悉的计算机语言和框架去实现这种算法。

### 分布式实现$^1$

#### **STEP 1：读取数据源**

根据用户行为得到用户物品打分表。

这一步已经在上一篇文章中完成。通过对用户行为数据的处理，得到了用户物品打分表，假设已经将此表存储在 Hive（或者类似的分布式存储）中。

表名称 recsys.data_itemcf，表数据格式如下：

user | item | rating  
---|---|---  
小明 | P40PRO | 1.28  
小明 | iPhone11 | 0.12  
小明 | iPad | 0.05  
小明 | 吸尘器 | 0.00001  
小明 | 空气净化器 | 0.00002  
…… | …… | ……  
  
首先定义一些变量，便于代码阅读：

    
    
    /* USER 就是 String 的别名，本质上是一样的，其他定义同理 */
    type USER = String
    type ITEM = String
    type RATING = Double
    type SIM = Double
    type SIMSUM = Double
    type COUNT = Long
    
    /* 定义数据结构 */
    case class UserItemRating(user: USER, item: ITEM, rating: RATING)
    

如下代码片段读取 Hive 数据：

    
    
    /* Spark 读取 Hive 表数据，将表数据转换成自定义的数据结构 */
    val userItemRating: RDD[(USER, (ITEM, RATING))] = spark.sqlContext.sql("select user, item, rating from recsys.data_itemcf")
      .map { case Row(user: USER, item: ITEM, rating: RATING) => (user, (item, rating)) }
    

#### **STEP 2：聚合行为数据**

根据 UID 聚合。

接下来需要对同一个用户的打分进行聚合，将分散在多个分区的同一个 USER 聚合到一条记录里来。

因为 Spark 是将海量数据分布在各个分区（partition）中，所以 同一个 USER 的数据可能会存在多个分区中，那么做聚合时，需要两步走：

  * 先在分区内将同一个 USER 的数据合并，这样一个分区内一个 USER 只有一条记录；
  * 再在分区间将同一个 USER 的数据合并，这样整个数据中同一个 USER 只有一条记录。

代码如下：

    
    
    val userItemRatings: RDD[(USER, ArrayBuffer[(ITEM, RATING)])] = 
    /* aggregateBykey 完成了以上两步的工作。 */
    userItemRating.rdd.aggregateByKey(ArrayBuffer[(ITEM, RATING)]())(
      (partitionRecords: ArrayBuffer[(ITEM, RATING)], singleRecord: (ITEM, RATING)) => {
          partitionRecords.append(singleRecord)
          partitionRecords
      }, // 1
      (partition1Records: ArrayBuffer[(ITEM, RATING)], partition2Records: ArrayBuffer[(ITEM, RATING)]) => {
          partition1Records.appendAll(partition2Records)
          partition1Records
      } // 2
    ).filter { case (user: USER, itemRatings: ArrayBuffer[(ITEM, RATING)]) => itemRatings.length >= 2 } // 3
    

  * 注释 1 是告诉 Spark 分区内同一个 KEY（USER）如何合并，在这里我们把一个分区内同一个 USER 的记录放在一个集合 中；
  * 注释 2 是告诉 Spark 分区间同一个 KEY（USER）如何合并，在这里我们把不同分区间同一个 USER 对应的 集合连接起来；
  * 注释 3 过滤掉只消费过 一个物品的用户，根据协同过滤的计算逻辑，想要计算同一个用户下的物品相似度，物品数量至少 2 个。

[aggregateBykey](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)
的数据流转如下所示：

![aggregateByKey](https://images.gitbook.cn/e253f100-2660-11eb-9e6e-492b4066adc9)

#### **STEP 3：局部物品相似度**

计算单个用户下物品相似度。

经过 STEP 2，已经得到了 同一个用户的所有行为物品及其打分表（称为 **用户物品倒排表** ），现在可以计算单个用户下，物品之间的相似度了。

    
    
    val itemSimFromOneUser: RDD[((ITEM, ITEM), SIM)] =  userItemRatings.flatMap {
      case (user: USER, itemRatings: ArrayBuffer[(ITEM, RATING)]) =>
        /* combinations(2) 函数返回集合内元素的两两排列组合 */
        /* 遍历 combinations 生成的两两组合 */
        for (ArrayBuffer(itemRating1, itemRating2) <- itemRatings.combinations(2)) yield {
          /* 每个 itemRating 都是 (item, rating) 的二元组 */
          val (item1, rating1) = itemRating1
          val (item2, rating2) = itemRating2
          val itemPair = (item1, item2)
          /* 采用得分绝对差值计算相似度 */
          val localSimilarity = 1 / (1 + Math.abs(rating1 - rating2))
          /* 得到单个用户下，物品两两相似度，key 为 (item1, item2) pair，value 为此用户眼中的物品相似度 */
          (itemPair, localSimilarity)
        }
    }
    

combinations(2) 函数会生成集合内元素的两两排列组合，比如：

    
    
    Array(1,2,3,4).combinations(2) => (1,2),(1,3),(1,4),(2,3),(2,4),(3,4)
    

恰好满足在同一个 USER 下计算物品两两相似度的需求。

#### **STEP 4 & 5：全局物品相似度**

聚合同一对 (item1, item2) 在所有用户下的相似度，得到相似度集合；每一对 (item1, item2) 的相似度集合求平均，得到全局相似度。

到这里，已经有了 (item1, item2) 的局部相似度（单个用户下的相似度）。

大数据时代，人多力量大，所以对 所有局部相似度 求平均，可以得到 全局相似度。

代码逻辑如下：

  * 以 (item1, item2) 为 key 聚合，生成一个 集合，不断地将 相似度 追加到集合中（注释 1）；
  * 聚合完毕后，数据结构为：(item1, item2, globalSimArray)，然后对 globalSimArray 中的元素求平均，得到最终的结果。

    
    
    val itemSimilarity: RDD[(ITEM, ITEM, SIM)] = 
      itemSimFromOneUser.aggregateByKey(ArrayBuffer[SIM]())( 
        (localSimArray:ArrayBuffer[SIM], sim: SIM) => {
          localSimArray.append(sim)
          localSimArray
        },
        (localSimArray1, localSimArray2) => {
          localSimArray1.appendAll(localSimArray2)
          localSimArray1
        } // 1
      ).map { case ((item1, item2), globalSimArray) =>
        (item1, item2, globalSimArray.sum / globalSimArray.length)
      }
    

很好，经过千山万水终于得到了协同过滤算法生成的物品相似度表，我迫不及待地在地鼠商城生产环境运行了这段代码。

怎么可能让我一次性就 pass 呢，这段代码运行的缓慢，甚至有时候会失败，聪明的读者发现了哪里会有问题了吗（停顿 3 分钟……）？

**答案就是** ：如果 (item1, item2) 同时出现的次数非常多，globalSimArray 会非常大，很容易 OOM 或者程序运行特别慢。

优化思路如下：

  * 平均公式：(sim1 + sim2 + … + simN) / N。分子为相似度值的累加，分母为 (item1, item2) 同时出现的次数，初值均为 0。
  * 聚合时，不保留相似度数组，只累加相似度值 similaritySum 以及 (item1, item2) 同时出现的次数 countSum。
  * 最终计算 similaritySum / countSum = (sim1 + sim2 + … + simN) / N。结果是一样的。

优化后的代码如下：

    
    
    val itemSimilarity: RDD[(ITEM, ITEM, SIM)] = 
      itemSimFromOneUser.aggregateByKey((0.0, 0L))( 
        (similarityAndCountSum:(SIMSUM, COUNT), similarity: SIM) => {
          val (similaritySum, countSum) = similarityAndCountSum
          (similaritySum + similarity, countSum + 1)
        },
        (similarityAndCountSum1:(SIMSUM, COUNT), similarityAndCountSum2:(SIMSUM, COUNT)) => {
          val (similaritySum1, countSum1) = similarityAndCountSum1
          val (similaritySum2, countSum2) = similarityAndCountSum2
          (similaritySum1 + similaritySum2, countSum1 + countSum2)
        }
      ).flatMap { case ((item1, item2), (similaritySum, countSum)) =>
        val item12Sim = (item1, item2, similaritySum / countSum)
        val item21Sim = (item2, item1, similaritySum / countSum)
        Iterator(item12Sim, item21Sim) // item1 和 item2 的相似度，与 item2 和 item1 的相似度是一样的
      }
    

当数据量特别大时，优化后的代码运行速度远超优化前的代码。

#### **STEP 6：topN**

对每个 IID，取与其最相似的 N 个物品，得到 topN 相似度表。

在协同过滤上线前，还有最后一步的工作。

对于每个物品，给用户推荐时，只能推与此物品最相似的 N 个物品，这里假设 N 为 10。

经过 以上 5 步跋山涉水，我们得到了如下物品相似度表：

item1 | item2 | similarity  
---|---|---  
string | string | double  
  
每个 item1 都有百万个 item2 以及对应的相似度 similarity。

那么 topN 怎么得到呢？

一种朴素的思路是：

> 根据 item1 聚合，得到一个集合，集合中含有百万个 (item2, similarity) 对，然后根据 similarity 从大到小排序，取
> topN 个。

这种方式可能可以得到想要的结果，但是对内存的要求特别大，因为每个物品都要保存一个容量为百万级别的集合。

> 时间复杂度 O(nlogn)，空间复杂度 O(n^2)，n 是物品数量。

那么有没有时间复杂度 O(n)，空间复杂度也是 O(n) 的方法呢？ **小顶堆** 。

经常刷 LeetCode 或者 HackerRank 的同学应该很清楚，topN 问题的经典解决方案。想要深入研究的同学可以在网上自行搜索。

大致的思路如下。

对于每个物品：

  * 建立一个容量为 N 的小顶堆，堆顶为值最小的元素。
  * 新元素到来时：
    * 如果堆中元素个数小于 N，直接插入；
    * 如果堆中元素个数大于等于 N，则：如果新元素小于堆顶元素，丢弃；否则删除堆顶元素，插入新元素。
    * 时间复杂度 O(logN)，与物品个数 n 无关，为常数 O(1)。
  * 因为堆中元素个数固定 N 个，与物品个数 n 无关，为常数 O(1)。

即每个物品得到 topN 所需的时间复杂度为 O(1)，空间复杂度为 O(1)。

此种解决方案的时间复杂度 O(n)，空间复杂度 O(n)。

代码如下所示：

    
    
    /* 首先定义如果集合中元素是 (ITEM, SIM) 时的排序规则，也即按照 SIM 来排序 */
    val ordering: Ordering[(ITEM, SIM)] = new Ordering[(ITEM, SIM)] {
      override def compare(self: (ITEM, SIM), that: (ITEM, SIM)): Int = {
        val (item1, sim1) = self
        val (item2, sim2) = that
        sim1.compareTo(sim2)
      }
    }
    
    /* 得到每个 item1 对应的 N 个最相似的 item2 */
    val itemTopNSimilarity: RDD[(ITEM, Array[(ITEM, SIM)])] = itemSimilarity
      .map { case (item1, item2, sim) => (item1, (item2, sim)) }
      .topByKey(N)(ordering)
    

至此，得到了每个物品及其对应的 N 个相似物品，这个结果已经可以在线上使用。

但是，本着精益求精的精神，还有一些小优化点需要考虑一下。

### 让结果更准确

通常在数据分析中，查看数据分布是最常见的一种手段。简要介绍下百分位数的概念。

假设有一个集合，内部的元素都是数字，第 i 个百分位数的值等于 j 的意思是：

> 有百分之 i 个数的数值小于 j。

比如，集合大小是 150，10 百分位数对应的数值是 20，说明集合中 10% 的数小于 20。99 百分位数对应的数值是 100，说明 集合中 99%
的数都小于 100。

理解了这个概念，再往下走。

#### **无效用户过滤**

首先，可以按照 USER 聚合，统计数据集内此用户产生行为的物品个数。

> 类似 COUNT(DISTINCT item) GROUP BY user。

那么就可以统计每个用户产生行为的物品个数对应的百分位数，过滤掉行为过多的或者过少的用户。比如，过滤掉大于 99.9 分位数的用户或者小于 1 分位数的用户。

HIVE SQL 有 PERCENTILE 和 PERCENTILE_APPROX 内置函数，可以查出每个数值列的百分位数对应的数值是多少。

#### **热门用户/物品惩罚**

爬虫用户或者代购用户或者经常进货的店主，这样的用户，其行为非常多且很杂乱，那么据此计算出的相似度是需要降权/惩罚的。

日用品或者消耗品，比如牙膏、大米、纸巾等，它们与其他物品同时出现的次数非常多，也就是从协同过滤计算逻辑来看，它们几乎会和任何物品产生“相似性”，同理，这样的物品的相似度计算也需要降权/惩罚。

#### **优化实现方案**

针对上述问题，实现方案也很简单，如下：

假设用户产生行为的物品个数的 99.9 百分位数为 3000，也就是说数据集内 99.9% 的用户消费的物品数不超过 3000。

优化实现如下。

**1\. 解决无效用户**

    
    
    /*** 1. 无效用户过滤 ****/
    val UPPER_BOUND = 3000
    val LOWER_BOUND = 2
    
    /* 获取到需要过滤的用户 */
    val filteredUsers = userItemRating
      .groupBy("user").agg(countDistinct("item") as "item_count")
      .filter($"item_count" >= UPPER_BOUND && $"item_count" >= LOWER_BOUND)
      .select("user").as[String].collect()
    
    /* 广播出去，提高运算性能 */
    val filteredUsersBC = spark.sparkContext.broadcast(filteredUsers)
    
    /* 过滤掉无效用户，后续计算都基于 filteredUserItemRating */
    val filteredUserItemRating = userItemRating
      .filter(!$"user".isin(filteredUsersBC.value: _*))
    

**2\. 惩罚热门用户/物品**

实现代码之前，先理清思路：

  * 惩罚热门用户，需要得到每个用户消费的物品数量，个数越多，此用户越热门
  * 惩罚热门物品，需要得到每个物品消费的用户数量，个数越多，此物品越热门
  * 计算局部相似度时，实施热门用户惩罚
  * 计算全局相似度时，实施热门物品惩罚

有了思路，代码片段如下：

    
    
    /* 统计每个物品的消费人数 */
    val itemCounts = filteredUserItemRating.
      groupBy("item").agg(countDistinct("user") as "user_count")
      .select("item", "user_count")
      .map{ case (item: ITEM, userCount: COUNT) => (item, userCount) }
      .rdd
      .collectAsMap()
    
    val itemCountBC = spark.sparkContext.broadcast(itemCounts)
    
    /* userItemRatings */
    val userItemRatings: RDD[(USER, ArrayBuffer[(ITEM, RATING)])] = filteredUserItemRating...
    
    val itemSimFromOneUser: RDD[((ITEM, ITEM), SIM)] = userItemRatings.flatMap {
      case (user: USER, itemRatingCounts: ArrayBuffer[(ITEM, RATING)]) =>
        for (ArrayBuffer(itemRating1, itemRating2) <- itemRatingCounts.combinations(2)) yield {
          val (item1, rating1) = itemRating1
          val (item2, rating2) = itemRating2
          val itemPair = (item1, item2)
          /* ADDED: 热门用户惩罚 */
          val localSimilarity = 1 / (1 + Math.abs(rating1 - rating2)) / math.log1p(itemRatingCounts.size)
          (itemPair, localSimilarity)
        }
    }
    
    val itemSimilarity: RDD[(ITEM, ITEM, SIM)] =
    itemSimFromOneUser.aggregateByKey((0.0, 0L))(
      (similarityAndCountSum: (SIMSUM, COUNT), similarity: SIM) => {
        val (similaritySum, countSum) = similarityAndCountSum
        (similaritySum + similarity, countSum + 1)
      },
      (similarityAndCountSum1: (SIMSUM, COUNT), similarityAndCountSum2: (SIMSUM, COUNT)) => {
        val (similaritySum1, countSum1) = similarityAndCountSum1
        val (similaritySum2, countSum2) = similarityAndCountSum2
        (similaritySum1 + similaritySum2, countSum1 + countSum2)
      }
    ).flatMap { case ((item1, item2), (similaritySum, _)) =>
      /* ADDED: 热门物品惩罚 */
      val count1 = itemCountBC.value(item1)
      val count2 = itemCountBC.value(item2)
      val item12Sim = (item1, item2, similaritySum / math.sqrt(count1 * count2))
      val item21Sim = (item2, item1, similaritySum / math.sqrt(count1 * count2))
      Iterator(item12Sim, item21Sim)
    }
    

### 下篇预告

目前为止，地鼠商城的第一个召回算法——协同过滤，基本上开发完成了，不管是物品的覆盖度和准确度等离线指标均表现良好，而且上线之后取得了很好的效果$^2$。

但是作为一个工程师，精益求精和折腾不止的态度是不能缺少的，通过上述实现读者们会发现，协同过滤算法计算量巨大，一般会采用每天运行一次来更新物品的相似度，但是在地鼠商城，物品的上架和下架都非常频繁，怎样让算法不再一天更新一次，而能够做到准实时（比如分钟级）的更新呢？

留给读者们这么一个小问题，下篇再见。

* * *

注释 1：本篇完整代码见 [GitHub](https://github.com/recsys-4-everyone/dist-recsys)

注释 2：关于召回算法的离线评测，会专门作为一个主题在后面细说

